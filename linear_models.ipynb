{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeKFold:\n",
    "    ''' k-fold cross validator splitting on a particular attribute\n",
    "        so that all samples with a given value are either in the train or test set\n",
    "\n",
    "        attribute value for each sample is given in the constructor, so that\n",
    "        the attribute itself need not be in the features for the model\n",
    "    '''\n",
    "    def __init__(self, cv, attr):\n",
    "        self.cv, self.attr = cv, attr\n",
    "\n",
    "    def get_n_splits(self, *args, **kwargs):\n",
    "        return self.cv.get_n_splits(*args, **kwargs)\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        vals = self.attr.unique()\n",
    "        for train_idx, test_idx in self.cv.split(vals):\n",
    "            train_mask = self.attr.isin(vals[train_idx])\n",
    "            test_mask = self.attr.isin(vals[test_idx])\n",
    "\n",
    "            yield (\n",
    "                np.argwhere(train_mask).reshape(-1),\n",
    "                np.argwhere(test_mask).reshape(-1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogUniform:\n",
    "    ''' random variable X such that log(x) is distributed uniformly\n",
    "    '''\n",
    "    def __init__(self, base, expmin, expmax):\n",
    "        self.base, self.expmin, self.expmax = base, expmin, expmax\n",
    "\n",
    "    def rvs(self, size=None, random_state=None):\n",
    "        random_state = random_state or np.random.RandomState()\n",
    "        exp = random_state.uniform(self.expmin, self.expmax, size=size)\n",
    "        return np.power(self.base, exp)\n",
    "\n",
    "\n",
    "class IntDistribution:\n",
    "    ''' random variable taking only integer values\n",
    "    '''\n",
    "    def __init__(self, rv):\n",
    "        self.rv = rv\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        sample = self.rv.rvs(*args, **kwargs)\n",
    "        return int(round(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(most_only):\n",
    "    dframe_path = 'data/cabauw/processed-full-log.csv.gz'\n",
    "    df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[df.ds != 201603]\n",
    "\n",
    "    wind_temp_levels = df.pivot_table(\n",
    "        values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "    ).reset_index()\n",
    "    wind_temp_levels.columns = [\n",
    "        '%s_%d' % (a, b) if b else a\n",
    "        for a, b in wind_temp_levels.columns.values\n",
    "    ]\n",
    "\n",
    "    ddf = df.merge(wind_temp_levels, on=['ds', 'tt']).dropna()\n",
    "    \n",
    "    if most_only:\n",
    "        ddf = ddf[(ddf.zL > -2) & (ddf.zL < 1)]\n",
    "\n",
    "    features = [\n",
    "        'air_dens', 'H', 'LE', 'wind', 'temp', 'virtual_temp',\n",
    "        'soil_temp', 'z',\n",
    "        'dewpoint', 'spec_hum', 'rel_hum', 'press', 'rain', 'co2flux',\n",
    "        'soilheat', 'netrad', 'temp_10', 'temp_20', 'temp_40', 'wind_10',\n",
    "        'wind_20', 'wind_40'\n",
    "    ]\n",
    "    \n",
    "    return ddf, features\n",
    "\n",
    "\n",
    "df, features = load_data(most_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = BaggingRegressor(Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('scal', StandardScaler()),\n",
    "    ('redu', TruncatedSVD()),\n",
    "    ('reg', Ridge()),\n",
    "]))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'base_estimator__poly__degree': [1, 2],\n",
    "    'base_estimator__poly__interaction_only': [True, False],\n",
    "    'base_estimator__redu__n_components': stats.uniform(0.1, 0.89),\n",
    "    'base_estimator__reg__alpha': LogUniform(10, -7, 1),\n",
    "    'n_estimators': IntDistribution(stats.uniform(5, 20)),\n",
    "    'max_samples': stats.uniform(0.05, 0.20),\n",
    "    'max_features': stats.uniform(0.25, 0.75),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=6)]: Done 156 tasks      | elapsed: 93.0min\n",
      "[Parallel(n_jobs=6)]: Done 240 out of 240 | elapsed: 152.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<__main__.AttributeKFold object at 0x000001541DBBF278>,\n",
       "          error_score='raise',\n",
       "          estimator=BaggingRegressor(base_estimator=Pipeline(memory=None,\n",
       "     steps=[('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('scal', StandardScaler(copy=True, with_mean=True, with_std=True)), ('redu', TruncatedSVD(algorithm='randomized', n_components=2, n_iter=5,\n",
       " ...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=24, n_jobs=6,\n",
       "          param_distributions={'base_estimator__poly__degree': [1, 2], 'base_estimator__poly__interaction_only': [True, False], 'base_estimator__redu__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001541DB63DA0>, 'base_estimator__reg__alpha': <__main__.LogUniform object at 0x00000...BCC160>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001541DBCC630>},\n",
       "          pre_dispatch='n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sdf = df.sample(250000)\n",
    "sdf = df\n",
    "cv = AttributeKFold(KFold(10, shuffle=True), sdf.ds)\n",
    "\n",
    "gs = RandomizedSearchCV(\n",
    "    est,\n",
    "    params,\n",
    "    n_iter=24,\n",
    "    n_jobs=6,\n",
    "    pre_dispatch='n_jobs',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")\n",
    "\n",
    "gs.fit(sdf[features], sdf.phi_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.22737299629452476,\n",
       " {'base_estimator__poly__degree': 2,\n",
       "  'base_estimator__poly__interaction_only': True,\n",
       "  'base_estimator__redu__n_components': 0.8490425973878727,\n",
       "  'base_estimator__reg__alpha': 2.4889513704928645,\n",
       "  'max_features': 0.8752263035307435,\n",
       "  'max_samples': 0.1990965341937379,\n",
       "  'n_estimators': 9})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_, gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
