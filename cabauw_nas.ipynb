{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we put together things from the nnet and neural architecture search notebooks, and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "from scipy.stats import probplot\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.utils import shuffle\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, GaussianNoise, Input, PReLU, Activation, Concatenate\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras import regularizers \n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerRNN:\n",
    "    def __init__(self, max_len, batch_size, type_size, arg_size,\n",
    "                 learning_rate=0.001, hidden_size=32, baseline_smoothing=0.95):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.unroll_by = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.type_size = type_size + 1  # 0 is for end-of-network token\n",
    "        self.arg_size = arg_size\n",
    "        self.baseline_smoothing = baseline_smoothing\n",
    "\n",
    "    def build(self):\n",
    "        # reward for the architectures\n",
    "        self.architecture_reward = tf.placeholder(tf.float32, [self.batch_size])\n",
    "        \n",
    "        # exponential moving average of the reward\n",
    "        self.last_average_reward = tf.reduce_mean(self.architecture_reward)\n",
    "        self.reward_ema = tf.train.ExponentialMovingAverage(self.baseline_smoothing)\n",
    "        self.update_reward_ema = self.reward_ema.apply([self.last_average_reward])\n",
    "\n",
    "        rnn = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
    "        state = tf.random_normal([self.batch_size, rnn.state_size])\n",
    "        \n",
    "        # weight matrices to transform from rnn output to layer type and discrete arg\n",
    "        rnn_to_layer_type_weight = tf.Variable(tf.random_normal([rnn.output_size, self.type_size]))\n",
    "        rnn_to_layer_type_gradient = []\n",
    "        rnn_to_layer_arg_weight = tf.Variable(tf.random_normal([rnn.output_size, self.arg_size]))\n",
    "        rnn_to_layer_arg_gradient = []\n",
    "\n",
    "        # rnn output and gradients\n",
    "        output = tf.random_normal([self.batch_size, rnn.output_size])\n",
    "\n",
    "        # layer_probs contains the output from the network, namely the probabilities\n",
    "        # of type and argument for every layer of every network\n",
    "        self.layer_probs = []\n",
    "\n",
    "        # layer_indicators contains one-hot indicators of type and argument\n",
    "        # for every layer of every network.\n",
    "        # used to select which action is used to compute the gradient.\n",
    "        # fixed, must be set before updating the weights\n",
    "        self.layer_indicators = []\n",
    "\n",
    "        losses = []\n",
    "        \n",
    "        for i in range(self.unroll_by):\n",
    "            # run rnn cell\n",
    "            output, state = rnn(output, state)\n",
    "\n",
    "            if i == 0:  # gru variables are only initialized now\n",
    "                rnn_params = rnn.trainable_variables + rnn.trainable_weights\n",
    "                rnn_gradients = [[] for _ in range(len(rnn_params))]\n",
    "\n",
    "            # compute output probabilites\n",
    "            layer_type = tf.nn.softmax(tf.matmul(output, rnn_to_layer_type_weight))\n",
    "            layer_arg = tf.nn.softmax(tf.matmul(output, rnn_to_layer_arg_weight))\n",
    "            chosen_layer_type = tf.placeholder(tf.int32, self.batch_size)\n",
    "            chosen_layer_arg = tf.placeholder(tf.int32, self.batch_size)\n",
    "            self.layer_probs.append((layer_type, layer_arg))\n",
    "            self.layer_indicators.append((chosen_layer_type, chosen_layer_arg))\n",
    "\n",
    "            # aggregate gradients\n",
    "            baseline = self.reward_ema.average(self.last_average_reward)\n",
    "            prob = (self.last_average_reward - baseline) * (\n",
    "                tf.reduce_sum(\n",
    "                    tf.one_hot(chosen_layer_type, depth=self.type_size) * tf.log(layer_type + 1e-12),\n",
    "                    axis=1\n",
    "                ) + tf.reduce_sum(\n",
    "                    tf.one_hot(chosen_layer_arg, depth=self.arg_size) * tf.log(layer_arg + 1e-12),\n",
    "                    axis=1\n",
    "                )\n",
    "            )\n",
    "            losses.append(prob)\n",
    "\n",
    "            rnn_to_layer_arg_gradient.append(tf.gradients(prob, rnn_to_layer_arg_weight)[0])\n",
    "            rnn_to_layer_type_gradient.append(tf.gradients(prob, rnn_to_layer_type_weight)[0])\n",
    "            for param, grad in zip(rnn_params, rnn_gradients):\n",
    "                grad.append(tf.gradients(prob, param)[0])\n",
    "\n",
    "        self.loss = tf.reduce_mean(losses)\n",
    "\n",
    "        def sanitize_gradient(grads):\n",
    "            avg = sum(grads) / len(grads)\n",
    "            return tf.clip_by_norm(avg, 1.0)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimize = optimizer.apply_gradients([\n",
    "            (sanitize_gradient(grad), param)\n",
    "            for param, grad in zip(rnn_params, rnn_gradients)\n",
    "        ] + [\n",
    "            (sanitize_gradient(rnn_to_layer_type_gradient), rnn_to_layer_type_weight),\n",
    "            (sanitize_gradient(rnn_to_layer_arg_gradient), rnn_to_layer_arg_weight),\n",
    "        ])\n",
    "\n",
    "    def generate_architecture(self, session):\n",
    "        layers = session.run(self.layer_probs)\n",
    "        networks = [[] for _ in range(self.batch_size)]\n",
    "        for (ltype, larg) in layers:\n",
    "            for i, (nnet, type_prob, arg_prob) in enumerate(zip(networks, ltype, larg)):\n",
    "                # the network always has at least one layer\n",
    "                if nnet and nnet[-1][0] == 0:\n",
    "                    continue\n",
    "\n",
    "                assert all(np.isfinite(type_prob))\n",
    "                assert all(np.isfinite(arg_prob))\n",
    "\n",
    "                layer_type = np.random.choice(len(type_prob), p=type_prob)\n",
    "                layer_arg = np.random.choice(len(arg_prob), p=arg_prob)\n",
    "                nnet.append((layer_type, layer_arg))\n",
    "\n",
    "        return networks\n",
    "\n",
    "    def learn_from_rewards(self, sess, networks, rewards):\n",
    "        assert len(rewards) == self.batch_size\n",
    "\n",
    "        # set the indicator variables, telling which action was chosen\n",
    "        feed_dict = {ind: []\n",
    "                     for layer_ind in self.layer_indicators\n",
    "                     for ind in layer_ind}\n",
    "\n",
    "        for nnet in networks:\n",
    "            # pad network if shorter than expected\n",
    "            # we set the indicators to -1, so that all one hot will be 0\n",
    "            # thus not contributing to the gradient\n",
    "            if len(nnet) < self.unroll_by:\n",
    "                nnet = nnet + [(-1, -1)] * (self.unroll_by - len(nnet))\n",
    "\n",
    "            assert len(nnet) == self.unroll_by\n",
    "            for (itype, iarg), (ntype, narg) in zip(self.layer_indicators, nnet):\n",
    "                feed_dict[itype].append(ntype)\n",
    "                feed_dict[iarg].append(narg)\n",
    "\n",
    "        feed_dict[self.architecture_reward] = rewards\n",
    "        loss, _, _ = sess.run([self.loss, self.update_reward_ema, self.optimize],\n",
    "                              feed_dict=feed_dict)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class MovingAverages:\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "        self.smoothing = {}\n",
    "        self.snapshots = []\n",
    "    \n",
    "    def update(self, metric, value, smoothing=None):\n",
    "        if smoothing is None:\n",
    "            smoothing = self.smoothing.get(metric, 0.6)\n",
    "        self.smoothing[metric] = smoothing\n",
    "        \n",
    "        # can pass None to update smoothing\n",
    "        if value is not None:\n",
    "            self.metrics[metric] = (\n",
    "                smoothing * self.metrics.get(metric, value)\n",
    "                + (1 - smoothing) * value\n",
    "            )\n",
    "        return self.metrics[metric]\n",
    "    \n",
    "    def update_all(self, **metrics):\n",
    "        for metric, value in metrics.items():\n",
    "            self.update(metric, value)\n",
    "        return [self.metrics[m] for m in metrics]\n",
    "    \n",
    "    def snapshot(self, **meta):\n",
    "        snap = dict(self.metrics)\n",
    "        snap.update(meta)\n",
    "        self.snapshots.append(snap)\n",
    "        return snap\n",
    "\n",
    "    \n",
    "def make_index(dtimes, interval):\n",
    "    # returns a tuple index_above, index_below\n",
    "    # index_above[i] is the largest i\n",
    "    # such that dtimes[index_above[i]] - dtimes[i] < interval\n",
    "    # index_below[i] is the smallest i\n",
    "    # such that dtimes[i] - dtimes[index_below[i]] < interval\n",
    "    # dtimes must be already sorted!\n",
    "    index_below, index_above = np.zeros(\n",
    "        (2, len(dtimes)), dtype=np.int\n",
    "    ) - 1\n",
    "    \n",
    "    for i, x in enumerate(dtimes):\n",
    "        j = index_below[i - 1] if i > 0 else 0\n",
    "        while x - dtimes[j] > interval:\n",
    "            j += 1\n",
    "\n",
    "        index_below[i] = j\n",
    "        index_above[j] = i\n",
    "\n",
    "    last_above = index_above[0]\n",
    "    for i in range(len(dtimes)):\n",
    "        if index_above[i] < 0:\n",
    "            index_above[i] = last_above\n",
    "        else:\n",
    "            last_above = index_above[i]\n",
    "    \n",
    "    return index_above, index_below\n",
    "\n",
    "\n",
    "def compute_trend(df, columns, interval=3600):\n",
    "    df = df.sort_values('datetime')\n",
    "    for z in df.z.unique():  \n",
    "        this_level = df[df.z == z]\n",
    "        index_above, index_below = make_index(this_level.datetime.values, interval)\n",
    "\n",
    "        for col in columns:\n",
    "            val_above = this_level[col].values\n",
    "            val_below = this_level.iloc[index_below][col].values\n",
    "\n",
    "            time_above = this_level.datetime.values\n",
    "            time_below = this_level.iloc[index_below].datetime.values\n",
    "\n",
    "            trend = 3600 * (val_above - val_below) / (time_above - time_below)\n",
    "\n",
    "            df.loc[df.z == z, col + '_trend'] = trend\n",
    "\n",
    "    return df, [col + '_trend' for col in columns]\n",
    "\n",
    "\n",
    "def get_features(df, use_trend, feature_level):\n",
    "    wind_temp_levels = df.pivot_table(\n",
    "        values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "    ).reset_index()\n",
    "    wind_temp_levels.columns = [\n",
    "        '%s_%d' % (a, b) if b else a\n",
    "        for a, b in wind_temp_levels.columns.values\n",
    "    ]\n",
    "\n",
    "    df = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "\n",
    "    feature_sets = [\n",
    "        [\n",
    "            'z', 'wind', 'temp', 'soil_temp',\n",
    "            'wind_10', 'wind_20', 'wind_40',\n",
    "            'temp_10', 'temp_20', 'temp_40',\n",
    "        ],\n",
    "        ['soilheat'],\n",
    "        ['netrad'],\n",
    "        ['rain', 'dewpoint'],\n",
    "        ['H', 'LE'],\n",
    "    ]\n",
    "\n",
    "    features = [\n",
    "        f for fset in feature_sets[:feature_level]\n",
    "        for f in fset\n",
    "    ]\n",
    "    \n",
    "    if use_trend:\n",
    "        df, added_cols = compute_trend(df, [\n",
    "            f for f in features if f != 'z'\n",
    "        ])\n",
    "        features.extend(added_cols)\n",
    "\n",
    "    return df, features\n",
    "\n",
    "\n",
    "def get_train_test_data(df, features, target, samples_count, n_months=12):\n",
    "    df = df.dropna()\n",
    "\n",
    "    # get random test months\n",
    "    test_ds = np.random.choice(df.ds.unique(), n_months, replace=False)\n",
    "    test_mask = df.ds.isin(test_ds)\n",
    "    \n",
    "    train_df, test_df = df.loc[~test_mask], df.loc[test_mask]\n",
    "    if samples_count > 0:\n",
    "        # maintain proportion of train/test samples\n",
    "        test_size = int(samples_count * len(test_df) / len(train_df))\n",
    "        train_df = train_df.sample(samples_count)\n",
    "        test_df = test_df.sample(test_size)\n",
    "    \n",
    "    train_x, train_y = train_df[features], train_df[target]\n",
    "    test_x, test_y = test_df[features], test_df[target]\n",
    "\n",
    "    mean_x, mean_y = train_x.mean(), train_y.mean()\n",
    "    std_x, std_y = train_x.std(), train_y.std()\n",
    "\n",
    "    train_x = (train_x - mean_x) /  std_x\n",
    "    test_x = (test_x - mean_x) / std_x\n",
    "    \n",
    "    assert np.all(np.isfinite(train_x))\n",
    "    \n",
    "    train_y = (train_y - mean_y) / std_y\n",
    "    test_y = (test_y - mean_y) / std_y\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y\n",
    "    \n",
    "\n",
    "def compute_denormalized_mse(std_y):\n",
    "    def denormalized_mse(y_true, y_pred):\n",
    "        # model is trained with normalized data, but we want\n",
    "        # mse on not normalized data to compare with MOST\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "        return mse * std_y**2\n",
    "    return denormalized_mse\n",
    "\n",
    "\n",
    "def build_model(input_shape, architecture, std_y=1):    \n",
    "    regularizer = None\n",
    "    layers = [Input(shape=(input_shape,))]\n",
    "\n",
    "    for layer_type, layer_arg in architecture:\n",
    "        if layer_type == 0 or layer_type == 1:\n",
    "            num = 2**layer_arg\n",
    "            layers.append(PReLU()(\n",
    "                BatchNormalization()(\n",
    "                    Dense(num, kernel_initializer=VarianceScaling(2, 'fan_in'),\n",
    "                          kernel_regularizer=regularizer)(\n",
    "                        layers[-1]\n",
    "                    )\n",
    "                )\n",
    "            ))\n",
    "        elif layer_type == 2:\n",
    "            pkeep = (layer_arg + 1) / 10\n",
    "            layers.append(Dropout(pkeep)(layers[-1]))\n",
    "        elif layer_type == 3:\n",
    "            regu = 6 ** -layer_arg\n",
    "            regularizer = regularizers.l2(regu)\n",
    "        else:\n",
    "            raise ValueError('layer type from 0 to 3')\n",
    "\n",
    "    layers.append(Dense(1)(layers[-1]))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model = Model(inputs=layers[0], outputs=layers[-1])\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=[compute_denormalized_mse(std_y)])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_architecture(step, arch_idx, architecture, max_epochs, samples_count):\n",
    "    train_x, train_y, test_x, test_y, _, std_y = get_train_test_data(\n",
    "        ddf, features, 'phi_m', samples_count, n_months=12\n",
    "    )\n",
    "    \n",
    "    #K.clear_session()  # https://stackoverflow.com/q/35114376/521776\n",
    "    model = build_model(train_x.shape[1], architecture, std_y=std_y)\n",
    "\n",
    "    logdir = 'dev/logs/nas/step-%d-arch-%d' % (step, arch_idx)\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(factor=0.1, verbose=0, min_lr=1e-6, patience=10),\n",
    "        TensorBoard(logdir, write_graph=True, write_grads=True, histogram_freq=0),\n",
    "        EarlyStopping(min_delta=0.001, patience=25),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_x, train_y,\n",
    "        batch_size=1024,\n",
    "        epochs=max_epochs,\n",
    "        verbose=0,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(test_x, test_y)\n",
    "    )\n",
    "\n",
    "    best = min(hist.history['val_denormalized_mse'])\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:211: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    dframe_path = 'data/cabauw/processed-full-log.csv.gz'\n",
    "    df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[df.ds != 201603]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "ddf, features = get_features(df, use_trend=True, feature_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "controller = ControllerRNN(\n",
    "    hidden_size=64,\n",
    "    max_len=20,\n",
    "    batch_size=1,\n",
    "    type_size=3,\n",
    "    arg_size=10,\n",
    "    learning_rate=0.001,\n",
    "    baseline_smoothing=0.99,\n",
    ")\n",
    "\n",
    "hist = []\n",
    "controller_graph = tf.Graph()\n",
    "with controller_graph.as_default():\n",
    "    controller.build()\n",
    "    controller_session = tf.Session(graph=controller_graph)\n",
    "    controller_session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=103.844  inner_mse=1.435  inner_mse_std=0.000  length=20.000  fc_count=0.000  dropo_count=1.000  regu_count=19.000  step=0.000  time=23.800\n",
      "contro_loss=62.420  inner_mse=0.988  inner_mse_std=0.000  length=12.400  fc_count=0.400  dropo_count=0.600  regu_count=11.400  step=1.000  time=48.087\n",
      "contro_loss=37.452  inner_mse=0.701  inner_mse_std=0.000  length=7.840  fc_count=0.640  dropo_count=0.360  regu_count=6.840  step=2.000  time=221.593\n",
      "contro_loss=22.474  inner_mse=0.532  inner_mse_std=0.000  length=5.104  fc_count=0.784  dropo_count=0.216  regu_count=4.104  step=3.000  time=283.459\n",
      "contro_loss=13.610  inner_mse=0.471  inner_mse_std=0.000  length=3.462  fc_count=0.870  dropo_count=0.130  regu_count=2.462  step=4.000  time=312.700\n",
      "contro_loss=28.278  inner_mse=0.715  inner_mse_std=0.000  length=10.077  fc_count=4.522  dropo_count=3.678  regu_count=1.877  step=5.000  time=3454.817\n",
      "contro_loss=72.059  inner_mse=0.706  inner_mse_std=0.000  length=14.046  fc_count=2.713  dropo_count=2.207  regu_count=9.126  step=6.000  time=3479.298\n",
      "contro_loss=43.267  inner_mse=0.591  inner_mse_std=0.000  length=8.828  fc_count=2.028  dropo_count=1.324  regu_count=5.476  step=7.000  time=3515.807\n",
      "contro_loss=305.411  inner_mse=1.171  inner_mse_std=0.000  length=13.297  fc_count=1.617  dropo_count=5.194  regu_count=6.486  step=8.000  time=3586.657\n",
      "contro_loss=183.330  inner_mse=0.867  inner_mse_std=0.000  length=8.378  fc_count=1.370  dropo_count=3.117  regu_count=3.891  step=9.000  time=3596.811\n",
      "contro_loss=110.452  inner_mse=0.781  inner_mse_std=0.000  length=7.427  fc_count=2.022  dropo_count=2.670  regu_count=2.735  step=10.000  time=3634.690\n",
      "contro_loss=358.617  inner_mse=1.264  inner_mse_std=0.000  length=12.456  fc_count=1.613  dropo_count=3.202  regu_count=7.641  step=11.000  time=3703.120\n",
      "contro_loss=215.212  inner_mse=0.910  inner_mse_std=0.000  length=8.274  fc_count=1.768  dropo_count=1.921  regu_count=4.585  step=12.000  time=3712.138\n",
      "contro_loss=130.071  inner_mse=0.981  inner_mse_std=0.000  length=5.764  fc_count=1.461  dropo_count=1.553  regu_count=2.751  step=13.000  time=3765.710\n",
      "contro_loss=78.055  inner_mse=0.703  inner_mse_std=0.000  length=3.859  fc_count=1.276  dropo_count=0.932  regu_count=1.650  step=14.000  time=3816.934\n",
      "contro_loss=55.259  inner_mse=0.733  inner_mse_std=0.000  length=10.315  fc_count=0.766  dropo_count=0.559  regu_count=8.990  step=15.000  time=3841.386\n",
      "contro_loss=57.594  inner_mse=0.995  inner_mse_std=0.000  length=14.189  fc_count=0.460  dropo_count=0.735  regu_count=12.994  step=16.000  time=3869.591\n",
      "contro_loss=35.426  inner_mse=0.749  inner_mse_std=0.000  length=10.513  fc_count=2.276  dropo_count=0.441  regu_count=7.796  step=17.000  time=3982.735\n",
      "contro_loss=21.827  inner_mse=0.774  inner_mse_std=0.000  length=14.308  fc_count=1.365  dropo_count=0.265  regu_count=12.678  step=18.000  time=4007.776\n",
      "contro_loss=13.622  inner_mse=0.728  inner_mse_std=0.000  length=16.585  fc_count=0.819  dropo_count=0.159  regu_count=15.607  step=19.000  time=4032.650\n",
      "contro_loss=8.260  inner_mse=0.572  inner_mse_std=0.000  length=14.751  fc_count=5.292  dropo_count=0.095  regu_count=9.364  step=20.000  time=4596.739\n",
      "contro_loss=6.871  inner_mse=0.620  inner_mse_std=0.000  length=16.851  fc_count=3.175  dropo_count=0.057  regu_count=13.618  step=21.000  time=4621.732\n",
      "contro_loss=170.194  inner_mse=1.181  inner_mse_std=0.000  length=17.310  fc_count=3.105  dropo_count=2.034  regu_count=12.171  step=22.000  time=4665.587\n",
      "contro_loss=106.223  inner_mse=1.259  inner_mse_std=0.000  length=11.586  fc_count=2.263  dropo_count=2.021  regu_count=7.303  step=23.000  time=4673.653\n",
      "contro_loss=63.759  inner_mse=0.959  inner_mse_std=0.000  length=7.352  fc_count=1.758  dropo_count=1.212  regu_count=4.382  step=24.000  time=4680.016\n",
      "contro_loss=38.709  inner_mse=0.786  inner_mse_std=0.000  length=5.611  fc_count=1.855  dropo_count=1.127  regu_count=2.629  step=25.000  time=4741.875\n",
      "contro_loss=23.258  inner_mse=0.597  inner_mse_std=0.000  length=4.167  fc_count=1.513  dropo_count=0.676  regu_count=1.977  step=26.000  time=4793.219\n",
      "contro_loss=103.301  inner_mse=0.624  inner_mse_std=0.000  length=10.500  fc_count=0.908  dropo_count=0.406  regu_count=9.186  step=27.000  time=4817.583\n",
      "contro_loss=165.849  inner_mse=1.114  inner_mse_std=0.000  length=10.300  fc_count=0.945  dropo_count=1.044  regu_count=8.312  step=28.000  time=4913.762\n",
      "contro_loss=99.698  inner_mse=1.020  inner_mse_std=0.000  length=8.180  fc_count=1.367  dropo_count=1.026  regu_count=5.787  step=29.000  time=4922.496\n",
      "contro_loss=62.166  inner_mse=1.121  inner_mse_std=0.000  length=6.908  fc_count=2.820  dropo_count=0.616  regu_count=3.472  step=30.000  time=4949.683\n",
      "contro_loss=393.610  inner_mse=1.139  inner_mse_std=0.000  length=12.145  fc_count=1.692  dropo_count=0.769  regu_count=9.683  step=31.000  time=4954.800\n",
      "contro_loss=236.195  inner_mse=0.876  inner_mse_std=0.000  length=8.087  fc_count=1.815  dropo_count=0.462  regu_count=5.810  step=32.000  time=4963.549\n",
      "contro_loss=291.793  inner_mse=0.829  inner_mse_std=0.000  length=12.852  fc_count=1.089  dropo_count=0.277  regu_count=11.486  step=33.000  time=4987.667\n",
      "contro_loss=175.078  inner_mse=0.654  inner_mse_std=0.000  length=8.111  fc_count=1.053  dropo_count=0.166  regu_count=6.892  step=34.000  time=5023.720\n",
      "contro_loss=105.054  inner_mse=0.543  inner_mse_std=0.000  length=5.267  fc_count=1.032  dropo_count=0.100  regu_count=4.135  step=35.000  time=5065.009\n",
      "contro_loss=63.034  inner_mse=0.498  inner_mse_std=0.000  length=3.560  fc_count=1.019  dropo_count=0.060  regu_count=2.481  step=36.000  time=5101.006\n",
      "contro_loss=37.822  inner_mse=0.428  inner_mse_std=0.000  length=2.536  fc_count=1.012  dropo_count=0.036  regu_count=1.489  step=37.000  time=5293.052\n",
      "contro_loss=22.745  inner_mse=0.379  inner_mse_std=0.000  length=5.522  fc_count=4.607  dropo_count=0.022  regu_count=0.893  step=38.000  time=6793.930\n",
      "contro_loss=303.108  inner_mse=1.370  inner_mse_std=0.000  length=8.113  fc_count=3.964  dropo_count=3.613  regu_count=0.536  step=39.000  time=8068.766\n",
      "contro_loss=183.664  inner_mse=1.358  inner_mse_std=0.000  length=12.868  fc_count=2.378  dropo_count=2.568  regu_count=7.922  step=40.000  time=8075.321\n",
      "contro_loss=110.201  inner_mse=0.967  inner_mse_std=0.000  length=15.721  fc_count=1.827  dropo_count=1.541  regu_count=12.353  step=41.000  time=8088.989\n",
      "contro_loss=66.121  inner_mse=0.707  inner_mse_std=0.000  length=9.832  fc_count=1.496  dropo_count=0.924  regu_count=7.412  step=42.000  time=8148.443\n",
      "contro_loss=961.766  inner_mse=1.240  inner_mse_std=0.000  length=13.899  fc_count=6.098  dropo_count=3.355  regu_count=4.447  step=43.000  time=8993.820\n",
      "contro_loss=653.908  inner_mse=1.500  inner_mse_std=0.000  length=11.940  fc_count=6.459  dropo_count=2.813  regu_count=2.668  step=44.000  time=9077.999\n",
      "contro_loss=417.200  inner_mse=1.726  inner_mse_std=0.000  length=10.364  fc_count=5.475  dropo_count=3.288  regu_count=1.601  step=45.000  time=9097.226\n",
      "contro_loss=440.744  inner_mse=1.503  inner_mse_std=0.000  length=14.218  fc_count=3.285  dropo_count=2.373  regu_count=8.561  step=46.000  time=9102.647\n",
      "contro_loss=264.447  inner_mse=1.102  inner_mse_std=0.000  length=8.931  fc_count=2.371  dropo_count=1.424  regu_count=5.136  step=47.000  time=9107.964\n",
      "contro_loss=158.699  inner_mse=0.855  inner_mse_std=0.000  length=9.359  fc_count=5.423  dropo_count=0.854  regu_count=3.082  step=48.000  time=9183.279\n",
      "contro_loss=95.453  inner_mse=0.813  inner_mse_std=0.000  length=13.615  fc_count=3.254  dropo_count=0.512  regu_count=9.849  step=49.000  time=9207.298\n",
      "contro_loss=119.490  inner_mse=0.915  inner_mse_std=0.000  length=14.569  fc_count=7.152  dropo_count=0.707  regu_count=6.709  step=50.000  time=10465.295\n",
      "contro_loss=333.089  inner_mse=1.393  inner_mse_std=0.000  length=16.741  fc_count=5.091  dropo_count=1.624  regu_count=10.026  step=51.000  time=10506.436\n",
      "contro_loss=203.308  inner_mse=1.336  inner_mse_std=0.000  length=12.045  fc_count=3.455  dropo_count=1.375  regu_count=7.215  step=52.000  time=10528.968\n",
      "contro_loss=121.985  inner_mse=0.958  inner_mse_std=0.000  length=9.227  fc_count=2.473  dropo_count=2.425  regu_count=4.329  step=53.000  time=10551.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=73.191  inner_mse=0.724  inner_mse_std=0.000  length=5.936  fc_count=1.884  dropo_count=1.455  regu_count=2.598  step=54.000  time=10586.618\n",
      "contro_loss=52.539  inner_mse=0.975  inner_mse_std=0.000  length=4.762  fc_count=1.530  dropo_count=1.673  regu_count=1.559  step=55.000  time=10640.526\n",
      "contro_loss=31.684  inner_mse=0.713  inner_mse_std=0.000  length=5.257  fc_count=3.318  dropo_count=1.004  regu_count=0.935  step=56.000  time=10797.402\n",
      "contro_loss=19.011  inner_mse=0.548  inner_mse_std=0.000  length=3.554  fc_count=2.391  dropo_count=0.602  regu_count=0.561  step=57.000  time=10887.765\n",
      "contro_loss=11.530  inner_mse=0.780  inner_mse_std=0.000  length=2.933  fc_count=1.835  dropo_count=0.761  regu_count=0.337  step=58.000  time=11054.288\n",
      "contro_loss=7.205  inner_mse=0.831  inner_mse_std=0.000  length=2.960  fc_count=1.901  dropo_count=0.857  regu_count=0.202  step=59.000  time=11092.624\n",
      "contro_loss=4.366  inner_mse=0.624  inner_mse_std=0.000  length=2.976  fc_count=1.540  dropo_count=0.514  regu_count=0.921  step=60.000  time=11259.757\n",
      "contro_loss=3.187  inner_mse=0.686  inner_mse_std=0.000  length=9.785  fc_count=0.924  dropo_count=0.308  regu_count=8.553  step=61.000  time=11282.726\n",
      "contro_loss=3.318  inner_mse=0.673  inner_mse_std=0.000  length=13.871  fc_count=0.555  dropo_count=0.185  regu_count=13.132  step=62.000  time=11306.166\n",
      "contro_loss=5.826  inner_mse=0.960  inner_mse_std=0.000  length=13.923  fc_count=5.133  dropo_count=0.911  regu_count=7.879  step=63.000  time=11895.859\n",
      "contro_loss=71.769  inner_mse=1.242  inner_mse_std=0.000  length=16.354  fc_count=6.680  dropo_count=1.747  regu_count=7.927  step=64.000  time=12246.268\n",
      "contro_loss=43.120  inner_mse=0.878  inner_mse_std=0.000  length=11.412  fc_count=4.408  dropo_count=2.248  regu_count=4.756  step=65.000  time=12269.162\n",
      "contro_loss=25.874  inner_mse=0.666  inner_mse_std=0.000  length=7.247  fc_count=3.045  dropo_count=1.349  regu_count=2.854  step=66.000  time=12297.174\n",
      "contro_loss=16.286  inner_mse=0.560  inner_mse_std=0.000  length=12.348  fc_count=3.027  dropo_count=0.809  regu_count=8.512  step=67.000  time=12396.447\n",
      "contro_loss=10.064  inner_mse=0.617  inner_mse_std=0.000  length=15.409  fc_count=1.816  dropo_count=0.486  regu_count=13.107  step=68.000  time=12420.604\n",
      "contro_loss=6.040  inner_mse=0.507  inner_mse_std=0.000  length=9.645  fc_count=1.490  dropo_count=0.291  regu_count=7.864  step=69.000  time=12452.985\n",
      "contro_loss=3.748  inner_mse=0.548  inner_mse_std=0.000  length=13.787  fc_count=0.894  dropo_count=0.175  regu_count=12.719  step=70.000  time=12475.824\n",
      "contro_loss=42.783  inner_mse=0.967  inner_mse_std=0.000  length=16.272  fc_count=0.536  dropo_count=0.505  regu_count=15.231  step=71.000  time=12503.255\n",
      "contro_loss=30.304  inner_mse=0.702  inner_mse_std=0.000  length=14.963  fc_count=3.522  dropo_count=2.303  regu_count=9.139  step=72.000  time=14115.402\n",
      "contro_loss=89.094  inner_mse=1.092  inner_mse_std=0.000  length=13.378  fc_count=5.313  dropo_count=1.382  regu_count=6.683  step=73.000  time=14223.094\n",
      "contro_loss=1809.226  inner_mse=1.436  inner_mse_std=0.000  length=16.027  fc_count=3.188  dropo_count=2.029  regu_count=10.810  step=74.000  time=14229.125\n",
      "contro_loss=1085.538  inner_mse=1.018  inner_mse_std=0.000  length=10.016  fc_count=2.313  dropo_count=1.217  regu_count=6.486  step=75.000  time=14242.880\n",
      "contro_loss=651.346  inner_mse=0.757  inner_mse_std=0.000  length=7.210  fc_count=1.788  dropo_count=0.730  regu_count=4.692  step=76.000  time=14253.046\n",
      "contro_loss=411.204  inner_mse=0.732  inner_mse_std=0.000  length=12.326  fc_count=1.073  dropo_count=0.838  regu_count=10.415  step=77.000  time=14276.411\n",
      "contro_loss=247.883  inner_mse=0.665  inner_mse_std=0.000  length=11.795  fc_count=2.244  dropo_count=0.503  regu_count=9.049  step=78.000  time=14558.757\n",
      "contro_loss=149.162  inner_mse=0.501  inner_mse_std=0.000  length=10.277  fc_count=4.546  dropo_count=0.302  regu_count=5.429  step=79.000  time=15577.408\n",
      "contro_loss=89.517  inner_mse=0.423  inner_mse_std=0.000  length=6.566  fc_count=3.128  dropo_count=0.181  regu_count=3.258  step=80.000  time=15627.469\n",
      "contro_loss=53.724  inner_mse=0.383  inner_mse_std=0.000  length=5.140  fc_count=2.277  dropo_count=0.109  regu_count=2.755  step=81.000  time=15927.076\n",
      "contro_loss=32.305  inner_mse=0.348  inner_mse_std=0.000  length=3.884  fc_count=2.166  dropo_count=0.065  regu_count=1.653  step=82.000  time=16262.064\n",
      "contro_loss=69.213  inner_mse=1.007  inner_mse_std=0.000  length=5.130  fc_count=1.700  dropo_count=2.439  regu_count=0.992  step=83.000  time=16801.553\n",
      "contro_loss=46.561  inner_mse=1.212  inner_mse_std=0.000  length=4.678  fc_count=1.420  dropo_count=2.663  regu_count=0.595  step=84.000  time=16824.766\n",
      "contro_loss=27.940  inner_mse=0.897  inner_mse_std=0.000  length=3.607  fc_count=1.652  dropo_count=1.598  regu_count=0.357  step=85.000  time=16834.886\n",
      "contro_loss=20.092  inner_mse=1.159  inner_mse_std=0.000  length=3.764  fc_count=2.191  dropo_count=1.359  regu_count=0.214  step=86.000  time=17112.890\n",
      "contro_loss=12.055  inner_mse=0.840  inner_mse_std=0.000  length=2.658  fc_count=1.715  dropo_count=0.815  regu_count=0.129  step=87.000  time=17136.649\n",
      "contro_loss=7.260  inner_mse=0.624  inner_mse_std=0.000  length=2.395  fc_count=1.829  dropo_count=0.489  regu_count=0.077  step=88.000  time=17549.078\n",
      "contro_loss=7.372  inner_mse=0.936  inner_mse_std=0.000  length=5.437  fc_count=3.497  dropo_count=1.894  regu_count=0.046  step=89.000  time=18245.971\n",
      "contro_loss=4.424  inner_mse=0.689  inner_mse_std=0.000  length=3.662  fc_count=2.498  dropo_count=1.136  regu_count=0.028  step=90.000  time=18286.729\n",
      "contro_loss=2.743  inner_mse=0.530  inner_mse_std=0.000  length=3.797  fc_count=2.699  dropo_count=0.682  regu_count=0.417  step=91.000  time=18379.014\n",
      "contro_loss=1.651  inner_mse=0.442  inner_mse_std=0.000  length=2.678  fc_count=2.019  dropo_count=0.409  regu_count=0.250  step=92.000  time=18428.637\n",
      "contro_loss=24.284  inner_mse=0.531  inner_mse_std=0.000  length=9.607  fc_count=1.212  dropo_count=0.245  regu_count=8.150  step=93.000  time=18564.661\n",
      "contro_loss=31.847  inner_mse=0.598  inner_mse_std=0.000  length=13.764  fc_count=0.727  dropo_count=0.147  regu_count=12.890  step=94.000  time=18588.208\n",
      "contro_loss=19.273  inner_mse=0.493  inner_mse_std=0.000  length=9.459  fc_count=0.836  dropo_count=0.088  regu_count=8.534  step=95.000  time=18683.212\n",
      "contro_loss=11.684  inner_mse=0.434  inner_mse_std=0.000  length=8.075  fc_count=2.502  dropo_count=0.053  regu_count=5.520  step=96.000  time=20927.385\n",
      "contro_loss=7.061  inner_mse=0.530  inner_mse_std=0.000  length=12.845  fc_count=1.501  dropo_count=0.032  regu_count=11.312  step=97.000  time=21027.718\n",
      "contro_loss=4.240  inner_mse=0.476  inner_mse_std=0.000  length=8.107  fc_count=1.301  dropo_count=0.019  regu_count=6.787  step=98.000  time=21057.725\n",
      "contro_loss=2.558  inner_mse=0.521  inner_mse_std=0.000  length=12.864  fc_count=0.780  dropo_count=0.011  regu_count=12.072  step=99.000  time=21186.957\n",
      "contro_loss=25.940  inner_mse=1.136  inner_mse_std=0.000  length=9.719  fc_count=0.868  dropo_count=1.607  regu_count=7.243  step=100.000  time=21359.287\n",
      "contro_loss=15.582  inner_mse=0.826  inner_mse_std=0.000  length=7.431  fc_count=1.721  dropo_count=1.364  regu_count=4.346  step=101.000  time=21384.697\n",
      "contro_loss=9.355  inner_mse=0.648  inner_mse_std=0.000  length=4.859  fc_count=1.433  dropo_count=0.818  regu_count=2.608  step=102.000  time=21434.381\n",
      "contro_loss=15.867  inner_mse=0.548  inner_mse_std=0.000  length=10.915  fc_count=2.060  dropo_count=1.291  regu_count=7.565  step=103.000  time=21520.211\n",
      "contro_loss=10.071  inner_mse=0.500  inner_mse_std=0.000  length=10.949  fc_count=5.636  dropo_count=0.775  regu_count=4.539  step=104.000  time=21737.480\n",
      "contro_loss=6.361  inner_mse=0.440  inner_mse_std=0.000  length=9.369  fc_count=5.381  dropo_count=0.465  regu_count=3.523  step=105.000  time=21849.783\n",
      "contro_loss=3.860  inner_mse=0.407  inner_mse_std=0.000  length=8.422  fc_count=5.629  dropo_count=0.279  regu_count=2.514  step=106.000  time=22698.124\n",
      "contro_loss=2.507  inner_mse=0.367  inner_mse_std=0.000  length=7.053  fc_count=4.577  dropo_count=0.167  regu_count=2.308  step=107.000  time=26587.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=1.715  inner_mse=0.340  inner_mse_std=0.000  length=9.832  fc_count=8.346  dropo_count=0.100  regu_count=1.385  step=108.000  time=38337.550\n",
      "contro_loss=1.041  inner_mse=0.340  inner_mse_std=0.000  length=6.299  fc_count=5.408  dropo_count=0.060  regu_count=0.831  step=109.000  time=38569.397\n",
      "contro_loss=3.566  inner_mse=1.048  inner_mse_std=0.000  length=5.379  fc_count=3.645  dropo_count=0.836  regu_count=0.899  step=110.000  time=38768.225\n",
      "contro_loss=13.512  inner_mse=1.130  inner_mse_std=0.000  length=5.628  fc_count=2.587  dropo_count=2.502  regu_count=0.539  step=111.000  time=38792.476\n",
      "contro_loss=44.764  inner_mse=1.441  inner_mse_std=0.000  length=6.577  fc_count=3.152  dropo_count=3.101  regu_count=0.323  step=112.000  time=38879.164\n",
      "contro_loss=26.869  inner_mse=1.025  inner_mse_std=0.000  length=6.746  fc_count=3.091  dropo_count=3.461  regu_count=0.194  step=113.000  time=38961.576\n",
      "contro_loss=16.739  inner_mse=1.035  inner_mse_std=0.000  length=12.048  fc_count=1.855  dropo_count=2.076  regu_count=8.116  step=114.000  time=38966.632\n",
      "contro_loss=225.219  inner_mse=1.470  inner_mse_std=0.000  length=10.829  fc_count=1.513  dropo_count=4.446  regu_count=4.870  step=115.000  time=38990.462\n",
      "contro_loss=155.008  inner_mse=1.724  inner_mse_std=0.000  length=14.497  fc_count=6.108  dropo_count=5.467  regu_count=2.922  step=116.000  time=39285.160\n",
      "contro_loss=93.718  inner_mse=1.498  inner_mse_std=0.000  length=12.698  fc_count=7.665  dropo_count=3.280  regu_count=1.753  step=117.000  time=39406.590\n",
      "contro_loss=56.232  inner_mse=1.143  inner_mse_std=0.000  length=9.219  fc_count=5.799  dropo_count=2.368  regu_count=1.052  step=118.000  time=39418.797\n",
      "contro_loss=200.349  inner_mse=1.175  inner_mse_std=0.000  length=13.531  fc_count=3.479  dropo_count=1.421  regu_count=8.631  step=119.000  time=39423.912\n",
      "contro_loss=635.844  inner_mse=1.243  inner_mse_std=0.000  length=16.119  fc_count=2.088  dropo_count=1.253  regu_count=12.779  step=120.000  time=39429.277\n",
      "contro_loss=412.364  inner_mse=1.392  inner_mse_std=0.000  length=12.471  fc_count=3.253  dropo_count=1.552  regu_count=7.667  step=121.000  time=39450.726\n",
      "contro_loss=247.437  inner_mse=0.972  inner_mse_std=0.000  length=8.683  fc_count=3.152  dropo_count=0.931  regu_count=4.600  step=122.000  time=39533.064\n",
      "contro_loss=148.483  inner_mse=0.703  inner_mse_std=0.000  length=5.610  fc_count=2.291  dropo_count=0.559  regu_count=2.760  step=123.000  time=39698.266\n",
      "contro_loss=89.131  inner_mse=0.525  inner_mse_std=0.000  length=3.766  fc_count=1.775  dropo_count=0.335  regu_count=1.656  step=124.000  time=39759.030\n",
      "contro_loss=53.508  inner_mse=0.668  inner_mse_std=0.000  length=3.059  fc_count=1.465  dropo_count=0.601  regu_count=0.994  step=125.000  time=39811.768\n",
      "contro_loss=32.234  inner_mse=0.525  inner_mse_std=0.000  length=2.636  fc_count=1.679  dropo_count=0.361  regu_count=0.596  step=126.000  time=40222.235\n",
      "contro_loss=19.730  inner_mse=0.454  inner_mse_std=0.000  length=3.181  fc_count=2.607  dropo_count=0.216  regu_count=0.358  step=127.000  time=40268.135\n",
      "contro_loss=11.857  inner_mse=0.410  inner_mse_std=0.000  length=2.309  fc_count=1.964  dropo_count=0.130  regu_count=0.215  step=128.000  time=40629.844\n",
      "contro_loss=7.436  inner_mse=0.418  inner_mse_std=0.000  length=4.585  fc_count=1.979  dropo_count=0.078  regu_count=2.529  step=129.000  time=41208.014\n",
      "contro_loss=4.702  inner_mse=0.366  inner_mse_std=0.000  length=4.751  fc_count=3.187  dropo_count=0.047  regu_count=1.517  step=130.000  time=44737.658\n",
      "contro_loss=6.337  inner_mse=0.846  inner_mse_std=0.000  length=10.851  fc_count=1.912  dropo_count=1.228  regu_count=7.710  step=131.000  time=44826.473\n",
      "contro_loss=3.863  inner_mse=0.665  inner_mse_std=0.000  length=6.910  fc_count=1.547  dropo_count=0.737  regu_count=4.626  step=132.000  time=44858.706\n",
      "contro_loss=47.996  inner_mse=0.929  inner_mse_std=0.000  length=12.146  fc_count=0.928  dropo_count=2.042  regu_count=9.176  step=133.000  time=44889.617\n",
      "contro_loss=29.271  inner_mse=0.697  inner_mse_std=0.000  length=12.888  fc_count=6.157  dropo_count=1.225  regu_count=5.505  step=134.000  time=47945.776\n",
      "contro_loss=18.300  inner_mse=0.545  inner_mse_std=0.000  length=9.333  fc_count=4.094  dropo_count=0.735  regu_count=4.503  step=135.000  time=47987.063\n",
      "contro_loss=10.981  inner_mse=0.444  inner_mse_std=0.000  length=6.000  fc_count=2.857  dropo_count=0.441  regu_count=2.702  step=136.000  time=48037.447\n",
      "contro_loss=8.708  inner_mse=0.819  inner_mse_std=0.000  length=6.800  fc_count=3.714  dropo_count=1.465  regu_count=1.621  step=137.000  time=48560.978\n",
      "contro_loss=246.640  inner_mse=1.347  inner_mse_std=0.000  length=10.880  fc_count=3.028  dropo_count=6.879  regu_count=0.973  step=138.000  time=48781.906\n",
      "contro_loss=147.993  inner_mse=1.100  inner_mse_std=0.000  length=6.928  fc_count=2.217  dropo_count=4.127  regu_count=0.584  step=139.000  time=48787.466\n",
      "contro_loss=88.840  inner_mse=0.816  inner_mse_std=0.000  length=4.957  fc_count=1.730  dropo_count=2.476  regu_count=0.750  step=140.000  time=48797.679\n",
      "contro_loss=53.600  inner_mse=0.678  inner_mse_std=0.000  length=10.974  fc_count=1.438  dropo_count=2.286  regu_count=7.250  step=141.000  time=48877.472\n",
      "contro_loss=33.915  inner_mse=0.805  inner_mse_std=0.000  length=12.584  fc_count=1.263  dropo_count=3.771  regu_count=7.550  step=142.000  time=48980.681\n",
      "contro_loss=62.916  inner_mse=0.631  inner_mse_std=0.000  length=14.751  fc_count=7.958  dropo_count=2.263  regu_count=4.530  step=143.000  time=51822.466\n",
      "contro_loss=63.749  inner_mse=0.887  inner_mse_std=0.000  length=13.250  fc_count=8.775  dropo_count=1.758  regu_count=2.718  step=144.000  time=53930.594\n",
      "contro_loss=39.265  inner_mse=0.643  inner_mse_std=0.000  length=12.750  fc_count=9.665  dropo_count=1.055  regu_count=2.031  step=145.000  time=55210.542\n",
      "contro_loss=23.561  inner_mse=0.648  inner_mse_std=0.000  length=15.650  fc_count=5.799  dropo_count=0.633  regu_count=9.218  step=146.000  time=55234.174\n",
      "contro_loss=19.227  inner_mse=1.257  inner_mse_std=0.000  length=17.390  fc_count=9.479  dropo_count=2.380  regu_count=5.531  step=147.000  time=57764.836\n",
      "contro_loss=435.786  inner_mse=1.263  inner_mse_std=0.000  length=18.434  fc_count=5.688  dropo_count=1.428  regu_count=11.319  step=148.000  time=57770.018\n",
      "contro_loss=263.605  inner_mse=1.717  inner_mse_std=0.000  length=14.660  fc_count=5.813  dropo_count=2.057  regu_count=6.791  step=149.000  time=57864.173\n",
      "contro_loss=468.788  inner_mse=1.583  inner_mse_std=0.000  length=16.796  fc_count=3.488  dropo_count=2.034  regu_count=11.275  step=150.000  time=57870.029\n",
      "contro_loss=421.884  inner_mse=1.391  inner_mse_std=0.000  length=18.078  fc_count=2.093  dropo_count=1.220  regu_count=14.765  step=151.000  time=57875.081\n",
      "contro_loss=253.647  inner_mse=1.001  inner_mse_std=0.000  length=13.247  fc_count=3.656  dropo_count=0.732  regu_count=8.859  step=152.000  time=57893.157\n",
      "contro_loss=159.594  inner_mse=1.539  inner_mse_std=0.000  length=13.548  fc_count=7.393  dropo_count=0.439  regu_count=5.715  step=153.000  time=58160.371\n",
      "contro_loss=169.798  inner_mse=1.319  inner_mse_std=0.000  length=16.129  fc_count=4.436  dropo_count=0.264  regu_count=11.429  step=154.000  time=58165.512\n",
      "contro_loss=102.208  inner_mse=0.937  inner_mse_std=0.000  length=17.677  fc_count=3.862  dropo_count=0.158  regu_count=13.658  step=155.000  time=58182.950\n",
      "contro_loss=134.289  inner_mse=0.706  inner_mse_std=0.000  length=18.606  fc_count=3.117  dropo_count=0.095  regu_count=15.395  step=156.000  time=58221.218\n",
      "contro_loss=80.600  inner_mse=0.541  inner_mse_std=0.000  length=11.564  fc_count=2.270  dropo_count=0.057  regu_count=9.237  step=157.000  time=58282.086\n",
      "contro_loss=48.486  inner_mse=0.561  inner_mse_std=0.000  length=14.938  fc_count=1.362  dropo_count=0.034  regu_count=13.542  step=158.000  time=58305.024\n",
      "contro_loss=29.092  inner_mse=0.464  inner_mse_std=0.000  length=9.363  fc_count=1.217  dropo_count=0.020  regu_count=8.125  step=159.000  time=58471.564\n",
      "contro_loss=21.472  inner_mse=0.937  inner_mse_std=0.000  length=8.018  fc_count=2.330  dropo_count=0.412  regu_count=5.275  step=160.000  time=59639.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=169.157  inner_mse=1.360  inner_mse_std=0.000  length=10.011  fc_count=2.998  dropo_count=3.847  regu_count=3.165  step=161.000  time=60349.195\n",
      "contro_loss=101.494  inner_mse=1.091  inner_mse_std=0.000  length=6.806  fc_count=2.199  dropo_count=2.308  regu_count=2.299  step=162.000  time=60355.464\n",
      "contro_loss=60.897  inner_mse=0.845  inner_mse_std=0.000  length=4.484  fc_count=1.719  dropo_count=1.385  regu_count=1.379  step=163.000  time=60378.693\n",
      "contro_loss=36.562  inner_mse=0.617  inner_mse_std=0.000  length=3.090  fc_count=1.432  dropo_count=0.831  regu_count=0.828  step=164.000  time=60439.396\n",
      "contro_loss=22.622  inner_mse=0.557  inner_mse_std=0.000  length=4.254  fc_count=3.259  dropo_count=0.499  regu_count=0.497  step=165.000  time=60522.222\n",
      "contro_loss=13.602  inner_mse=0.498  inner_mse_std=0.000  length=2.953  fc_count=2.355  dropo_count=0.299  regu_count=0.298  step=166.000  time=60557.769\n",
      "contro_loss=13.569  inner_mse=0.543  inner_mse_std=0.000  length=9.772  fc_count=1.413  dropo_count=0.180  regu_count=8.179  step=167.000  time=60690.142\n",
      "contro_loss=8.622  inner_mse=0.591  inner_mse_std=0.000  length=13.863  fc_count=0.848  dropo_count=0.108  regu_count=12.907  step=168.000  time=60713.338\n",
      "contro_loss=5.177  inner_mse=0.489  inner_mse_std=0.000  length=8.718  fc_count=0.909  dropo_count=0.065  regu_count=7.744  step=169.000  time=60753.492\n",
      "contro_loss=13.376  inner_mse=0.920  inner_mse_std=0.000  length=8.431  fc_count=2.945  dropo_count=0.839  regu_count=4.647  step=170.000  time=63210.530\n",
      "contro_loss=103.584  inner_mse=0.698  inner_mse_std=0.000  length=13.058  fc_count=2.967  dropo_count=0.503  regu_count=9.588  step=171.000  time=63254.522\n",
      "contro_loss=62.355  inner_mse=1.159  inner_mse_std=0.000  length=9.035  fc_count=2.180  dropo_count=1.102  regu_count=5.753  step=172.000  time=63318.960\n",
      "contro_loss=38.794  inner_mse=1.321  inner_mse_std=0.000  length=8.621  fc_count=4.108  dropo_count=1.061  regu_count=3.452  step=173.000  time=63416.428\n",
      "contro_loss=23.314  inner_mse=1.115  inner_mse_std=0.000  length=5.973  fc_count=2.865  dropo_count=1.037  regu_count=2.071  step=174.000  time=63439.903\n",
      "contro_loss=14.111  inner_mse=1.039  inner_mse_std=0.000  length=11.584  fc_count=1.719  dropo_count=0.622  regu_count=9.243  step=175.000  time=63444.960\n",
      "contro_loss=1468.088  inner_mse=1.581  inner_mse_std=0.000  length=14.950  fc_count=1.031  dropo_count=1.973  regu_count=11.946  step=176.000  time=63451.283\n",
      "contro_loss=881.264  inner_mse=1.110  inner_mse_std=0.000  length=10.170  fc_count=1.019  dropo_count=1.184  regu_count=7.967  step=177.000  time=63461.486\n",
      "contro_loss=528.888  inner_mse=1.111  inner_mse_std=0.000  length=6.902  fc_count=1.011  dropo_count=1.110  regu_count=4.780  step=178.000  time=63471.956\n",
      "contro_loss=317.376  inner_mse=0.842  inner_mse_std=0.000  length=5.341  fc_count=1.807  dropo_count=0.666  regu_count=2.868  step=179.000  time=63528.540\n",
      "contro_loss=190.426  inner_mse=0.795  inner_mse_std=0.000  length=11.205  fc_count=1.084  dropo_count=0.400  regu_count=9.721  step=180.000  time=63551.660\n",
      "contro_loss=115.218  inner_mse=0.781  inner_mse_std=0.000  length=14.723  fc_count=0.650  dropo_count=0.240  regu_count=13.833  step=181.000  time=63575.259\n",
      "contro_loss=73.708  inner_mse=1.160  inner_mse_std=0.000  length=10.834  fc_count=1.190  dropo_count=1.344  regu_count=8.300  step=182.000  time=63649.805\n",
      "contro_loss=44.511  inner_mse=0.838  inner_mse_std=0.000  length=7.700  fc_count=1.914  dropo_count=0.806  regu_count=4.980  step=183.000  time=63670.746\n",
      "contro_loss=26.755  inner_mse=0.669  inner_mse_std=0.000  length=5.020  fc_count=1.548  dropo_count=0.484  regu_count=2.988  step=184.000  time=63700.524\n",
      "contro_loss=16.098  inner_mse=0.548  inner_mse_std=0.000  length=3.412  fc_count=1.329  dropo_count=0.290  regu_count=1.793  step=185.000  time=63740.048\n",
      "contro_loss=9.698  inner_mse=0.491  inner_mse_std=0.000  length=2.447  fc_count=1.197  dropo_count=0.174  regu_count=1.076  step=186.000  time=63769.831\n",
      "contro_loss=150.491  inner_mse=0.409  inner_mse_std=0.000  length=9.468  fc_count=1.518  dropo_count=0.105  regu_count=7.845  step=187.000  time=64885.954\n",
      "contro_loss=90.333  inner_mse=0.368  inner_mse_std=0.000  length=6.081  fc_count=1.311  dropo_count=0.063  regu_count=4.707  step=188.000  time=65182.778\n",
      "contro_loss=54.218  inner_mse=0.361  inner_mse_std=0.000  length=4.049  fc_count=1.187  dropo_count=0.038  regu_count=2.824  step=189.000  time=65337.639\n",
      "contro_loss=36.455  inner_mse=0.745  inner_mse_std=0.000  length=4.829  fc_count=1.112  dropo_count=2.023  regu_count=1.695  step=190.000  time=65545.924\n",
      "contro_loss=21.874  inner_mse=0.798  inner_mse_std=0.000  length=3.697  fc_count=1.067  dropo_count=1.614  regu_count=1.017  step=191.000  time=65585.188\n",
      "contro_loss=13.256  inner_mse=0.629  inner_mse_std=0.000  length=3.018  fc_count=1.040  dropo_count=0.968  regu_count=1.010  step=192.000  time=65645.938\n",
      "contro_loss=7.994  inner_mse=0.538  inner_mse_std=0.000  length=3.011  fc_count=1.024  dropo_count=0.581  regu_count=1.406  step=193.000  time=65676.166\n",
      "contro_loss=4.873  inner_mse=0.440  inner_mse_std=0.000  length=2.207  fc_count=1.015  dropo_count=0.349  regu_count=0.844  step=194.000  time=65736.713\n",
      "contro_loss=2.935  inner_mse=0.452  inner_mse_std=0.000  length=2.924  fc_count=2.209  dropo_count=0.209  regu_count=0.506  step=195.000  time=68037.554\n",
      "contro_loss=1.763  inner_mse=0.517  inner_mse_std=0.000  length=9.754  fc_count=1.325  dropo_count=0.125  regu_count=8.304  step=196.000  time=68169.384\n",
      "contro_loss=18.905  inner_mse=0.418  inner_mse_std=0.000  length=10.253  fc_count=3.995  dropo_count=0.075  regu_count=6.182  step=197.000  time=68654.613\n",
      "contro_loss=11.357  inner_mse=0.375  inner_mse_std=0.000  length=6.952  fc_count=2.797  dropo_count=0.045  regu_count=4.109  step=198.000  time=68900.240\n",
      "contro_loss=6.828  inner_mse=0.363  inner_mse_std=0.000  length=4.571  fc_count=2.078  dropo_count=0.027  regu_count=2.466  step=199.000  time=69258.341\n",
      "contro_loss=6.219  inner_mse=0.352  inner_mse_std=0.000  length=10.743  fc_count=2.847  dropo_count=0.016  regu_count=7.879  step=200.000  time=71023.286\n",
      "contro_loss=10.028  inner_mse=0.352  inner_mse_std=0.000  length=10.846  fc_count=6.108  dropo_count=0.010  regu_count=4.728  step=201.000  time=72262.749\n",
      "contro_loss=6.107  inner_mse=0.340  inner_mse_std=0.000  length=6.907  fc_count=4.065  dropo_count=0.006  regu_count=2.837  step=202.000  time=72857.142\n",
      "contro_loss=4.147  inner_mse=0.306  inner_mse_std=0.000  length=6.144  fc_count=4.039  dropo_count=0.004  regu_count=2.102  step=203.000  time=73557.254\n",
      "contro_loss=2.506  inner_mse=0.442  inner_mse_std=0.000  length=11.687  fc_count=2.423  dropo_count=0.002  regu_count=9.261  step=204.000  time=73685.697\n",
      "contro_loss=4.910  inner_mse=0.916  inner_mse_std=0.000  length=8.212  fc_count=1.854  dropo_count=0.801  regu_count=5.557  step=205.000  time=73862.838\n",
      "contro_loss=3.040  inner_mse=0.698  inner_mse_std=0.000  length=6.527  fc_count=1.912  dropo_count=0.481  regu_count=4.134  step=206.000  time=73910.262\n",
      "contro_loss=1.833  inner_mse=0.655  inner_mse_std=0.000  length=11.916  fc_count=1.147  dropo_count=0.288  regu_count=10.480  step=207.000  time=73933.462\n",
      "contro_loss=1.638  inner_mse=0.517  inner_mse_std=0.000  length=8.750  fc_count=2.288  dropo_count=0.173  regu_count=6.288  step=208.000  time=74328.077\n",
      "contro_loss=22.523  inner_mse=0.640  inner_mse_std=0.000  length=13.250  fc_count=1.373  dropo_count=0.104  regu_count=11.773  step=209.000  time=74352.108\n",
      "contro_loss=14.255  inner_mse=0.947  inner_mse_std=0.000  length=9.150  fc_count=1.224  dropo_count=0.862  regu_count=7.064  step=210.000  time=74410.163\n",
      "contro_loss=8.633  inner_mse=0.709  inner_mse_std=0.000  length=5.890  fc_count=1.134  dropo_count=0.517  regu_count=4.238  step=211.000  time=74507.139\n",
      "contro_loss=5.234  inner_mse=0.776  inner_mse_std=0.000  length=6.334  fc_count=3.081  dropo_count=0.710  regu_count=2.543  step=212.000  time=75426.100\n",
      "contro_loss=4.448  inner_mse=0.757  inner_mse_std=0.000  length=11.800  fc_count=1.848  dropo_count=0.426  regu_count=9.526  step=213.000  time=75449.356\n",
      "contro_loss=2.723  inner_mse=0.589  inner_mse_std=0.000  length=7.480  fc_count=1.509  dropo_count=0.256  regu_count=5.715  step=214.000  time=75477.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=62.326  inner_mse=0.490  inner_mse_std=0.000  length=12.488  fc_count=2.105  dropo_count=0.153  regu_count=10.229  step=215.000  time=75586.635\n",
      "contro_loss=41.152  inner_mse=1.277  inner_mse_std=0.000  length=15.493  fc_count=1.263  dropo_count=1.292  regu_count=12.938  step=216.000  time=75729.330\n",
      "contro_loss=26.232  inner_mse=1.290  inner_mse_std=0.000  length=17.296  fc_count=0.758  dropo_count=1.175  regu_count=15.363  step=217.000  time=75734.928\n",
      "contro_loss=17.470  inner_mse=0.957  inner_mse_std=0.000  length=13.577  fc_count=3.655  dropo_count=0.705  regu_count=9.218  step=218.000  time=75777.395\n",
      "contro_loss=10.503  inner_mse=0.803  inner_mse_std=0.000  length=16.146  fc_count=2.193  dropo_count=0.423  regu_count=13.531  step=219.000  time=75801.552\n",
      "contro_loss=6.303  inner_mse=0.771  inner_mse_std=0.000  length=17.688  fc_count=1.316  dropo_count=0.254  regu_count=16.118  step=220.000  time=75825.046\n",
      "contro_loss=5.238  inner_mse=0.612  inner_mse_std=0.000  length=12.613  fc_count=2.789  dropo_count=0.152  regu_count=9.671  step=221.000  time=76101.859\n",
      "contro_loss=411.418  inner_mse=1.210  inner_mse_std=0.000  length=15.568  fc_count=1.674  dropo_count=1.691  regu_count=12.203  step=222.000  time=76135.576\n",
      "contro_loss=247.207  inner_mse=1.309  inner_mse_std=0.000  length=10.141  fc_count=1.404  dropo_count=1.415  regu_count=7.322  step=223.000  time=76146.871\n",
      "contro_loss=148.330  inner_mse=1.141  inner_mse_std=0.000  length=6.884  fc_count=1.243  dropo_count=1.249  regu_count=4.393  step=224.000  time=76170.418\n",
      "contro_loss=959.168  inner_mse=1.629  inner_mse_std=0.000  length=11.731  fc_count=2.746  dropo_count=6.349  regu_count=2.636  step=225.000  time=76232.056\n",
      "contro_loss=4276.661  inner_mse=2.241  inner_mse_std=0.000  length=15.038  fc_count=1.647  dropo_count=6.210  regu_count=7.181  step=226.000  time=76240.611\n",
      "contro_loss=2577.316  inner_mse=2.074  inner_mse_std=0.000  length=11.023  fc_count=1.388  dropo_count=5.326  regu_count=4.309  step=227.000  time=76264.530\n",
      "contro_loss=1547.059  inner_mse=1.401  inner_mse_std=0.000  length=7.414  fc_count=1.233  dropo_count=3.195  regu_count=2.985  step=228.000  time=76272.386\n",
      "contro_loss=945.642  inner_mse=1.662  inner_mse_std=0.000  length=6.848  fc_count=1.540  dropo_count=3.517  regu_count=1.791  step=229.000  time=76301.451\n",
      "contro_loss=567.921  inner_mse=1.133  inner_mse_std=0.000  length=4.909  fc_count=1.724  dropo_count=2.110  regu_count=1.075  step=230.000  time=76317.383\n",
      "contro_loss=342.773  inner_mse=0.842  inner_mse_std=0.000  length=6.545  fc_count=4.634  dropo_count=1.266  regu_count=0.645  step=231.000  time=76478.788\n",
      "contro_loss=205.845  inner_mse=0.638  inner_mse_std=0.000  length=4.327  fc_count=3.181  dropo_count=0.760  regu_count=0.387  step=232.000  time=76574.919\n",
      "contro_loss=143.045  inner_mse=0.630  inner_mse_std=0.000  length=10.596  fc_count=1.908  dropo_count=0.456  regu_count=8.232  step=233.000  time=76598.977\n",
      "contro_loss=85.882  inner_mse=0.628  inner_mse_std=0.000  length=14.358  fc_count=1.145  dropo_count=0.274  regu_count=12.939  step=234.000  time=76622.732\n",
      "contro_loss=58.040  inner_mse=0.644  inner_mse_std=0.000  length=16.615  fc_count=0.687  dropo_count=0.164  regu_count=15.764  step=235.000  time=76646.070\n",
      "contro_loss=34.824  inner_mse=0.522  inner_mse_std=0.000  length=10.369  fc_count=0.812  dropo_count=0.098  regu_count=9.458  step=236.000  time=76680.637\n",
      "contro_loss=21.126  inner_mse=0.493  inner_mse_std=0.000  length=6.621  fc_count=0.887  dropo_count=0.059  regu_count=5.675  step=237.000  time=76710.790\n",
      "contro_loss=12.702  inner_mse=0.460  inner_mse_std=0.000  length=4.373  fc_count=0.932  dropo_count=0.035  regu_count=3.405  step=238.000  time=76808.641\n",
      "contro_loss=17.646  inner_mse=0.389  inner_mse_std=0.000  length=5.024  fc_count=2.959  dropo_count=0.021  regu_count=2.043  step=239.000  time=77485.545\n",
      "contro_loss=10.665  inner_mse=0.340  inner_mse_std=0.000  length=3.814  fc_count=2.576  dropo_count=0.013  regu_count=1.226  step=240.000  time=77907.539\n",
      "contro_loss=7.893  inner_mse=0.321  inner_mse_std=0.000  length=4.289  fc_count=3.545  dropo_count=0.008  regu_count=0.735  step=241.000  time=82203.311\n",
      "contro_loss=5.638  inner_mse=0.328  inner_mse_std=0.000  length=10.573  fc_count=2.527  dropo_count=0.005  regu_count=8.041  step=242.000  time=82521.855\n",
      "contro_loss=3.460  inner_mse=0.329  inner_mse_std=0.000  length=6.744  fc_count=1.916  dropo_count=0.003  regu_count=4.825  step=243.000  time=82659.046\n",
      "contro_loss=3.966  inner_mse=0.292  inner_mse_std=0.000  length=6.046  fc_count=2.750  dropo_count=0.002  regu_count=3.295  step=244.000  time=84129.051\n",
      "contro_loss=12.318  inner_mse=1.124  inner_mse_std=0.000  length=5.228  fc_count=2.450  dropo_count=0.801  regu_count=1.977  step=245.000  time=84668.766\n",
      "contro_loss=9.303  inner_mse=1.176  inner_mse_std=0.000  length=4.337  fc_count=1.870  dropo_count=1.281  regu_count=1.186  step=246.000  time=84677.155\n",
      "contro_loss=402.885  inner_mse=1.283  inner_mse_std=0.000  length=10.602  fc_count=1.122  dropo_count=0.768  regu_count=8.712  step=247.000  time=84682.642\n",
      "contro_loss=289.632  inner_mse=1.602  inner_mse_std=0.000  length=8.761  fc_count=1.073  dropo_count=2.461  regu_count=5.227  step=248.000  time=84691.813\n",
      "contro_loss=173.791  inner_mse=1.164  inner_mse_std=0.000  length=5.657  fc_count=1.044  dropo_count=1.477  regu_count=3.136  step=249.000  time=84698.903\n",
      "contro_loss=104.301  inner_mse=1.121  inner_mse_std=0.000  length=11.394  fc_count=0.626  dropo_count=0.886  regu_count=9.882  step=250.000  time=84704.278\n",
      "contro_loss=63.142  inner_mse=1.168  inner_mse_std=0.000  length=14.836  fc_count=0.376  dropo_count=0.932  regu_count=13.529  step=251.000  time=84710.418\n",
      "contro_loss=38.050  inner_mse=0.883  inner_mse_std=0.000  length=10.102  fc_count=1.425  dropo_count=0.559  regu_count=8.117  step=252.000  time=84721.272\n",
      "contro_loss=22.832  inner_mse=0.832  inner_mse_std=0.000  length=14.061  fc_count=0.855  dropo_count=0.335  regu_count=12.870  step=253.000  time=84745.525\n",
      "contro_loss=13.889  inner_mse=0.671  inner_mse_std=0.000  length=10.437  fc_count=2.513  dropo_count=0.201  regu_count=7.722  step=254.000  time=85465.191\n",
      "contro_loss=8.346  inner_mse=0.552  inner_mse_std=0.000  length=6.662  fc_count=1.908  dropo_count=0.121  regu_count=4.633  step=255.000  time=85500.133\n",
      "contro_loss=5.067  inner_mse=0.453  inner_mse_std=0.000  length=4.397  fc_count=1.545  dropo_count=0.072  regu_count=2.780  step=256.000  time=85529.948\n",
      "contro_loss=3.704  inner_mse=0.699  inner_mse_std=0.000  length=4.238  fc_count=1.327  dropo_count=1.243  regu_count=1.668  step=257.000  time=85721.913\n",
      "contro_loss=2.258  inner_mse=0.556  inner_mse_std=0.000  length=2.943  fc_count=1.196  dropo_count=0.746  regu_count=1.001  step=258.000  time=85905.658\n",
      "contro_loss=1.368  inner_mse=0.464  inner_mse_std=0.000  length=2.166  fc_count=1.118  dropo_count=0.448  regu_count=0.600  step=259.000  time=86001.232\n",
      "contro_loss=1.789  inner_mse=0.382  inner_mse_std=0.000  length=2.499  fc_count=1.871  dropo_count=0.269  regu_count=0.360  step=260.000  time=88531.589\n",
      "contro_loss=2.171  inner_mse=0.689  inner_mse_std=0.000  length=2.700  fc_count=1.922  dropo_count=0.561  regu_count=0.216  step=261.000  time=88756.147\n",
      "contro_loss=54.839  inner_mse=1.398  inner_mse_std=0.000  length=5.220  fc_count=1.553  dropo_count=3.537  regu_count=0.130  step=262.000  time=88810.853\n",
      "contro_loss=33.139  inner_mse=1.275  inner_mse_std=0.000  length=11.132  fc_count=0.932  dropo_count=2.122  regu_count=8.078  step=263.000  time=88815.791\n",
      "contro_loss=21.185  inner_mse=1.090  inner_mse_std=0.000  length=14.679  fc_count=0.559  dropo_count=1.273  regu_count=12.847  step=264.000  time=88820.739\n",
      "contro_loss=42.445  inner_mse=1.039  inner_mse_std=0.000  length=16.807  fc_count=0.336  dropo_count=0.764  regu_count=15.708  step=265.000  time=88825.641\n",
      "contro_loss=25.552  inner_mse=0.763  inner_mse_std=0.000  length=10.484  fc_count=0.601  dropo_count=0.458  regu_count=9.425  step=266.000  time=88850.218\n",
      "contro_loss=15.459  inner_mse=0.584  inner_mse_std=0.000  length=6.691  fc_count=0.761  dropo_count=0.275  regu_count=5.655  step=267.000  time=88879.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=9.316  inner_mse=0.468  inner_mse_std=0.000  length=4.414  fc_count=0.856  dropo_count=0.165  regu_count=3.393  step=268.000  time=88980.976\n",
      "contro_loss=5.605  inner_mse=0.415  inner_mse_std=0.000  length=3.049  fc_count=0.914  dropo_count=0.099  regu_count=2.036  step=269.000  time=89221.908\n",
      "contro_loss=4.943  inner_mse=0.348  inner_mse_std=0.000  length=3.429  fc_count=2.148  dropo_count=0.059  regu_count=1.221  step=270.000  time=89828.464\n",
      "contro_loss=4.258  inner_mse=0.702  inner_mse_std=0.000  length=5.258  fc_count=2.489  dropo_count=1.636  regu_count=1.133  step=271.000  time=92365.198\n",
      "contro_loss=3.959  inner_mse=0.578  inner_mse_std=0.000  length=5.555  fc_count=3.093  dropo_count=0.981  regu_count=1.480  step=272.000  time=92700.392\n",
      "contro_loss=2.396  inner_mse=0.482  inner_mse_std=0.000  length=3.733  fc_count=2.256  dropo_count=0.589  regu_count=0.888  step=273.000  time=92752.333\n",
      "contro_loss=168.703  inner_mse=0.795  inner_mse_std=0.000  length=10.240  fc_count=1.354  dropo_count=0.753  regu_count=8.133  step=274.000  time=92865.725\n",
      "contro_loss=101.223  inner_mse=0.626  inner_mse_std=0.000  length=6.544  fc_count=1.212  dropo_count=0.452  regu_count=4.880  step=275.000  time=92894.824\n",
      "contro_loss=218.960  inner_mse=0.509  inner_mse_std=0.000  length=11.926  fc_count=1.927  dropo_count=0.671  regu_count=9.328  step=276.000  time=93208.048\n",
      "contro_loss=171.847  inner_mse=1.096  inner_mse_std=0.000  length=9.556  fc_count=2.356  dropo_count=1.603  regu_count=5.597  step=277.000  time=93444.700\n",
      "contro_loss=104.727  inner_mse=0.927  inner_mse_std=0.000  length=10.533  fc_count=5.814  dropo_count=1.362  regu_count=3.358  step=278.000  time=93631.762\n",
      "contro_loss=63.095  inner_mse=0.965  inner_mse_std=0.000  length=7.520  fc_count=4.288  dropo_count=1.217  regu_count=2.015  step=279.000  time=94056.921\n",
      "contro_loss=37.857  inner_mse=0.699  inner_mse_std=0.000  length=5.312  fc_count=3.373  dropo_count=0.730  regu_count=1.209  step=280.000  time=94507.982\n",
      "contro_loss=22.824  inner_mse=0.540  inner_mse_std=0.000  length=3.587  fc_count=2.424  dropo_count=0.438  regu_count=0.725  step=281.000  time=94549.163\n",
      "contro_loss=13.703  inner_mse=0.460  inner_mse_std=0.000  length=2.552  fc_count=1.854  dropo_count=0.263  regu_count=0.435  step=282.000  time=94590.299\n",
      "contro_loss=8.844  inner_mse=0.423  inner_mse_std=0.000  length=3.531  fc_count=3.113  dropo_count=0.158  regu_count=0.261  step=283.000  time=95177.185\n",
      "contro_loss=5.315  inner_mse=0.423  inner_mse_std=0.000  length=2.519  fc_count=2.268  dropo_count=0.095  regu_count=0.157  step=284.000  time=95376.414\n",
      "contro_loss=3.231  inner_mse=0.411  inner_mse_std=0.000  length=1.911  fc_count=1.761  dropo_count=0.057  regu_count=0.094  step=285.000  time=95548.125\n",
      "contro_loss=1.939  inner_mse=0.363  inner_mse_std=0.000  length=1.547  fc_count=1.456  dropo_count=0.034  regu_count=0.056  step=286.000  time=95926.430\n",
      "contro_loss=2.919  inner_mse=0.794  inner_mse_std=0.000  length=2.128  fc_count=1.274  dropo_count=0.820  regu_count=0.034  step=287.000  time=96105.573\n",
      "contro_loss=1.759  inner_mse=0.743  inner_mse_std=0.000  length=9.277  fc_count=0.764  dropo_count=0.492  regu_count=8.020  step=288.000  time=96129.076\n",
      "contro_loss=1.089  inner_mse=0.743  inner_mse_std=0.000  length=13.566  fc_count=0.459  dropo_count=0.295  regu_count=12.812  step=289.000  time=96152.287\n",
      "contro_loss=0.734  inner_mse=0.588  inner_mse_std=0.000  length=8.540  fc_count=0.675  dropo_count=0.177  regu_count=7.687  step=290.000  time=96215.680\n",
      "contro_loss=0.448  inner_mse=0.558  inner_mse_std=0.000  length=5.524  fc_count=0.805  dropo_count=0.106  regu_count=4.612  step=291.000  time=96241.179\n",
      "contro_loss=97.281  inner_mse=1.214  inner_mse_std=0.000  length=5.714  fc_count=0.883  dropo_count=2.064  regu_count=2.767  step=292.000  time=96444.377\n",
      "contro_loss=58.371  inner_mse=0.961  inner_mse_std=0.000  length=3.829  fc_count=0.930  dropo_count=1.238  regu_count=1.660  step=293.000  time=96451.349\n",
      "contro_loss=79.119  inner_mse=0.702  inner_mse_std=0.000  length=10.297  fc_count=1.358  dropo_count=0.743  regu_count=8.196  step=294.000  time=96516.659\n",
      "contro_loss=47.530  inner_mse=0.550  inner_mse_std=0.000  length=7.378  fc_count=2.015  dropo_count=0.446  regu_count=4.918  step=295.000  time=96990.923\n",
      "contro_loss=28.687  inner_mse=0.479  inner_mse_std=0.000  length=5.227  fc_count=1.609  dropo_count=0.267  regu_count=3.351  step=296.000  time=97024.944\n",
      "contro_loss=26.914  inner_mse=1.032  inner_mse_std=0.000  length=5.536  fc_count=1.765  dropo_count=1.760  regu_count=2.010  step=297.000  time=97248.804\n",
      "contro_loss=16.256  inner_mse=0.777  inner_mse_std=0.000  length=4.122  fc_count=1.459  dropo_count=1.456  regu_count=1.206  step=298.000  time=97257.923\n"
     ]
    }
   ],
   "source": [
    "averages = MovingAverages()\n",
    "averages.smoothing['time'] = 0\n",
    "start_time = time.time()\n",
    "for step_idx in range(10000):\n",
    "    avg_mse = averages.metrics.get('inner_mse', 10)\n",
    "    if avg_mse > 1:\n",
    "        samples_count, max_epochs = 250000, 5\n",
    "    elif avg_mse > 0.5:\n",
    "        samples_count, max_epochs = 500000, 20\n",
    "    elif avg_mse > 0.3:\n",
    "        samples_count, max_epochs = -1, 50\n",
    "    else:\n",
    "        samples_count, max_epochs = -1, 500\n",
    "\n",
    "    architectures = controller.generate_architecture(controller_session)\n",
    "\n",
    "    # test architectures on a temporary graph\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default():\n",
    "            rewards = [\n",
    "                evaluate_architecture(\n",
    "                    step_idx, arch_idx, arch,\n",
    "                    max_epochs, samples_count\n",
    "                )\n",
    "                for arch_idx, arch in enumerate(architectures)\n",
    "            ]\n",
    "\n",
    "    loss = controller.learn_from_rewards(\n",
    "        controller_session, architectures, rewards\n",
    "    )\n",
    "\n",
    "    averages.update_all(\n",
    "        contro_loss=loss**2,\n",
    "        inner_mse=np.mean(rewards),\n",
    "        inner_mse_std=np.std(rewards),\n",
    "        length=np.mean(list(map(len, architectures))),\n",
    "        fc_count=np.mean([sum(1 for lt, _ in arch if lt <= 1) for arch in architectures]),\n",
    "        dropo_count=np.mean([sum(1 for lt, _ in arch if lt == 2) for arch in architectures]),\n",
    "        regu_count=np.mean([sum(1 for lt, _ in arch if lt == 3) for arch in architectures]),\n",
    "    )\n",
    "\n",
    "    if step_idx % 1 == 0:\n",
    "        snap = averages.snapshot(step=step_idx, time=time.time() - start_time)\n",
    "        print('  '.join(\n",
    "            '%s=%.3f' % metric for metric in snap.items()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
