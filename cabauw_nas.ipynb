{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we put together things from the nnet and neural architecture search notebooks, and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "from scipy.stats import probplot\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.utils import shuffle\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, GaussianNoise, Input, PReLU, Activation, Concatenate\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras import regularizers \n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerRNN:\n",
    "    def __init__(self, max_len, batch_size, type_size, arg_size,\n",
    "                 learning_rate=0.001, hidden_size=32, baseline_smoothing=0.95,\n",
    "                 variable_length_nnet=True):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.unroll_by = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.type_size = type_size + 1 * variable_length_nnet  # 0 is for end-of-network token\n",
    "        self.arg_size = arg_size\n",
    "        self.baseline_smoothing = baseline_smoothing\n",
    "        self.variable_length_nnet = variable_length_nnet\n",
    "\n",
    "    def build(self):\n",
    "        # reward for the architectures\n",
    "        self.architecture_reward = tf.placeholder(tf.float32, [self.batch_size])\n",
    "        \n",
    "        # exponential moving average of the reward\n",
    "        self.last_average_reward = tf.reduce_mean(self.architecture_reward)\n",
    "        self.reward_ema = tf.train.ExponentialMovingAverage(self.baseline_smoothing)\n",
    "        self.update_reward_ema = self.reward_ema.apply([self.last_average_reward])\n",
    "\n",
    "        rnn_input = tf.random_normal([self.batch_size, self.type_size + self.arg_size])\n",
    "        rnn = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
    "        state = tf.random_normal([self.batch_size, rnn.state_size])\n",
    "\n",
    "        # weight matrices to transform from rnn output to layer type and discrete arg\n",
    "        rnn_to_layer_type_weight = tf.Variable(tf.random_normal([rnn.output_size + 1, self.type_size]))\n",
    "        rnn_to_layer_type_gradient = []\n",
    "        rnn_to_layer_arg_weight = tf.Variable(tf.random_normal([rnn.output_size + 1, self.arg_size]))\n",
    "        rnn_to_layer_arg_gradient = []\n",
    "\n",
    "        # layer_probs contains the output from the network, namely the probabilities\n",
    "        # of type and argument for every layer of every network\n",
    "        self.layer_probs = []\n",
    "\n",
    "        # layer_indicators contains one-hot indicators of type and argument\n",
    "        # for every layer of every network.\n",
    "        # used to select which action is used to compute the gradient.\n",
    "        # fixed, must be set before updating the weights\n",
    "        self.layer_indicators = []\n",
    "\n",
    "        losses = []\n",
    "        for i in range(self.unroll_by):\n",
    "            # run rnn cell\n",
    "            output, state = rnn(rnn_input, state)\n",
    "\n",
    "            if i == 0:  # rnn variables are only initialized now\n",
    "                rnn_params = rnn.trainable_variables + rnn.trainable_weights\n",
    "                rnn_gradients = [[] for _ in range(len(rnn_params))]\n",
    "\n",
    "            # compute output probabilites\n",
    "            output = tf.concat([output, tf.ones((output.shape[0], 1))], axis=1)\n",
    "            layer_type = tf.nn.relu(tf.matmul(output, rnn_to_layer_type_weight))\n",
    "            layer_arg = tf.nn.relu(tf.matmul(output, rnn_to_layer_arg_weight))\n",
    "            rnn_input = tf.concat([layer_type, layer_arg], axis=1)\n",
    "\n",
    "            layer_type_probs = tf.nn.softmax(layer_type)\n",
    "            layer_arg_probs = tf.nn.softmax(layer_arg)\n",
    "\n",
    "            chosen_layer_type = tf.placeholder(tf.int32, self.batch_size)\n",
    "            chosen_layer_arg = tf.placeholder(tf.int32, self.batch_size)\n",
    "\n",
    "            self.layer_probs.append((layer_type_probs, layer_arg_probs))\n",
    "            self.layer_indicators.append((chosen_layer_type, chosen_layer_arg))\n",
    "\n",
    "            # aggregate gradients\n",
    "            baseline = self.reward_ema.average(self.last_average_reward)\n",
    "            prob = (self.last_average_reward - baseline) * (\n",
    "                tf.reduce_sum(\n",
    "                    tf.one_hot(\n",
    "                        chosen_layer_type, depth=self.type_size\n",
    "                    ) * tf.log(layer_type_probs + 1e-12),\n",
    "                    axis=1\n",
    "                ) + tf.reduce_sum(\n",
    "                    tf.one_hot(\n",
    "                        chosen_layer_arg, depth=self.arg_size\n",
    "                    ) * tf.log(layer_arg_probs + 1e-12),\n",
    "                    axis=1\n",
    "                )\n",
    "            )\n",
    "            losses.append(prob)\n",
    "\n",
    "            rnn_to_layer_arg_gradient.append(tf.gradients(prob, rnn_to_layer_arg_weight)[0])\n",
    "            rnn_to_layer_type_gradient.append(tf.gradients(prob, rnn_to_layer_type_weight)[0])\n",
    "            for param, grad in zip(rnn_params, rnn_gradients):\n",
    "                grad.append(tf.gradients(prob, param)[0])\n",
    "\n",
    "        self.loss = tf.reduce_mean(losses)\n",
    "\n",
    "        def sanitize_gradient(grads):\n",
    "            avg = sum(grads) / len(grads)\n",
    "            return tf.clip_by_norm(avg, 1.0)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimize = optimizer.apply_gradients([\n",
    "            (sanitize_gradient(grad), param)\n",
    "            for param, grad in zip(rnn_params, rnn_gradients)\n",
    "        ] + [\n",
    "            (sanitize_gradient(rnn_to_layer_type_gradient), rnn_to_layer_type_weight),\n",
    "            (sanitize_gradient(rnn_to_layer_arg_gradient), rnn_to_layer_arg_weight),\n",
    "        ])\n",
    "\n",
    "    def generate_architecture(self, session):\n",
    "        layers = session.run(self.layer_probs)\n",
    "        networks = [[] for _ in range(self.batch_size)]\n",
    "        for (ltype, larg) in layers:\n",
    "            for i, (nnet, type_prob, arg_prob) in enumerate(zip(networks, ltype, larg)):\n",
    "                if self.variable_length_nnet and nnet and nnet[-1][0] == 0:\n",
    "                    continue\n",
    "\n",
    "                assert all(np.isfinite(type_prob))\n",
    "                assert all(np.isfinite(arg_prob))\n",
    "\n",
    "                layer_type = np.random.choice(len(type_prob), p=type_prob)\n",
    "                layer_arg = np.random.choice(len(arg_prob), p=arg_prob)\n",
    "\n",
    "                nnet.append((layer_type, layer_arg))\n",
    "\n",
    "        return networks\n",
    "\n",
    "    def learn_from_rewards(self, sess, networks, rewards):\n",
    "        assert len(rewards) == self.batch_size\n",
    "\n",
    "        # set the indicator variables, telling which action was chosen\n",
    "        feed_dict = {ind: []\n",
    "                     for layer_ind in self.layer_indicators\n",
    "                     for ind in layer_ind}\n",
    "\n",
    "        for nnet in networks:\n",
    "            # pad network if shorter than expected\n",
    "            # we set the indicators to -1, so that all one hot will be 0\n",
    "            # thus not contributing to the gradient\n",
    "            if len(nnet) < self.unroll_by:\n",
    "                nnet = nnet + [(-1, -1)] * (self.unroll_by - len(nnet))\n",
    "\n",
    "            assert len(nnet) == self.unroll_by\n",
    "            for (itype, iarg), (ntype, narg) in zip(self.layer_indicators, nnet):\n",
    "                feed_dict[itype].append(ntype)\n",
    "                feed_dict[iarg].append(narg)\n",
    "\n",
    "        feed_dict[self.architecture_reward] = rewards\n",
    "        loss, _, _ = sess.run([self.loss, self.update_reward_ema, self.optimize],\n",
    "                              feed_dict=feed_dict)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class MovingAverages:\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "        self.smoothing = {}\n",
    "        self.snapshots = []\n",
    "    \n",
    "    def update(self, metric, value, smoothing=None):\n",
    "        if smoothing is None:\n",
    "            smoothing = self.smoothing.get(metric, 0.6)\n",
    "        self.smoothing[metric] = smoothing\n",
    "        \n",
    "        # can pass None to update smoothing\n",
    "        if value is not None:\n",
    "            self.metrics[metric] = (\n",
    "                smoothing * self.metrics.get(metric, value)\n",
    "                + (1 - smoothing) * value\n",
    "            )\n",
    "        return self.metrics[metric]\n",
    "    \n",
    "    def update_all(self, **metrics):\n",
    "        for metric, value in metrics.items():\n",
    "            self.update(metric, value)\n",
    "        return [self.metrics[m] for m in metrics]\n",
    "    \n",
    "    def snapshot(self, **meta):\n",
    "        snap = dict(self.metrics)\n",
    "        snap.update(meta)\n",
    "        self.snapshots.append(snap)\n",
    "        return snap\n",
    "\n",
    "    \n",
    "def make_index(dtimes, interval):\n",
    "    # returns a tuple index_above, index_below\n",
    "    # index_above[i] is the largest i\n",
    "    # such that dtimes[index_above[i]] - dtimes[i] < interval\n",
    "    # index_below[i] is the smallest i\n",
    "    # such that dtimes[i] - dtimes[index_below[i]] < interval\n",
    "    # dtimes must be already sorted!\n",
    "    index_below, index_above = np.zeros(\n",
    "        (2, len(dtimes)), dtype=np.int\n",
    "    ) - 1\n",
    "    \n",
    "    for i, x in enumerate(dtimes):\n",
    "        j = index_below[i - 1] if i > 0 else 0\n",
    "        while x - dtimes[j] > interval:\n",
    "            j += 1\n",
    "\n",
    "        index_below[i] = j\n",
    "        index_above[j] = i\n",
    "\n",
    "    last_above = index_above[0]\n",
    "    for i in range(len(dtimes)):\n",
    "        if index_above[i] < 0:\n",
    "            index_above[i] = last_above\n",
    "        else:\n",
    "            last_above = index_above[i]\n",
    "    \n",
    "    return index_above, index_below\n",
    "\n",
    "\n",
    "def compute_trend(df, columns, interval=3600):\n",
    "    df = df.sort_values('datetime')\n",
    "    for z in df.z.unique():  \n",
    "        this_level = df[df.z == z]\n",
    "        index_above, index_below = make_index(this_level.datetime.values, interval)\n",
    "\n",
    "        for col in columns:\n",
    "            val_above = this_level[col].values\n",
    "            val_below = this_level.iloc[index_below][col].values\n",
    "\n",
    "            time_above = this_level.datetime.values\n",
    "            time_below = this_level.iloc[index_below].datetime.values\n",
    "\n",
    "            trend = 3600 * (val_above - val_below) / (time_above - time_below)\n",
    "\n",
    "            df.loc[df.z == z, col + '_trend'] = trend\n",
    "\n",
    "    return df, [col + '_trend' for col in columns]\n",
    "\n",
    "\n",
    "def get_features(df, use_trend, feature_level):\n",
    "    wind_temp_levels = df.pivot_table(\n",
    "        values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "    ).reset_index()\n",
    "    wind_temp_levels.columns = [\n",
    "        '%s_%d' % (a, b) if b else a\n",
    "        for a, b in wind_temp_levels.columns.values\n",
    "    ]\n",
    "\n",
    "    df = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "\n",
    "    feature_sets = [\n",
    "        [\n",
    "            'z', 'wind', 'temp', 'soil_temp',\n",
    "            'wind_10', 'wind_20', 'wind_40',\n",
    "            'temp_10', 'temp_20', 'temp_40',\n",
    "        ],\n",
    "        ['soilheat'],\n",
    "        ['netrad'],\n",
    "        ['rain', 'dewpoint'],\n",
    "        ['H', 'LE'],\n",
    "    ]\n",
    "\n",
    "    features = [\n",
    "        f for fset in feature_sets[:feature_level]\n",
    "        for f in fset\n",
    "    ]\n",
    "    \n",
    "    if use_trend:\n",
    "        df, added_cols = compute_trend(df, [\n",
    "            f for f in features if f != 'z'\n",
    "        ])\n",
    "        features.extend(added_cols)\n",
    "\n",
    "    return df, features\n",
    "\n",
    "\n",
    "def get_train_test_data(df, features, target, samples_count, n_months=12):\n",
    "    df = df.dropna()\n",
    "\n",
    "    # get random test months\n",
    "    test_ds = np.random.choice(df.ds.unique(), n_months, replace=False)\n",
    "    test_mask = df.ds.isin(test_ds)\n",
    "    \n",
    "    train_df, test_df = df.loc[~test_mask], df.loc[test_mask]\n",
    "    if samples_count > 0:\n",
    "        # maintain proportion of train/test samples\n",
    "        test_size = int(samples_count * len(test_df) / len(train_df))\n",
    "        train_df = train_df.sample(samples_count)\n",
    "        test_df = test_df.sample(test_size)\n",
    "    \n",
    "    train_x, train_y = train_df[features], train_df[target]\n",
    "    test_x, test_y = test_df[features], test_df[target]\n",
    "\n",
    "    mean_x, mean_y = train_x.mean(), train_y.mean()\n",
    "    std_x, std_y = train_x.std(), train_y.std()\n",
    "\n",
    "    train_x = (train_x - mean_x) /  std_x\n",
    "    test_x = (test_x - mean_x) / std_x\n",
    "    \n",
    "    assert np.all(np.isfinite(train_x))\n",
    "    \n",
    "    train_y = (train_y - mean_y) / std_y\n",
    "    test_y = (test_y - mean_y) / std_y\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y\n",
    "    \n",
    "\n",
    "def compute_denormalized_mse(std_y):\n",
    "    def denormalized_mse(y_true, y_pred):\n",
    "        # model is trained with normalized data, but we want\n",
    "        # mse on not normalized data to compare with MOST\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "        return mse * std_y**2\n",
    "    return denormalized_mse\n",
    "\n",
    "\n",
    "def build_model(input_shape, architecture, std_y=1):\n",
    "    # build model with fixed length architecture\n",
    "    layers = [Input(shape=(input_shape,))]\n",
    "\n",
    "    for i, (layer_type, layer_arg) in enumerate(architecture):\n",
    "        if i % 2 == 0:\n",
    "            num = 2**layer_arg\n",
    "            layers.append(PReLU()(\n",
    "                    Dense(num, kernel_initializer=VarianceScaling(2, 'fan_in'))(\n",
    "                        layers[-1]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            pkeep = (layer_arg + 1) / 10  # from 0.1 to 1\n",
    "            if pkeep < 1:\n",
    "                layers.append(Dropout(pkeep)(layers[-1]))\n",
    "\n",
    "    layers.append(Dense(1)(layers[-1]))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model = Model(inputs=layers[0], outputs=layers[-1])\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=[compute_denormalized_mse(std_y)])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_vlen(input_shape, architecture, std_y=1):\n",
    "    # build model with variable length architecture\n",
    "    layers = [Input(shape=(input_shape,))]\n",
    "\n",
    "    for layer_type, layer_arg in architecture:\n",
    "        if layer_type == 0 or layer_type == 1:\n",
    "            num = 2**layer_arg\n",
    "            layers.append(PReLU()(\n",
    "                    Dense(num, kernel_initializer=VarianceScaling(2, 'fan_in'))(\n",
    "                        layers[-1]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        elif layer_type == 2:\n",
    "            pkeep = (layer_arg + 1) / 11  # from 1/11 to 10/11\n",
    "            layers.append(Dropout(pkeep)(layers[-1]))\n",
    "        else:\n",
    "            raise ValueError('layer type from 0 to 2')\n",
    "\n",
    "    layers.append(Dense(1)(layers[-1]))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model = Model(inputs=layers[0], outputs=layers[-1])\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=[compute_denormalized_mse(std_y)])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_architecture(step, arch_idx, architecture, max_epochs, samples_count):\n",
    "    train_x, train_y, test_x, test_y, _, std_y = get_train_test_data(\n",
    "        ddf, features, 'phi_m', samples_count, n_months=12\n",
    "    )\n",
    "    \n",
    "    #K.clear_session()  # https://stackoverflow.com/q/35114376/521776\n",
    "    model = build_model(train_x.shape[1], architecture, std_y=std_y)\n",
    "\n",
    "    logdir = 'dev/logs/nas-2/step-%d-arch-%d' % (step, arch_idx)\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(factor=0.1, verbose=0, min_lr=1e-6, patience=10, monitor='loss'),\n",
    "        TensorBoard(logdir, write_graph=True, write_grads=True, histogram_freq=0),\n",
    "        EarlyStopping(min_delta=0.001, patience=25),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_x, train_y,\n",
    "        batch_size=1024,\n",
    "        epochs=max_epochs,\n",
    "        verbose=0,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(test_x, test_y)\n",
    "    )\n",
    "\n",
    "    best = min(hist.history['val_denormalized_mse'])\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:221: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    dframe_path = 'data/cabauw/processed-full-log.csv.gz'\n",
    "    df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[df.ds != 201603]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "ddf, features = get_features(df, use_trend=True, feature_level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = ControllerRNN(\n",
    "    hidden_size=64,\n",
    "    max_len=16,\n",
    "    batch_size=1,\n",
    "    type_size=1,\n",
    "    arg_size=10,\n",
    "    learning_rate=0.001,\n",
    "    baseline_smoothing=0.99,\n",
    "    variable_length_nnet=False\n",
    ")\n",
    "\n",
    "hist = []\n",
    "controller_graph = tf.Graph()\n",
    "with controller_graph.as_default():\n",
    "    controller.build()\n",
    "    controller_session = tf.Session(graph=controller_graph)\n",
    "    controller_session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "np.random.seed(4312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=8.213  inner_mse=1.536  step=0.000  time=29.399\n",
      "[[(0, 0), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]]\n",
      "contro_loss=19.503  inner_mse=1.872  step=1.000  time=374.429\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=51.795  inner_mse=2.001  step=2.000  time=553.970\n",
      "[[(0, 4), (0, 4), (0, 4), (0, 4), (0, 1), (0, 1), (0, 1), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=45.309  inner_mse=1.905  step=3.000  time=624.190\n",
      "[[(0, 9), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=27.561  inner_mse=1.942  step=4.000  time=651.273\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 3), (0, 1), (0, 1)]]\n",
      "contro_loss=19.982  inner_mse=1.478  step=5.000  time=719.394\n",
      "[[(0, 2), (0, 2), (0, 2), (0, 2), (0, 6), (0, 6), (0, 2), (0, 2), (0, 2), (0, 2), (0, 6), (0, 2), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=82.268  inner_mse=1.758  step=6.000  time=1034.757\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 6), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=182.544  inner_mse=1.951  step=7.000  time=1426.187\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=110.517  inner_mse=2.007  step=8.000  time=1454.391\n",
      "[[(0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=66.482  inner_mse=1.778  step=9.000  time=1568.053\n",
      "[[(0, 6), (0, 5), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 6), (0, 1), (0, 1), (0, 6), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=40.161  inner_mse=2.101  step=10.000  time=1595.559\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=53.116  inner_mse=1.988  step=11.000  time=1623.641\n",
      "[[(0, 3), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 6), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=80.016  inner_mse=2.010  step=12.000  time=1652.191\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=48.010  inner_mse=1.796  step=13.000  time=1680.089\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=120.098  inner_mse=1.903  step=14.000  time=1707.897\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=72.230  inner_mse=1.645  step=15.000  time=1795.608\n",
      "[[(0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=127.054  inner_mse=1.795  step=16.000  time=1879.499\n",
      "[[(0, 0), (0, 0), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=140.297  inner_mse=1.904  step=17.000  time=1911.942\n",
      "[[(0, 3), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]]\n",
      "contro_loss=91.473  inner_mse=1.853  step=18.000  time=1941.673\n",
      "[[(0, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 1), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]]\n",
      "contro_loss=55.645  inner_mse=2.011  step=19.000  time=2047.648\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=36.777  inner_mse=1.591  step=20.000  time=2080.053\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]]\n",
      "contro_loss=84.727  inner_mse=1.830  step=21.000  time=2213.366\n",
      "[[(0, 9), (0, 9), (0, 6), (0, 6), (0, 6), (0, 1), (0, 1), (0, 1), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=50.862  inner_mse=2.049  step=22.000  time=2559.835\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=30.517  inner_mse=1.721  step=23.000  time=2587.178\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=69.499  inner_mse=1.948  step=24.000  time=2658.751\n",
      "[[(0, 5), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=101.357  inner_mse=2.074  step=25.000  time=2934.687\n",
      "[[(0, 5), (0, 5), (0, 5), (0, 2), (0, 2), (0, 2), (0, 8), (0, 8), (0, 8), (0, 7), (0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=72.420  inner_mse=2.181  step=26.000  time=3107.439\n",
      "[[(0, 6), (0, 2), (0, 2), (0, 2), (0, 2), (0, 8), (0, 8), (0, 8), (0, 2), (0, 2), (0, 8), (0, 2), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=43.483  inner_mse=2.212  step=27.000  time=3456.023\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=26.127  inner_mse=1.789  step=28.000  time=3485.798\n",
      "[[(0, 4), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 3), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=28.402  inner_mse=1.429  step=29.000  time=3746.893\n",
      "[[(0, 5), (0, 9), (0, 3), (0, 1), (0, 6), (0, 6), (0, 9), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 1), (0, 9)]]\n",
      "contro_loss=48.671  inner_mse=1.731  step=30.000  time=3903.179\n",
      "[[(0, 8), (0, 8), (0, 7), (0, 8), (0, 6), (0, 8), (0, 6), (0, 6), (0, 8), (0, 6), (0, 6), (0, 7), (0, 7), (0, 7), (0, 3), (0, 3)]]\n",
      "contro_loss=32.973  inner_mse=1.791  step=31.000  time=3943.954\n",
      "[[(0, 4), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 6), (0, 6), (0, 1), (0, 1), (0, 9), (0, 1), (0, 1), (0, 1), (0, 6)]]\n",
      "contro_loss=61.690  inner_mse=1.986  step=32.000  time=4050.175\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=46.319  inner_mse=1.609  step=33.000  time=4178.008\n",
      "[[(0, 7), (0, 7), (0, 7), (0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 1), (0, 9), (0, 1), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=45.795  inner_mse=1.760  step=34.000  time=4596.799\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=27.686  inner_mse=2.066  step=35.000  time=4924.792\n",
      "[[(0, 6), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=23.557  inner_mse=2.073  step=36.000  time=5282.434\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=16.564  inner_mse=2.288  step=37.000  time=5620.524\n",
      "[[(0, 6), (0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=47.057  inner_mse=2.235  step=38.000  time=5932.891\n",
      "[[(0, 2), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=72.995  inner_mse=2.275  step=39.000  time=6349.440\n",
      "[[(0, 2), (0, 7), (0, 7), (0, 7), (0, 7), (0, 9), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=43.797  inner_mse=1.882  step=40.000  time=6382.141\n",
      "[[(0, 5), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=27.323  inner_mse=1.912  step=41.000  time=6641.739\n",
      "[[(0, 3), (0, 3), (0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=16.599  inner_mse=2.177  step=42.000  time=6822.395\n",
      "[[(0, 5), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=14.530  inner_mse=1.604  step=43.000  time=7406.434\n",
      "[[(0, 7), (0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=72.492  inner_mse=1.903  step=44.000  time=7541.840\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 9), (0, 2), (0, 2), (0, 2), (0, 9), (0, 2), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=58.618  inner_mse=1.515  step=45.000  time=7774.106\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 9), (0, 1), (0, 9), (0, 9), (0, 1), (0, 1)]]\n",
      "contro_loss=35.747  inner_mse=1.811  step=46.000  time=7807.169\n",
      "[[(0, 5), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=262.260  inner_mse=2.024  step=47.000  time=7855.542\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=157.872  inner_mse=1.721  step=48.000  time=8244.957\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=305.543  inner_mse=2.028  step=49.000  time=8339.339\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 3), (0, 3), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6)]]\n",
      "contro_loss=262.070  inner_mse=2.192  step=50.000  time=8683.248\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=172.881  inner_mse=2.451  step=51.000  time=8711.615\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=180.506  inner_mse=2.477  step=52.000  time=8887.169\n",
      "[[(0, 2), (0, 1), (0, 1), (0, 8), (0, 1), (0, 8), (0, 1), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=133.230  inner_mse=2.493  step=53.000  time=9331.899\n",
      "[[(0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=148.166  inner_mse=2.513  step=54.000  time=9672.257\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=95.688  inner_mse=2.200  step=55.000  time=10214.440\n",
      "[[(0, 2), (0, 2), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=281.283  inner_mse=1.441  step=56.000  time=10880.732\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=285.886  inner_mse=1.010  step=57.000  time=11624.063\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=171.987  inner_mse=1.412  step=58.000  time=11925.789\n",
      "[[(0, 2), (0, 9), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=225.827  inner_mse=1.807  step=59.000  time=11963.484\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 6), (0, 1), (0, 1), (0, 6), (0, 1)]]\n",
      "contro_loss=136.462  inner_mse=1.405  step=60.000  time=12413.673\n",
      "[[(0, 2), (0, 2), (0, 2), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 1), (0, 9)]]\n",
      "contro_loss=82.039  inner_mse=1.692  step=61.000  time=12442.393\n",
      "[[(0, 3), (0, 3), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=125.117  inner_mse=2.019  step=62.000  time=12699.554\n",
      "[[(0, 9), (0, 9), (0, 1), (0, 1), (0, 1), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=76.254  inner_mse=2.089  step=63.000  time=13040.836\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=45.762  inner_mse=2.133  step=64.000  time=13383.216\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=77.221  inner_mse=2.148  step=65.000  time=13726.442\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=46.576  inner_mse=1.629  step=66.000  time=13919.610\n",
      "[[(0, 2), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 1), (0, 9), (0, 1), (0, 9)]]\n",
      "contro_loss=111.669  inner_mse=1.899  step=67.000  time=14177.654\n",
      "[[(0, 3), (0, 3), (0, 3), (0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=67.558  inner_mse=2.054  step=68.000  time=14518.833\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=40.919  inner_mse=1.380  step=69.000  time=15157.899\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=24.660  inner_mse=1.690  step=70.000  time=15472.996\n",
      "[[(0, 6), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=22.165  inner_mse=1.271  step=71.000  time=15810.127\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=30.013  inner_mse=1.521  step=72.000  time=15841.549\n",
      "[[(0, 4), (0, 4), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=139.592  inner_mse=1.038  step=73.000  time=16594.480\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 8)]]\n",
      "contro_loss=89.072  inner_mse=1.489  step=74.000  time=16885.540\n",
      "[[(0, 6), (0, 6), (0, 3), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=152.604  inner_mse=1.834  step=75.000  time=17229.259\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=265.396  inner_mse=1.235  step=76.000  time=17895.839\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=159.267  inner_mse=0.897  step=77.000  time=18541.107\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=225.946  inner_mse=1.444  step=78.000  time=18632.274\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=199.791  inner_mse=1.735  step=79.000  time=18933.833\n",
      "[[(0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=121.400  inner_mse=1.891  step=80.000  time=19153.304\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=73.684  inner_mse=2.012  step=81.000  time=19653.082\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=109.634  inner_mse=1.403  step=82.000  time=20293.257\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=127.242  inner_mse=1.746  step=83.000  time=20599.490\n",
      "[[(0, 5), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=76.679  inner_mse=1.672  step=84.000  time=20649.857\n",
      "[[(0, 7), (0, 1), (0, 1), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=48.332  inner_mse=1.427  step=85.000  time=21099.995\n",
      "[[(0, 4), (0, 4), (0, 1), (0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=107.551  inner_mse=0.992  step=86.000  time=21746.071\n",
      "[[(0, 5), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=66.596  inner_mse=0.909  step=87.000  time=23911.001\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=60.020  inner_mse=1.497  step=88.000  time=23998.768\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1)]]\n",
      "contro_loss=77.398  inner_mse=1.773  step=89.000  time=24302.109\n",
      "[[(0, 3), (0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=46.833  inner_mse=1.179  step=90.000  time=24862.028\n",
      "[[(0, 7), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=121.842  inner_mse=1.634  step=91.000  time=25102.841\n",
      "[[(0, 4), (0, 6), (0, 6), (0, 6), (0, 6), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=73.395  inner_mse=1.129  step=92.000  time=25756.225\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=166.163  inner_mse=1.616  step=93.000  time=26100.044\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=102.610  inner_mse=1.086  step=94.000  time=26845.596\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=61.986  inner_mse=0.994  step=95.000  time=27447.050\n",
      "[[(0, 4), (0, 4), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=46.624  inner_mse=0.757  step=96.000  time=29457.695\n",
      "[[(0, 5), (0, 2), (0, 9), (0, 9), (0, 8), (0, 9), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=28.622  inner_mse=0.639  step=97.000  time=31617.409\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=17.444  inner_mse=0.768  step=98.000  time=33416.908\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=55.663  inner_mse=0.624  step=99.000  time=35965.294\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=33.398  inner_mse=0.498  step=100.000  time=38918.025\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=21.142  inner_mse=0.413  step=101.000  time=44372.671\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=12.685  inner_mse=0.804  step=102.000  time=48345.390\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=8.050  inner_mse=0.713  step=103.000  time=50901.198\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=5.023  inner_mse=0.808  step=104.000  time=53695.018\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=3.592  inner_mse=0.612  step=105.000  time=55885.827\n",
      "[[(0, 6), (0, 6), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.157  inner_mse=0.925  step=106.000  time=58105.837\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=31.846  inner_mse=0.965  step=107.000  time=60300.640\n",
      "[[(0, 5), (0, 5), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=19.119  inner_mse=1.056  step=108.000  time=62908.735\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=11.751  inner_mse=0.965  step=109.000  time=63500.651\n",
      "[[(0, 7), (0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=7.102  inner_mse=0.684  step=110.000  time=66054.210\n",
      "[[(0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=88.904  inner_mse=1.358  step=111.000  time=67403.556\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8)]]\n",
      "contro_loss=147.512  inner_mse=0.960  step=112.000  time=67952.106\n",
      "[[(0, 1), (0, 9), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=88.548  inner_mse=1.013  step=113.000  time=70558.402\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=53.373  inner_mse=0.727  step=114.000  time=71204.493\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=32.150  inner_mse=0.932  step=115.000  time=73722.115\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=19.290  inner_mse=1.102  step=116.000  time=76107.646\n",
      "[[(0, 5), (0, 5), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=11.951  inner_mse=0.765  step=117.000  time=76764.048\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=7.536  inner_mse=0.570  step=118.000  time=79327.342\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=5.012  inner_mse=0.500  step=119.000  time=81787.458\n",
      "[[(0, 7), (0, 3), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=8.391  inner_mse=0.460  step=120.000  time=88139.734\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=6.207  inner_mse=1.166  step=121.000  time=90944.229\n",
      "[[(0, 0), (0, 0), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=3.955  inner_mse=1.129  step=122.000  time=91567.038\n",
      "[[(0, 7), (0, 7), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.373  inner_mse=1.199  step=123.000  time=92118.507\n",
      "[[(0, 3), (0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.424  inner_mse=0.981  step=124.000  time=92765.338\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.268  inner_mse=0.714  step=125.000  time=95713.048\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.613  inner_mse=1.240  step=126.000  time=98261.146\n",
      "[[(0, 0), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=1.171  inner_mse=0.909  step=127.000  time=98903.551\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.726  inner_mse=0.664  step=128.000  time=101658.679\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.452  inner_mse=0.532  step=129.000  time=104398.452\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.721  inner_mse=1.180  step=130.000  time=106954.367\n",
      "[[(0, 1), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.788  inner_mse=1.030  step=131.000  time=107593.737\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.294  inner_mse=0.771  step=132.000  time=108273.428\n",
      "[[(0, 7), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.394  inner_mse=0.593  step=133.000  time=110881.641\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.857  inner_mse=0.817  step=134.000  time=113413.937\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.671  inner_mse=1.325  step=135.000  time=115588.831\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.075  inner_mse=1.067  step=136.000  time=116249.726\n",
      "[[(0, 0), (0, 1), (0, 9), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.032  inner_mse=0.749  step=137.000  time=116837.202\n",
      "[[(0, 7), (0, 1), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.658  inner_mse=0.592  step=138.000  time=119409.598\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.666  inner_mse=0.461  step=139.000  time=122162.327\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.475  inner_mse=0.396  step=140.000  time=126148.560\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.307  inner_mse=0.357  step=141.000  time=132375.320\n",
      "[[(0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.975  inner_mse=0.336  step=142.000  time=137325.165\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.197  inner_mse=0.716  step=143.000  time=140697.963\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.718  inner_mse=1.004  step=144.000  time=143465.245\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.306  inner_mse=0.726  step=145.000  time=144109.163\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.878  inner_mse=0.797  step=146.000  time=146340.299\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.527  inner_mse=0.912  step=147.000  time=148936.713\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=3.377  inner_mse=0.653  step=148.000  time=151882.681\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.158  inner_mse=0.921  step=149.000  time=153010.121\n",
      "[[(0, 2), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 6), (0, 9), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.349  inner_mse=0.808  step=150.000  time=155678.571\n",
      "[[(0, 7), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.069  inner_mse=0.743  step=151.000  time=157464.844\n",
      "[[(0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.289  inner_mse=0.567  step=152.000  time=160414.899\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.909  inner_mse=0.472  step=153.000  time=163349.273\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.642  inner_mse=0.411  step=154.000  time=167871.429\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.387  inner_mse=0.694  step=155.000  time=172531.554\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.242  inner_mse=0.811  step=156.000  time=175312.313\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.193  inner_mse=0.614  step=157.000  time=177486.989\n",
      "[[(0, 4), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.116  inner_mse=0.559  step=158.000  time=180044.863\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.072  inner_mse=0.469  step=159.000  time=182987.822\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.288  inner_mse=0.578  step=160.000  time=188356.294\n",
      "[[(0, 3), (0, 2), (0, 2), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=67.443  inner_mse=0.484  step=161.000  time=191008.682\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=40.489  inner_mse=0.778  step=162.000  time=194909.426\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=28.770  inner_mse=0.817  step=163.000  time=196774.718\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=17.378  inner_mse=0.615  step=164.000  time=199374.416\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=10.427  inner_mse=0.656  step=165.000  time=202170.996\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=6.346  inner_mse=1.092  step=166.000  time=204347.930\n",
      "[[(0, 3), (0, 6), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=3.807  inner_mse=1.101  step=167.000  time=204996.141\n",
      "[[(0, 2), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.473  inner_mse=0.810  step=168.000  time=205641.910\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=3.586  inner_mse=0.631  step=169.000  time=207899.024\n",
      "[[(0, 8), (0, 8), (0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.157  inner_mse=0.493  step=170.000  time=210840.923\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.689  inner_mse=0.512  step=171.000  time=214134.153\n",
      "[[(0, 6), (0, 5), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.184  inner_mse=1.020  step=172.000  time=215908.314\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.946  inner_mse=0.927  step=173.000  time=216476.476\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.176  inner_mse=1.007  step=174.000  time=218923.011\n",
      "[[(0, 6), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.706  inner_mse=1.011  step=175.000  time=219568.832\n",
      "[[(0, 4), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.679  inner_mse=1.144  step=176.000  time=220129.073\n",
      "[[(0, 4), (0, 4), (0, 6), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.424  inner_mse=1.173  step=177.000  time=220678.340\n",
      "[[(0, 1), (0, 2), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.668  inner_mse=0.987  step=178.000  time=221247.458\n",
      "[[(0, 6), (0, 6), (0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.418  inner_mse=0.721  step=179.000  time=223807.209\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.252  inner_mse=0.847  step=180.000  time=226581.100\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.197  inner_mse=0.636  step=181.000  time=229605.298\n",
      "[[(0, 9), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.188  inner_mse=0.487  step=182.000  time=232191.381\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.114  inner_mse=0.552  step=183.000  time=238544.710\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.553  inner_mse=0.543  step=184.000  time=241085.957\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.340  inner_mse=0.483  step=185.000  time=243639.149\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.209  inner_mse=0.681  step=186.000  time=247088.628\n",
      "[[(0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.299  inner_mse=0.533  step=187.000  time=249632.823\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.185  inner_mse=0.449  step=188.000  time=252567.910\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.144  inner_mse=0.449  step=189.000  time=258919.629\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.095  inner_mse=0.493  step=190.000  time=265278.011\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.143  inner_mse=0.404  step=191.000  time=270540.428\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.089  inner_mse=0.699  step=192.000  time=273924.014\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.266  inner_mse=0.609  step=193.000  time=276115.574\n",
      "[[(0, 1), (0, 1), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.556  inner_mse=0.487  step=194.000  time=277941.009\n",
      "[[(0, 7), (0, 2), (0, 2), (0, 0), (0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.699  inner_mse=0.425  step=195.000  time=283097.579\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.320  inner_mse=0.810  step=196.000  time=288398.877\n",
      "[[(0, 3), (0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=10.601  inner_mse=1.081  step=197.000  time=290453.834\n",
      "[[(0, 2), (0, 4), (0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 8), (0, 8), (0, 8), (0, 9), (0, 8)]]\n",
      "contro_loss=6.446  inner_mse=0.863  step=198.000  time=291097.141\n",
      "[[(0, 0), (0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=4.000  inner_mse=0.697  step=199.000  time=293632.341\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.441  inner_mse=0.532  step=200.000  time=296188.883\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.822  inner_mse=0.840  step=201.000  time=298541.173\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.693  inner_mse=0.906  step=202.000  time=301324.773\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.039  inner_mse=0.667  step=203.000  time=303915.210\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.634  inner_mse=0.513  step=204.000  time=306457.248\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.381  inner_mse=0.416  step=205.000  time=308993.763\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.302  inner_mse=0.375  step=206.000  time=313129.954\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.216  inner_mse=0.526  step=207.000  time=316964.563\n",
      "[[(0, 3), (0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.221  inner_mse=0.429  step=208.000  time=319515.475\n",
      "[[(0, 4), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.134  inner_mse=0.372  step=209.000  time=324933.961\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.795  inner_mse=1.024  step=210.000  time=329219.093\n",
      "[[(0, 0), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=0.501  inner_mse=0.756  step=211.000  time=329865.802\n",
      "[[(0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.305  inner_mse=0.632  step=212.000  time=332416.637\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.199  inner_mse=0.571  step=213.000  time=334942.168\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.221  inner_mse=0.523  step=214.000  time=337471.917\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=3.387  inner_mse=1.201  step=215.000  time=339607.569\n",
      "[[(0, 0), (0, 0), (0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.138  inner_mse=1.222  step=216.000  time=340313.210\n",
      "[[(0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.347  inner_mse=0.855  step=217.000  time=341005.418\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.809  inner_mse=0.675  step=218.000  time=343561.174\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.545  inner_mse=0.543  step=219.000  time=346114.254\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.339  inner_mse=0.565  step=220.000  time=348666.671\n",
      "[[(0, 3), (0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.238  inner_mse=0.898  step=221.000  time=351215.020\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.153  inner_mse=0.956  step=222.000  time=353877.127\n",
      "[[(0, 7), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.205  inner_mse=0.744  step=223.000  time=356428.342\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.181  inner_mse=0.901  step=224.000  time=359010.063\n",
      "[[(0, 5), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.114  inner_mse=0.719  step=225.000  time=361564.962\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.143  inner_mse=0.607  step=226.000  time=364104.301\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.176  inner_mse=0.557  step=227.000  time=366654.031\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.532  inner_mse=0.971  step=228.000  time=369240.898\n",
      "[[(0, 5), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.403  inner_mse=0.755  step=229.000  time=371773.965\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.300  inner_mse=0.583  step=230.000  time=374340.766\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.187  inner_mse=0.472  step=231.000  time=377070.770\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.152  inner_mse=0.398  step=232.000  time=381085.288\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.114  inner_mse=0.421  step=233.000  time=386911.535\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.090  inner_mse=0.390  step=234.000  time=391244.980\n",
      "[[(0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.055  inner_mse=0.344  step=235.000  time=395626.307\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.038  inner_mse=0.399  step=236.000  time=401962.105\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.024  inner_mse=0.650  step=237.000  time=408323.397\n",
      "[[(0, 3), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.074  inner_mse=0.577  step=238.000  time=410865.759\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.056  inner_mse=0.463  step=239.000  time=413414.892\n",
      "[[(0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.034  inner_mse=0.402  step=240.000  time=418855.973\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.075  inner_mse=0.353  step=241.000  time=423836.377\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.125  inner_mse=0.323  step=242.000  time=428342.208\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.137  inner_mse=0.354  step=243.000  time=433165.983\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.125  inner_mse=0.323  step=244.000  time=437866.400\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.082  inner_mse=0.354  step=245.000  time=444210.871\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.113  inner_mse=0.389  step=246.000  time=450448.381\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.089  inner_mse=0.352  step=247.000  time=454555.955\n",
      "[[(0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.086  inner_mse=0.329  step=248.000  time=459577.497\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.163  inner_mse=0.417  step=249.000  time=464419.351\n",
      "[[(0, 1), (0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.128  inner_mse=0.793  step=250.000  time=470764.479\n",
      "[[(0, 0), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.139  inner_mse=0.601  step=251.000  time=473517.900\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.112  inner_mse=0.527  step=252.000  time=476067.872\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contro_loss=0.403  inner_mse=0.470  step=253.000  time=478617.595\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.424  inner_mse=0.438  step=254.000  time=483892.580\n",
      "[[(0, 4), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.405  inner_mse=0.400  step=255.000  time=488043.367\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.291  inner_mse=0.363  step=256.000  time=493439.675\n",
      "[[(0, 3), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.219  inner_mse=0.336  step=257.000  time=497562.806\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.423  inner_mse=0.353  step=258.000  time=503277.930\n",
      "[[(0, 8), (0, 2), (0, 2), (0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.923  inner_mse=0.326  step=259.000  time=508593.339\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.749  inner_mse=0.446  step=260.000  time=514997.963\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.763  inner_mse=0.491  step=261.000  time=521409.256\n",
      "[[(0, 8), (0, 8), (0, 8), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.468  inner_mse=0.401  step=262.000  time=527142.623\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.316  inner_mse=0.355  step=263.000  time=532142.100\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.204  inner_mse=0.331  step=264.000  time=536897.956\n",
      "[[(0, 8), (0, 5), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.430  inner_mse=0.803  step=265.000  time=540563.730\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.314  inner_mse=0.608  step=266.000  time=543514.102\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.232  inner_mse=0.532  step=267.000  time=546080.770\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.151  inner_mse=0.436  step=268.000  time=548834.657\n",
      "[[(0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.091  inner_mse=0.532  step=269.000  time=555212.820\n",
      "[[(0, 1), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=2.106  inner_mse=1.081  step=270.000  time=557781.791\n",
      "[[(0, 2), (0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=1.265  inner_mse=0.814  step=271.000  time=558429.876\n",
      "[[(0, 2), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.768  inner_mse=1.130  step=272.000  time=561038.092\n",
      "[[(0, 6), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.499  inner_mse=0.789  step=273.000  time=561698.373\n",
      "[[(0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.304  inner_mse=0.627  step=274.000  time=564251.700\n",
      "[[(0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.232  inner_mse=0.559  step=275.000  time=566829.953\n",
      "[[(0, 4), (0, 1), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.916  inner_mse=0.974  step=276.000  time=569399.505\n",
      "[[(0, 4), (0, 8), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.551  inner_mse=1.140  step=277.000  time=572020.210\n",
      "[[(0, 6), (0, 6), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.331  inner_mse=0.810  step=278.000  time=572691.088\n",
      "[[(0, 7), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n",
      "contro_loss=0.214  inner_mse=0.595  step=279.000  time=575633.530\n",
      "[[(0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9), (0, 9)]]\n"
     ]
    }
   ],
   "source": [
    "averages = MovingAverages()\n",
    "averages.smoothing['time'] = 0\n",
    "start_time = time.time()\n",
    "for step_idx in range(10000):\n",
    "    avg_mse = averages.metrics.get('inner_mse', 10)\n",
    "    if avg_mse > 1:\n",
    "        max_epochs = 5\n",
    "    elif avg_mse > 0.5:\n",
    "        max_epochs = 20\n",
    "    elif avg_mse > 0.3:\n",
    "        max_epochs = 50\n",
    "    else:\n",
    "        max_epochs = 500\n",
    "\n",
    "    architectures = controller.generate_architecture(controller_session)\n",
    "\n",
    "    # test architectures on a temporary graph\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default():\n",
    "            rewards = [\n",
    "                evaluate_architecture(\n",
    "                    step_idx, arch_idx, arch,\n",
    "                    max_epochs, samples_count=-1\n",
    "                )\n",
    "                for arch_idx, arch in enumerate(architectures)\n",
    "            ]\n",
    "\n",
    "    loss = controller.learn_from_rewards(\n",
    "        controller_session, architectures, rewards\n",
    "    )\n",
    "\n",
    "    averages.update_all(\n",
    "        contro_loss=loss**2,\n",
    "        inner_mse=np.mean(rewards),\n",
    "    )\n",
    "\n",
    "    if step_idx % 1 == 0:\n",
    "        snap = averages.snapshot(step=step_idx, time=time.time() - start_time)\n",
    "        print('  '.join(\n",
    "            '%s=%.3f' % metric for metric in snap.items()\n",
    "        ))\n",
    "        print(architectures)\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
