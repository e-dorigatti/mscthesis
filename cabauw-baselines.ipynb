{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we run some baselines to understand the level of performance to beat\n",
    "we use nested CV and grid search to get realistic performance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from collections import defaultdict, namedtuple\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from hkfold import HKFold, train_test_split\n",
    "from scipy.optimize import fmin_cg, fmin_ncg\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(dframe_path='data/cabauw/processed-full-log.csv.gz'):\n",
    "    try:\n",
    "        df = pd.read_csv(dframe_path, na_values='--')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[(df.ds != 201603) & (df.phi_m.notnull())]\n",
    "    df = df.sort_values(['ds', 'tt'])\n",
    "    #df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(dtimes, interval):\n",
    "    # returns a tuple index_above, index_below\n",
    "    # index_above[i] is the largest i\n",
    "    # such that dtimes[index_above[i]] - dtimes[i] < interval\n",
    "    # index_below[i] is the smallest i\n",
    "    # such that dtimes[i] - dtimes[index_below[i]] < interval\n",
    "    # dtimes must be already sorted!\n",
    "    index_below, index_above = np.zeros(\n",
    "        (2, len(dtimes)), dtype=np.int\n",
    "    ) - 1\n",
    "\n",
    "    for i, x in enumerate(dtimes):\n",
    "        j = index_below[i - 1] if i > 0 else 0\n",
    "        while x - dtimes[j] > interval:\n",
    "            j += 1\n",
    "\n",
    "        index_below[i] = j\n",
    "        index_above[j] = i\n",
    "\n",
    "    last_above = index_above[0]\n",
    "    for i in range(len(dtimes)):\n",
    "        if index_above[i] < 0:\n",
    "            index_above[i] = last_above\n",
    "        else:\n",
    "            last_above = index_above[i]\n",
    "    \n",
    "    return index_above, index_below\n",
    "\n",
    "\n",
    "def compute_trend(df, columns, interval=3600):\n",
    "    df = df.sort_values('datetime')\n",
    "    for z in df.z.unique():  \n",
    "        this_level = df[df.z == z]\n",
    "        index_above, index_below = make_index(this_level.datetime.values, interval)\n",
    "\n",
    "        for col in columns:\n",
    "            val_above = this_level[col].values\n",
    "            val_below = this_level.iloc[index_below][col].values\n",
    "\n",
    "            time_above = this_level.datetime.values\n",
    "            time_below = this_level.iloc[index_below].datetime.values\n",
    "\n",
    "            trend = 3600 * (val_above - val_below) / (time_above - time_below)\n",
    "\n",
    "            df.loc[df.z == z, col + '_trend'] = trend\n",
    "\n",
    "    return df, [col + '_trend' for col in columns]\n",
    "\n",
    "\n",
    "def get_features(df, use_trend, feature_level):\n",
    "    # get feature names of the corresponding level\n",
    "    # adding them to df if not already there\n",
    "\n",
    "    feature_sets = [\n",
    "        [\n",
    "            'z', 'wind', 'temp', 'soil_temp',\n",
    "            'wind_10', 'wind_20', 'wind_40',\n",
    "            'temp_10', 'temp_20', 'temp_40',\n",
    "        ],\n",
    "        ['soilheat'],\n",
    "        ['netrad'],\n",
    "        ['rain', 'dewpoint'],\n",
    "        ['H', 'LE'],\n",
    "    ]\n",
    "\n",
    "    if isinstance(feature_level, int):\n",
    "        features = [\n",
    "            f for fset in feature_sets[:feature_level]\n",
    "            for f in fset\n",
    "        ]\n",
    "    elif isinstance(feature_level, (list, tuple)):\n",
    "        features = feature_level\n",
    "    else:\n",
    "        raise ValueError('pass list or int')\n",
    "\n",
    "    if ('wind_40' not in df.columns or\n",
    "            'wind_20' not in df.columns or\n",
    "            'wind_10' not in df.columns):\n",
    "\n",
    "        wind_temp_levels = df.pivot_table(\n",
    "            values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "        ).reset_index()\n",
    "        wind_temp_levels.columns = [\n",
    "            '%s_%d' % (a, b) if b else a\n",
    "            for a, b in wind_temp_levels.columns.values\n",
    "        ]\n",
    "        df = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "        \n",
    "    if use_trend:\n",
    "        missing_trend = [\n",
    "            f for f in features\n",
    "            if f != 'z' and f + '_trend' not in df.columns\n",
    "        ]\n",
    "\n",
    "        if missing_trend:\n",
    "            df, added_cols = compute_trend(df, missing_trend)\n",
    "            features.extend(added_cols)\n",
    "\n",
    "    # remove feature columns with only nulls and rows with any null\n",
    "    empty_columns = df.isnull().all(axis=0)\n",
    "    keep_columns = df.columns.isin(features) & ~empty_columns\n",
    "    missing = df.loc[:, keep_columns].isnull().any(axis=1)\n",
    "    df = df[~missing]\n",
    "    features = keep_columns.index.values[keep_columns.values]\n",
    "\n",
    "    return df, list(features)\n",
    "\n",
    "\n",
    "def get_train_test(df, features, target, train_idx, test_idx, normalize):\n",
    "    train_x, train_y = df.iloc[train_idx][features], df.iloc[train_idx][target]\n",
    "    test_x, test_y = df.iloc[test_idx][features], df.iloc[test_idx][target]\n",
    "\n",
    "    if normalize:\n",
    "        mean_x, std_x = train_x.mean(), train_x.std()\n",
    "        train_x = (train_x - mean_x) / std_x\n",
    "        test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "        mean_y, std_y = train_y.mean(), train_y.std()\n",
    "        train_y = (train_y - mean_y) / std_y\n",
    "        test_y = (test_y - mean_y) / std_y\n",
    "    else:\n",
    "        mean_y, std_y = 0, 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets start with a baseline. data doesnt follow the functions given in the literature, so while I fix it we can change those functions to fit the data. given the definition of $\\phi_m$ for $\\xi>0$:\n",
    "\n",
    "$$\n",
    "\\phi_m(\\xi)=a+b\\xi\n",
    "$$\n",
    "\n",
    "whose derivatives are trivial. for $\\xi<0$ we have\n",
    "\n",
    "$$\n",
    "\\phi_m(\\xi)=a(1-c^2\\xi)^d\n",
    "$$\n",
    "\n",
    "where we square $c$ to make sure the base of the power is always positive. its derivatives are\n",
    "\n",
    "$$\n",
    "{\\frac{\\partial \\phi_m}{\\partial a}}\\rvert_{\\xi<0}=(1-c^2\\xi)^d\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi_m}{\\partial c}=-2acd\\xi(1-c^2\\xi)^{d-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi_m}{\\partial d}=a(1-c^2\\xi)^d\\ln(1-c^2\\xi)\n",
    "$$\n",
    "\n",
    "considering the usual least squares with l2 regularization we have the loss function\n",
    "\n",
    "$$\n",
    "E=\\frac{1}{N}\\sum_i(\\hat\\phi_m(\\xi_i)-\\phi_m(\\xi_i,p))^2+\\frac{\\lambda}{2}\\sum_p p^2\n",
    "$$\n",
    "\n",
    "and its derivative with respect to the parameter $p$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial p}=\\frac{2}{N}\\sum_i\\frac{\\partial}{\\partial p}\\phi_m(\\xi_i,p)\\cdot(\\hat\\phi_m(\\xi_i)-\\phi_m(\\xi_i,p))+\\lambda p\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTEstimator:\n",
    "    ''' estimator for the universal functions in the monin-obukhov similarity theory\n",
    "        implementing scikit's interface\n",
    "        \n",
    "        fitting is done by minimizing the L2 regularized squared error\n",
    "        via conjugate gradient\n",
    "    '''\n",
    "    def __init__(self, regu=0.1, use_hessian=True):\n",
    "        self.regu = regu\n",
    "        self.a, self.b, self.c, self.d = (1, 4.8, np.sqrt(19.3), -0.25)\n",
    "        self.use_hessian = use_hessian\n",
    "        self.symbols = None\n",
    "\n",
    "    def _lazy_init_hessian(self):\n",
    "        # we initialize these functions lazily so that we can pickle\n",
    "        # this object and send it around before fitting\n",
    "        if self.use_hessian and self.symbols is None:\n",
    "            a, b, c, d, x = sp.symbols('a b c d x')\n",
    "            self.symbols = a, b, c, d\n",
    "\n",
    "            self._neg_H_fn = self._get_hessian_functions(\n",
    "                a * sp.Pow(1 - x * c**2, d), x, a, b, c, d\n",
    "            )\n",
    "            self._pos_H_fn = self._get_hessian_functions(\n",
    "                a + b * x, x, a, b, c, d\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_hessian_functions(expr, x, *symbols):\n",
    "        # returns functions computing second-order partial derivatives\n",
    "        # of expr. keyed by differentiation variables\n",
    "        return {\n",
    "            (s1, s2): sp.lambdify(\n",
    "                (x, *symbols),\n",
    "                sp.simplify(sp.diff(sp.diff(expr, s1), s2)),\n",
    "                'numpy'\n",
    "            ) for s1 in symbols for s2 in symbols\n",
    "        }\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'regu': self.regu}\n",
    "\n",
    "    def set_params(self, regu):\n",
    "        self.regu = regu\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def _compute_phi(cls, zL, a, b, c, d):\n",
    "        zL = cls._to_vec(zL)\n",
    "        mask = zL >= 0\n",
    "        yy = np.zeros(zL.shape)\n",
    "        yy[mask] = a + b * zL[mask]\n",
    "        yy[~mask] = a * np.power(1 - c**2 * zL[~mask], d)\n",
    "        assert all(np.isfinite(zL))\n",
    "        assert all(np.isfinite(yy)), (a, b, c, d)\n",
    "        return yy\n",
    "\n",
    "    @classmethod\n",
    "    def _compute_phi_prime(cls, zL, a, b, c, d):\n",
    "        zL = cls._to_vec(zL)\n",
    "        dpda, dpdb, dpdc, dpdd = np.zeros((4, len(zL)))\n",
    "\n",
    "        pos, neg = zL >= 0, zL < 0\n",
    "\n",
    "        dpda[pos] = 1\n",
    "        dpdb[pos] = zL[pos]\n",
    "\n",
    "        inner = 1 - c**2 * zL[neg]\n",
    "        dpda[neg] = np.power(inner, d)\n",
    "        dpdc[neg] = -2 * zL[neg] * a * c * d * np.power(inner, d - 1)\n",
    "        dpdd[neg] = a * np.log(inner) * np.power(inner, d)\n",
    "\n",
    "        return dpda, dpdb, dpdc, dpdd\n",
    "\n",
    "    def _fmin_hess(self, params, xx, yy, regu):\n",
    "        self._lazy_init_hessian()\n",
    "\n",
    "        preds = self._compute_phi(xx, *params)\n",
    "        xpos_mask = xx >= 0\n",
    "        hh1 = np.zeros((4, 4))\n",
    "\n",
    "        for i, s1 in enumerate(self.symbols):\n",
    "            for j, s2 in enumerate(self.symbols):\n",
    "                # when xx >= 0 the function is linear\n",
    "                # its hessian is always 0\n",
    "\n",
    "                neg = self._neg_H_fn[s1, s2](xx[~xpos_mask], *params)\n",
    "                hh1[i, j] = np.sum((preds[~xpos_mask] - yy[~xpos_mask]) * neg)\n",
    "\n",
    "        hh2 = np.zeros((4, len(xx)))\n",
    "        hh2[:, :] = self._compute_phi_prime(xx, *params)\n",
    "        \n",
    "        hess = 2 * ((hh2.dot(hh2.T) + hh1) / len(xx) + regu * np.eye(4))\n",
    "        return hess\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmin_target(params, xx, yy, regu):\n",
    "        preds = MOSTEstimator._compute_phi(xx, *params)\n",
    "        err = np.mean((yy - preds)**2) + regu * sum(p**2 for p in params)\n",
    "        return err\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmin_grad(params, xx, yy, regu):\n",
    "        preds = MOSTEstimator._compute_phi(xx, *params)\n",
    "        der = MOSTEstimator._compute_phi_prime(xx, *params)\n",
    "\n",
    "        grads = [\n",
    "            2 * np.mean((preds - yy) * parpr) + 2 * regu * par\n",
    "            for par, parpr in zip(params, der)\n",
    "        ]\n",
    "\n",
    "        return np.array(grads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_vec(mat):\n",
    "        mat = np.array(mat)\n",
    "        \n",
    "        # check that multi-dimensional arrays have only one\n",
    "        # dimension with more than one sample\n",
    "        # e.g. 1x1x99x1 is fine, 1x2x99x is not\n",
    "        assert sum(1 for n in mat.shape if n > 1) == 1\n",
    "        return mat.reshape(-1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self._to_vec(X)\n",
    "        y = self._to_vec(y)\n",
    "\n",
    "        if self.use_hessian:\n",
    "            self.a, self.b, self.c, self.d = fmin_ncg(\n",
    "                self._fmin_target,\n",
    "                (self.a, self.b, self.c, self.d),\n",
    "                self._fmin_grad,\n",
    "                fhess=self._fmin_hess,\n",
    "                args=(X, y, self.regu),\n",
    "                disp=False,\n",
    "            )\n",
    "        else:\n",
    "            self.a, self.b, self.c, self.d = fmin_cg(\n",
    "                self._fmin_target,\n",
    "                (self.a, self.b, self.c, self.d),\n",
    "                self._fmin_grad,\n",
    "                args=(X, y, self.regu),\n",
    "                disp=False,\n",
    "            )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._compute_phi(X, self.a, self.b, self.c, self.d)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return metrics.mean_squared_error(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeKFold:\n",
    "    ''' k-fold cross validator splitting on a particular attribute\n",
    "        so that all samples with a given value are either in the train or test set\n",
    "\n",
    "        attribute value for each sample is given in the constructor, so that\n",
    "        the attribute itself need not be in the features for the model\n",
    "    '''\n",
    "    def __init__(self, cv, attr):\n",
    "        self.cv, self.attr = cv, attr\n",
    "\n",
    "    def get_n_splits(self, *args, **kwargs):\n",
    "        return self.cv.get_n_splits(*args, **kwargs)\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        vals = self.attr.unique()\n",
    "        for train_idx, test_idx in self.cv.split(vals):\n",
    "            train_mask = self.attr.isin(vals[train_idx])\n",
    "            test_mask = self.attr.isin(vals[test_idx])\n",
    "\n",
    "            X = np.argwhere(train_mask).reshape(-1)\n",
    "            y = np.argwhere(test_mask).reshape(-1)\n",
    "            \n",
    "            assert np.all(np.isfinite(X))\n",
    "            assert np.all(np.isfinite(y))\n",
    "            \n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attributekfold():\n",
    "    outer_cv = AttributeKFold(KFold(10, shuffle=True), df.ds)\n",
    "    outer_train, outer_test = np.zeros((2, len(df)))\n",
    "    for outer_train_idx, outer_test_idx in outer_cv.split(df):\n",
    "\n",
    "        outer_train[outer_train_idx] += 1\n",
    "        outer_test[outer_test_idx] += 1\n",
    "\n",
    "        inner_train, inner_test = np.zeros((2, len(outer_train_idx)))\n",
    "        inner_cv = AttributeKFold(KFold(5, shuffle=True), df.iloc[outer_train_idx].ds)\n",
    "        for inner_train_idx, inner_test_idx in inner_cv.split(df.iloc[outer_train_idx]):\n",
    "            inner_train[inner_train_idx] += 1\n",
    "            inner_test[inner_test_idx] += 1\n",
    "\n",
    "        assert all(inner_train == 4)\n",
    "        assert all(inner_test == 1)\n",
    "\n",
    "    assert all(outer_train == 9)\n",
    "    assert all(outer_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(ypred, ytrue):\n",
    "    minn = max(min(ypred), min(ytrue))\n",
    "    maxx = min(max(ypred), max(ytrue))\n",
    "    \n",
    "    plt.scatter(ytrue, ypred, s=2)\n",
    "    plt.plot([minn, maxx], [minn, maxx], 'r--')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CVSpec = namedtuple('CVSpec', [\n",
    "    'model', 'param_distribution', 'features', 'target',\n",
    "    'inner_cv', 'outer_cv', 'n_iter', 'normalize',\n",
    "    'inner_seed', 'outer_seed', 'param_seed', 'meta',\n",
    "    'save_to',\n",
    "])\n",
    "\n",
    "CVResult = namedtuple('CVResult', [\n",
    "    'meta', 'scores', 'test_x', 'test_y', 'y_pred', 'imps'\n",
    "])\n",
    "\n",
    "\n",
    "# set default value to None, https://stackoverflow.com/a/18348004/521776\n",
    "CVSpec.__new__.__defaults__ = (None,) * len(CVSpec._fields)\n",
    "CVResult.__new__.__defaults__ = (None,) * len(CVResult._fields)\n",
    "\n",
    "\n",
    "def get_cv_fold(fold, cv_k, seed, attr):\n",
    "    cv = AttributeKFold(\n",
    "        KFold(cv_k, shuffle=True, random_state=seed),\n",
    "        attr\n",
    "    ).split(attr)\n",
    "    for _ in range(fold):\n",
    "        _ = next(cv)\n",
    "    return next(cv)\n",
    "\n",
    "\n",
    "def get_train_test(df, features, target, train_idx, test_idx, normalize):\n",
    "    train_x, train_y = df.iloc[train_idx][features], df.iloc[train_idx][target]\n",
    "    test_x, test_y = df.iloc[test_idx][features], df.iloc[test_idx][target]\n",
    "\n",
    "    if normalize:\n",
    "        mean_x, std_x = train_x.mean(), train_x.std()\n",
    "        train_x = (train_x - mean_x) / std_x\n",
    "        test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "        mean_y, std_y = train_y.mean(), train_y.std()\n",
    "        train_y = (train_y - mean_y) / std_y\n",
    "        test_y = (test_y - mean_y) / std_y\n",
    "    else:\n",
    "        mean_y, std_y = 0, 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y\n",
    "\n",
    "\n",
    "class CachedResults:\n",
    "    def __init__(self, **kwargs):\n",
    "        try:\n",
    "            from hops import hdfs\n",
    "            fs = hdfs.get_fs()\n",
    "            self.open_ = fs.open_file\n",
    "            self.cache_dir = 'hdfs:///Projects/more_stuff/checkpoints/'\n",
    "        except ImportError:\n",
    "            self.open_ = open\n",
    "            self.cache_dir = './dev/checkpoints/'\n",
    "\n",
    "        self.fname = hashlib.sha256(\n",
    "            json.dumps(kwargs).encode('utf8')\n",
    "        ).hexdigest()\n",
    "    \n",
    "    def get_value(self):\n",
    "        try:\n",
    "            with self.open_(self.cache_dir + self.fname, 'rb') as f:\n",
    "                return pickle.loads(f.read())\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def set_value(self, val):\n",
    "        with self.open_(self.cache_dir + self.fname, 'wb') as f:\n",
    "            f.write(pickle.dumps(val))\n",
    "\n",
    "\n",
    "def inner_train(df_bcast, model, features, target, params, folds,\n",
    "                keys, outer_seed, inner_seed, normalize):\n",
    "\n",
    "    cache = CachedResults(\n",
    "        model=model.__class__.__name__, features=features, target=target,\n",
    "        params=params, folds=folds, keys=keys, outer_seed=outer_seed,\n",
    "        inner_seed=inner_seed, normalize=normalize\n",
    "    )\n",
    "    saved = cache.get_value()\n",
    "    if saved is not None:\n",
    "        return saved\n",
    "    \n",
    "    df = df_bcast.value\n",
    "    if any(f not in df.columns for f in features):\n",
    "        print('some features are missing, reloading...')\n",
    "        df, _ = get_features(read_df(), use_trend=True, feature_level=5)\n",
    "    assert all(f in df.columns for f in features), (df.columns, features)\n",
    "    \n",
    "    outer_fold, inner_fold = folds\n",
    "    outer_train_idx, outer_test_idx = get_cv_fold(\n",
    "        outer_fold, 10, outer_seed, df.ds\n",
    "    )\n",
    "    \n",
    "    inner_train_idx, inner_test_idx = get_cv_fold(\n",
    "        inner_fold, 5, inner_seed, df.iloc[outer_train_idx].ds\n",
    "    )\n",
    "\n",
    "    train_idx, test_idx = outer_train_idx[inner_train_idx], outer_train_idx[inner_test_idx]\n",
    "    train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test(\n",
    "        df, features, target, train_idx, test_idx, normalize\n",
    "    )\n",
    "\n",
    "    model = model.set_params(**dict(zip(keys, params)))\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    mse = metrics.mean_squared_error(test_y, y_pred)\n",
    "\n",
    "    cache.set_value(mse)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def outer_train(df_bcast, model, features, target, outer_fold, params,\n",
    "                keys, outer_seed, normalize):\n",
    "    cache = CachedResults(\n",
    "        model=model.__class__.__name__, features=features,\n",
    "        target=target, params=params, outer_fold=outer_fold,\n",
    "        keys=keys, outer_seed=outer_seed, normalize=normalize\n",
    "    )\n",
    "    saved = cache.get_value()\n",
    "    if saved is not None:\n",
    "        return saved\n",
    "\n",
    "    df = df_bcast.value\n",
    "    if any(f not in df.columns for f in features):\n",
    "        print('some features are missing, reloading...')\n",
    "        df, _ = get_features(read_df(), use_trend=True, feature_level=5)\n",
    "    assert all(f in df.columns for f in features), (df.columns, features)\n",
    "    \n",
    "    train_idx, test_idx = get_cv_fold(\n",
    "        outer_fold, 10, outer_seed, df.ds\n",
    "    )\n",
    "\n",
    "    train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test(\n",
    "        df, features, target, train_idx, test_idx, normalize\n",
    "    )\n",
    "\n",
    "    model = model.set_params(**dict(zip(keys, params)))\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    y_pred = y_pred * std_y + mean_y\n",
    "    test_y = test_y * std_y + mean_y\n",
    "\n",
    "    perc_errors = 100 * np.abs((test_y - y_pred) / test_y)\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    else:\n",
    "        importances = []\n",
    "    \n",
    "    result = ((\n",
    "        metrics.explained_variance_score(test_y, y_pred),\n",
    "        metrics.mean_absolute_error(test_y, y_pred),\n",
    "        metrics.mean_squared_error(test_y, y_pred),\n",
    "        metrics.median_absolute_error(test_y, y_pred),\n",
    "        metrics.r2_score(test_y, y_pred),\n",
    "        np.mean(perc_errors),\n",
    "        np.median(perc_errors),\n",
    "    )) #, importances, (test_x, test_y, y_pred) if outer_fold == 0 else None)\n",
    "\n",
    "    cache.set_value(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def finalize_result(meta, results, save_to=None):\n",
    "    #scores, imps, preds = zip(*list(results))\n",
    "    scores = list(results)\n",
    "    scores_df = pd.DataFrame(list(scores), columns=[\n",
    "        'explained_variance_score',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'median_absolute_error',\n",
    "        'r2_score',\n",
    "        'mean_abs_percent_error',\n",
    "        'median_abs_percent_error',\n",
    "    ])\n",
    "\n",
    "    if save_to:\n",
    "        try:\n",
    "            from hops import hdfs\n",
    "            fs = hdfs.get_fs()\n",
    "            open_ = fs.open_file\n",
    "            base_dir = 'hdfs:///Projects/more_stuff/'\n",
    "        except ImportError:\n",
    "            open_ = open\n",
    "            base_dir = './data/'\n",
    "\n",
    "        fname = '%s/cabauw/results_%s.txt' % (base_dir, save_to)\n",
    "        with open_(fname, 'w') as f:\n",
    "            f.write(scores_df.describe().T.to_string())\n",
    "            f.write('\\n\\n**raw scores\\n\\n')\n",
    "            f.write(scores_df.to_string())\n",
    "\n",
    "    #test_x, test_y, y_pred = [ps for ps in preds if ps is not None][0]\n",
    "    return CVResult(\n",
    "        meta=meta, scores=scores,\n",
    "        #test_x=test_x, test_y=test_y, y_pred=y_pred, imps=imps\n",
    "        test_x=None, test_y=None, y_pred=None, imps=None\n",
    "    )\n",
    "\n",
    "\n",
    "def nested_cv_spark(df, *cv_specs):\n",
    "    ''' nested cross-validation performing random search in the inner loop\n",
    "\n",
    "        optimized for running several nested cv in parallel, each with\n",
    "        different models and/or grids\n",
    "\n",
    "        callers must make sure that the dataframe contains all the features\n",
    "        and target they request\n",
    "    '''\n",
    "    df_bcast = sc.broadcast(df)\n",
    "\n",
    "    result_rdd = None\n",
    "    for spec in cv_specs:\n",
    "        # default values\n",
    "        inner_cv = spec.inner_cv or 10\n",
    "        outer_cv = spec.outer_cv or 10\n",
    "        n_iter = spec.n_iter or 10\n",
    "        normalize = spec.normalize or True\n",
    "        \n",
    "        # need to have the same seed in all workers,\n",
    "        # so that the folds are consistent\n",
    "        inner_seed = spec.inner_seed or np.random.randint(2**32, dtype=np.uint)\n",
    "        outer_seed = spec.outer_seed or np.random.randint(2**32, dtype=np.uint)\n",
    "\n",
    "        # build grid with random parameter values\n",
    "        rnd = np.random.RandomState(spec.param_seed)\n",
    "        grid = [{\n",
    "            par: distr.rvs(random_state=rnd) if hasattr(distr, 'rvs') else np.random.choice(distr)\n",
    "            for par, distr in spec.param_distribution.items()\n",
    "        } for _ in range(n_iter)]\n",
    "\n",
    "        # build list of all grids to try and inner/outer combinations\n",
    "        grid_vals = [tuple(p.values()) for p in grid]\n",
    "        cv_vals = list(itertools.product(range(outer_cv), range(inner_cv)))\n",
    "\n",
    "        results = (sc.parallelize(grid_vals, len(grid_vals))\n",
    "             .cartesian(sc.parallelize(cv_vals, len(cv_vals)))\n",
    "\n",
    "             # train and evaluate on inner fold for each outer fold\n",
    "             # key by (outer fold, parameters)\n",
    "             .map(lambda x: ((x[1][0], x[0]), inner_train(\n",
    "                 df_bcast, spec.model, spec.features, spec.target,\n",
    "                 x[0], x[1], tuple(spec.param_distribution.keys()),\n",
    "                 outer_seed, inner_seed, normalize\n",
    "             )))\n",
    "\n",
    "             # for each outer fold/parameters, compute sum of mse\n",
    "             .reduceByKey(lambda mse1, mse2: mse1 + mse2,\n",
    "                          numPartitions=outer_cv)\n",
    "\n",
    "             # for each outer fold, find parameters with best mse\n",
    "             .map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "             .reduceByKey(lambda x, y: x if x[1] < y[1] else y)\n",
    "\n",
    "             # for each outer fold, validate using best parameters\n",
    "             # x is (outer fold, (parameters, mse))\n",
    "             .map(lambda x: outer_train(\n",
    "                 df_bcast, spec.model, spec.features, spec.target, x[0], x[1][0],\n",
    "                 tuple(spec.param_distribution.keys()), outer_seed, spec.normalize\n",
    "             ))\n",
    "\n",
    "             # finalize results, optionally saving\n",
    "            .coalesce(1)\n",
    "            .mapPartitions(lambda x: finalize_result(spec.meta, x)))\n",
    "\n",
    "        if result_rdd is None:\n",
    "            result_rdd = results\n",
    "        else:\n",
    "            result_rdd = result_rdd.union(results)\n",
    "\n",
    "    cv_results = result_rdd.collect()\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(df, model, grid, feature_level, target, most_only, n_jobs=-2,\n",
    "              random_iter=10, normalize=True, use_trend=True, outer_callback=None):\n",
    "    df, features = get_features(df, use_trend, feature_level)\n",
    "    if most_only:\n",
    "        df = df[(df.zL > -2) & (df.zL < 1)]\n",
    "\n",
    "    outer_cv = AttributeKFold(KFold(10, shuffle=True), df.ds)\n",
    "    results = []\n",
    "    for oi, (train_idx, test_idx) in enumerate(outer_cv.split(df.ds)):\n",
    "        train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test(\n",
    "            df, features, target, train_idx, test_idx, normalize\n",
    "        )\n",
    "\n",
    "        # grid search for best params\n",
    "        inner_cv = AttributeKFold(KFold(10, shuffle=True), df.iloc[train_idx].ds)\n",
    "        gs = RandomizedSearchCV(\n",
    "            model(), grid, n_jobs=n_jobs, cv=inner_cv,\n",
    "            n_iter=random_iter,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            verbose=2,\n",
    "        )\n",
    "        \n",
    "        assert np.all(np.isfinite(train_x))\n",
    "        assert np.all(np.isfinite(train_y))\n",
    "        gs.fit(train_x, train_y)\n",
    "\n",
    "        # evaluate on test data\n",
    "        y_pred = gs.best_estimator_.predict(test_x)\n",
    "        y_pred = y_pred * std_y + mean_y\n",
    "        test_y = test_y * std_y + mean_y\n",
    "        perc_errors = 100 * np.abs((test_y - y_pred) / test_y)\n",
    "\n",
    "        results.append((\n",
    "            metrics.explained_variance_score(test_y, y_pred),\n",
    "            metrics.mean_absolute_error(test_y, y_pred),\n",
    "            metrics.mean_squared_error(test_y, y_pred),\n",
    "            metrics.median_absolute_error(test_y, y_pred),\n",
    "            metrics.r2_score(test_y, y_pred),\n",
    "            np.mean(perc_errors),\n",
    "            np.median(perc_errors),\n",
    "        ))\n",
    "        \n",
    "        if outer_callback is not None:\n",
    "            outer_callback(gs, results[-1], test_x, test_y, y_pred)\n",
    "        \n",
    "    clear_output()\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\n",
    "        'explained_variance_score',\n",
    "        'mean_absolute_error',\n",
    "        'mean_squared_error',\n",
    "        'median_absolute_error',\n",
    "        'r2_score',\n",
    "        'mean_abs_percent_error',\n",
    "        'median_abs_percent_error',\n",
    "    ]), test_x, test_y, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(df, most_only, spark=True):\n",
    "    ''' run each model on all features with and without trend\n",
    "    '''\n",
    "    if most_only:\n",
    "        df = df[(df.zL > -2) & (df.zL < 1)]\n",
    "\n",
    "    ridge_spec = Ridge, {\n",
    "        'alpha': LogUniform(10, -6, 1)\n",
    "    }\n",
    "    \n",
    "    knn_spec = KNeighborsRegressor, {\n",
    "        'n_neighbors': IntDistribution(stats.uniform(1, 14)),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2],\n",
    "    }\n",
    "    \n",
    "    gbr_spec = GradientBoostingRegressor, {\n",
    "        'max_depth': IntDistribution(stats.uniform(loc=4, scale=8)),\n",
    "        'subsample': stats.uniform(loc=0.25, scale=0.75),\n",
    "        'max_features': stats.uniform(0.1, 0.9),\n",
    "        'loss': ['lad', 'ls', 'huber'],\n",
    "        'n_estimators': IntDistribution(LogUniform(10, 1, 4)),\n",
    "        'learning_rate': LogUniform(10, -4, 0),\n",
    "        'alpha': stats.uniform(0.01, 0.98),\n",
    "    }\n",
    "\n",
    "    specs = []\n",
    "    for trend in [True, False]:\n",
    "        for fset in range(1, 6):\n",
    "            _, features = get_features(df, trend, fset)\n",
    "            for model_cls, grid in [ridge_spec]: #[ridge_spec, knn_spec, gbr_spec]:\n",
    "                dtime = datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "                fname = '%s_f%d_%strend_%smost-%s' % (\n",
    "                    model_cls.__name__, fset,\n",
    "                    '' if trend else 'no',\n",
    "                    '' if most_only else 'no', dtime\n",
    "                )\n",
    "                \n",
    "                meta = {\n",
    "                    'trend': trend,\n",
    "                    'fset': fset,\n",
    "                    'model': model_cls,\n",
    "                    'most_only': most_only\n",
    "                }\n",
    "                \n",
    "                if spark:\n",
    "                    specs.append(CVSpec(\n",
    "                        model_cls(), grid, features,\n",
    "                        'phi_m', save_to=fname, meta=meta,\n",
    "                        inner_seed=233522635,\n",
    "                        outer_seed=773466534,\n",
    "                        param_seed=634643256,\n",
    "                    ))\n",
    "                else:\n",
    "                    results, _, _, _ = nested_cv(\n",
    "                        df, model_cls, grid, features, 'phi_m',\n",
    "                        most_only, use_trend=trend,\n",
    "                    )\n",
    "                    specs.append(finalize_result(None, results.values, save_to=fname))\n",
    "\n",
    "    if spark:\n",
    "        cv_results = nested_cv_spark(df, *specs)\n",
    "        return cv_results\n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogUniform:\n",
    "    ''' random variable X such that log(x) is distributed uniformly\n",
    "    '''\n",
    "    def __init__(self, base, expmin, expmax):\n",
    "        self.base, self.expmin, self.expmax = base, expmin, expmax\n",
    "\n",
    "    def rvs(self, random_state=None, size=None):\n",
    "        random_state = random_state or np.random.RandomState()\n",
    "        exp = random_state.uniform(self.expmin, self.expmax, size=size)\n",
    "        return np.power(self.base, exp)\n",
    "\n",
    "\n",
    "class IntDistribution:\n",
    "    ''' random variable taking only integer values\n",
    "    '''\n",
    "    def __init__(self, rv):\n",
    "        self.rv = rv\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        sample = self.rv.rvs(*args, **kwargs)\n",
    "        return int(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "ddf, _ = get_features(df, use_trend=True, feature_level=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init spark locally if not on hops\n",
    "try:\n",
    "    sc\n",
    "except NameError:\n",
    "    sc = None\n",
    "\n",
    "if not sc:\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    sc = SparkContext(conf=SparkConf().setMaster('local[7]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'do_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4eaa0b6d6f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmost_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'do_test' is not defined"
     ]
    }
   ],
   "source": [
    "most_res = do_test(ddf, most_only=False, spark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
