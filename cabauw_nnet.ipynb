{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "from scipy.stats import probplot\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (Dense, Dropout, BatchNormalization, LSTM,\n",
    "                          GaussianNoise, Input, PReLU, Activation,\n",
    "                          Concatenate, GRU, Masking, TimeDistributed)\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras import regularizers \n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dframe_path = 'data/cabauw/processed-full-log.csv.gz'\n",
    "    df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[df.ds != 201603]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingMeanStd:\n",
    "    # http://people.ds.cam.ac.uk/fanf2/hermes/doc/antiforgery/stats.pdf\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.mu = self.s = None\n",
    "    \n",
    "    def add(self, x):\n",
    "        self.n += 1\n",
    "        if self.n == 1:\n",
    "            self.mu = self.s = x\n",
    "            return\n",
    "\n",
    "        old_mu = self.mu\n",
    "        old_s = self.s\n",
    "        \n",
    "        self.mu = old_mu + (x - old_mu) / self.n\n",
    "        self.s = old_s + (x - old_mu) * (x - self.mu)\n",
    "    \n",
    "    @property\n",
    "    def count(self):\n",
    "        return self.n\n",
    "\n",
    "    @property\n",
    "    def rolling_mean(self):\n",
    "        return self.mu\n",
    "    \n",
    "    @property\n",
    "    def rolling_std(self):\n",
    "        return np.sqrt(self.s / self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_temp_levels = df.pivot_table(\n",
    "    values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    ").reset_index()\n",
    "wind_temp_levels.columns = [\n",
    "    '%s_%d' % (a, b) if b else a\n",
    "    for a, b in wind_temp_levels.columns.values\n",
    "]\n",
    "\n",
    "ddf = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "\n",
    "feature_sets = [\n",
    "    [\n",
    "        'z', 'wind', 'temp', 'soil_temp',\n",
    "        'wind_10', 'wind_20', 'wind_40',\n",
    "        'temp_10', 'temp_20', 'temp_40',\n",
    "    ],\n",
    "    ['soilheat'],\n",
    "    ['netrad'],\n",
    "    ['rain', 'dewpoint'],\n",
    "    ['H', 'LE'],\n",
    "]\n",
    "\n",
    "all_features = [f for fset in feature_sets for f in fset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "51989 3.9999969224282657\n",
      "103978 7.999993844856531\n",
      "155967 11.999990767284796\n",
      "207956 15.999987689713063\n",
      "259945 19.99998461214133\n",
      "311934 23.999981534569592\n",
      "363923 27.99997845699786\n",
      "415912 31.999975379426125\n",
      "467901 35.99997230185439\n",
      "519890 39.99996922428266\n",
      "571879 43.999966146710925\n",
      "623868 47.999963069139184\n",
      "675857 51.99995999156745\n",
      "727846 55.99995691399572\n",
      "779835 59.999953836423984\n",
      "831824 63.99995075885225\n",
      "883813 67.99994768128052\n",
      "935802 71.99994460370878\n",
      "987791 75.99994152613705\n",
      "1039780 79.99993844856532\n",
      "1091769 83.99993537099358\n",
      "1143758 87.99993229342185\n",
      "1195747 91.99992921585012\n",
      "1247736 95.99992613827837\n",
      "1299725 99.99992306070664\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "window_size = 1 * 60 * 60\n",
    "\n",
    "queues = {z: deque() for z in ddf.z.unique()}\n",
    "normalizer = RollingMeanStd()\n",
    "samples_x, samples_y = [], []\n",
    "nonas = ddf.dropna()\n",
    "max_len = 0\n",
    "\n",
    "for i, row in enumerate(nonas.sort_values('datetime').itertuples()):\n",
    "    qq = queues[row.z]\n",
    "    qq.append(row)\n",
    "    while qq and row.datetime - qq[0].datetime > window_size:\n",
    "        qq.popleft()\n",
    "\n",
    "    sample = []\n",
    "    for obs in qq:\n",
    "        ss = [getattr(obs, ff) for ff in all_features]\n",
    "        ss.append(row.datetime - obs.datetime)\n",
    "        sample.append(ss)\n",
    "    \n",
    "    # add new sample to normalizer\n",
    "    # (other samples were added in previous iterations)\n",
    "    normalizer.add(np.array(ss[:-1]))\n",
    "    max_len = max(max_len, len(sample))\n",
    "\n",
    "    samples_x.append(np.array(sample))\n",
    "    samples_y.append(row.phi_m)\n",
    "    \n",
    "    if i % int(len(nonas) / 25) == 0:\n",
    "        print(i, 100 * i / len(nonas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 7, 17), (32, 1))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_x = normalizer.rolling_mean\n",
    "std_x = normalizer.rolling_std\n",
    "\n",
    "mu_y = np.mean(samples_y)\n",
    "std_y = np.std(samples_y)\n",
    "\n",
    "def make_batches(all_samples, epochs, batch_size, pad_to,\n",
    "                 num_features, shuffle=True):\n",
    "    ep = 0\n",
    "\n",
    "    batch_x = np.zeros((batch_size, pad_to, num_features))\n",
    "    batch_y = np.zeros((batch_size, 1))\n",
    "\n",
    "    while epochs < 0 or ep < epochs:\n",
    "        if shuffle:\n",
    "            random.shuffle(all_samples)\n",
    "\n",
    "        ep += 1\n",
    "        max_len = 0\n",
    "\n",
    "        for i, (sx, sy) in enumerate(all_samples):\n",
    "            max_len = max(max_len, sx.shape[0])\n",
    "\n",
    "            sx[:, :-1] = (sx[:, :-1] - mu_x) / std_x\n",
    "            sx[:, -1] = sx[:, -1] / window_size - 0.5\n",
    "\n",
    "            batch_x[i % batch_size, :sx.shape[0]] = sx\n",
    "            batch_y[i % batch_size] = (sy - mu_y) / std_y\n",
    "\n",
    "            assert np.all(np.isfinite(sx)), i\n",
    "            assert np.all(np.isfinite(sy)), i\n",
    "\n",
    "            if (i + 1) % batch_size == 0:\n",
    "                yield batch_x[:, :max_len], batch_y[:, :max_len]\n",
    "                max_len = 0\n",
    "\n",
    "        remaining = (i + 1) % batch_size\n",
    "        if remaining > 0:\n",
    "            yield batch_x[:remaining, :max_len], batch_y[:remaining, :max_len]\n",
    "\n",
    "                            \n",
    "bx, by = next(make_batches(list(zip(samples_x, samples_y)), -1,\n",
    "                           32, max_len, 17))\n",
    "bx.shape, by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_31 (GRU)                 (None, None, 256)         210432    \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, None, 256)         256       \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, None, 128)         147840    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 128)         128       \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "p_re_lu_110 (PReLU)          (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "p_re_lu_111 (PReLU)          (None, 32)                32        \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "p_re_lu_112 (PReLU)          (None, 16)                16        \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "p_re_lu_113 (PReLU)          (None, 8)                 8         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "p_re_lu_114 (PReLU)          (None, 4)                 4         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "p_re_lu_115 (PReLU)          (None, 2)                 2         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 398,631\n",
      "Trainable params: 398,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def compute_denormalized_mse(std_y):\n",
    "    def denormalized_mse(y_true, y_pred):\n",
    "        # model is trained with normalized data, but we want\n",
    "        # mse on not normalized data to compare with MOST\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "        return mse * std_y**2\n",
    "    return denormalized_mse\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        GRU(256, return_sequences=True, activation=None, input_shape=(None, 17)),\n",
    "        TimeDistributed(PReLU()),\n",
    "        GRU(128, return_sequences=True, activation=None),\n",
    "        TimeDistributed(PReLU()),\n",
    "        GRU(64, activation=None), PReLU(),\n",
    "        Dense(32), PReLU(),\n",
    "        Dense(16), PReLU(),\n",
    "        Dense(8), PReLU(),\n",
    "        Dense(4), PReLU(),\n",
    "        Dense(2), PReLU(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    opt = Adam(lr=1e-6, clipvalue=1)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=[compute_denormalized_mse(std_y)])\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10155/10155 [==============================] - 570s 56ms/step - loss: 1.0397 - denormalized_mse: 2.4019\n",
      "Epoch 2/500\n",
      " 2710/10155 [=======>......................] - ETA: 6:46 - loss: 2.7314 - denormalized_mse: 6.3103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-f68e0dfd1569>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmake_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})).as_default():\n",
    "        model = build_model()\n",
    "        \n",
    "        model.fit_generator(\n",
    "            make_batches(list(zip(samples_x, samples_y)), -1, batch_size, max_len, 17),\n",
    "            steps_per_epoch = int(len(samples_x) / batch_size) + 1,\n",
    "            epochs=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plain dense fc networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_index(dtimes, interval):\n",
    "    # returns a tuple index_above, index_below\n",
    "    # index_above[i] is the largest i\n",
    "    # such that dtimes[index_above[i]] - dtimes[i] < interval\n",
    "    # index_below[i] is the smallest i\n",
    "    # such that dtimes[i] - dtimes[index_below[i]] < interval\n",
    "    # dtimes must be already sorted!\n",
    "    index_below, index_above = np.zeros(\n",
    "        (2, len(dtimes)), dtype=np.int\n",
    "    ) - 1\n",
    "    \n",
    "    for i, x in enumerate(dtimes):\n",
    "        j = index_below[i - 1] if i > 0 else 0\n",
    "        while x - dtimes[j] > interval:\n",
    "            j += 1\n",
    "\n",
    "        index_below[i] = j\n",
    "        index_above[j] = i\n",
    "\n",
    "    last_above = index_above[0]\n",
    "    for i in range(len(dtimes)):\n",
    "        if index_above[i] < 0:\n",
    "            index_above[i] = last_above\n",
    "        else:\n",
    "            last_above = index_above[i]\n",
    "    \n",
    "    return index_above, index_below\n",
    "\n",
    "\n",
    "def compute_trend(df, columns, interval=3600):\n",
    "    df = df.sort_values('datetime')\n",
    "    for z in df.z.unique():  \n",
    "        this_level = df[df.z == z]\n",
    "        index_above, index_below = make_index(this_level.datetime.values, interval)\n",
    "\n",
    "        for col in columns:\n",
    "            val_above = this_level[col].values\n",
    "            val_below = this_level.iloc[index_below][col].values\n",
    "\n",
    "            time_above = this_level.datetime.values\n",
    "            time_below = this_level.iloc[index_below].datetime.values\n",
    "\n",
    "            trend = 3600 * (val_above - val_below) / (time_above - time_below)\n",
    "\n",
    "            df.loc[df.z == z, col + '_trend'] = trend\n",
    "\n",
    "    return df, [col + '_trend' for col in columns]\n",
    "\n",
    "\n",
    "def get_features(df, use_trend, feature_level):\n",
    "    wind_temp_levels = df.pivot_table(\n",
    "        values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "    ).reset_index()\n",
    "    wind_temp_levels.columns = [\n",
    "        '%s_%d' % (a, b) if b else a\n",
    "        for a, b in wind_temp_levels.columns.values\n",
    "    ]\n",
    "\n",
    "    df = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "\n",
    "    feature_sets = [\n",
    "        [\n",
    "            'z', 'wind', 'temp', 'soil_temp',\n",
    "            'wind_10', 'wind_20', 'wind_40',\n",
    "            'temp_10', 'temp_20', 'temp_40',\n",
    "        ],\n",
    "        ['soilheat'],\n",
    "        ['netrad'],\n",
    "        ['rain', 'dewpoint'],\n",
    "        ['H', 'LE'],\n",
    "    ]\n",
    "\n",
    "    features = [\n",
    "        f for fset in feature_sets[:feature_level]\n",
    "        for f in fset\n",
    "    ]\n",
    "\n",
    "    if use_trend:\n",
    "        df, added_cols = compute_trend(df, [\n",
    "            f for f in features if f != 'z'\n",
    "        ])\n",
    "        features.extend(added_cols)\n",
    "        \n",
    "    return df, features\n",
    "\n",
    "\n",
    "def get_train_test_data_my_random_months(df, features, target, n_months=18):\n",
    "    test_ds = np.random.choice(df.ds.unique(), n_months, replace=False)\n",
    "    test_mask = df.ds.isin(test_ds)\n",
    "\n",
    "    train_x, train_y = df.loc[~test_mask, features], df.loc[~test_mask, target]\n",
    "    test_x, test_y = df.loc[test_mask, features], df.loc[test_mask, target]\n",
    "\n",
    "    mean_x, mean_y = train_x.mean(), train_y.mean()\n",
    "    std_x, std_y = train_x.std(), train_y.std()\n",
    "\n",
    "    train_x = (train_x - mean_x) / std_x\n",
    "    test_x = (test_x - mean_x) / std_x\n",
    "    \n",
    "    assert np.all(np.isfinite(train_x))\n",
    "    assert np.all(np.isfinite(test_x))\n",
    "    \n",
    "    train_y = (train_y - mean_y) / std_y\n",
    "    test_y = (test_y - mean_y) / std_y\n",
    "\n",
    "    return features, train_x, train_y, test_x, test_y, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeKFold:\n",
    "    ''' k-fold cross validator splitting on a particular attribute\n",
    "        so that all samples with a given value are either in the train or test set\n",
    "\n",
    "        attribute value for each sample is given in the constructor, so that\n",
    "        the attribute itself need not be in the features for the model\n",
    "    '''\n",
    "    def __init__(self, cv, attr):\n",
    "        self.cv, self.attr = cv, attr\n",
    "\n",
    "    def get_n_splits(self, *args, **kwargs):\n",
    "        return self.cv.get_n_splits(*args, **kwargs)\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        vals = self.attr.unique()\n",
    "        for train_idx, test_idx in self.cv.split(vals):\n",
    "            train_mask = self.attr.isin(vals[train_idx])\n",
    "            test_mask = self.attr.isin(vals[test_idx])\n",
    "\n",
    "            X = np.argwhere(train_mask).reshape(-1)\n",
    "            y = np.argwhere(test_mask).reshape(-1)\n",
    "            \n",
    "            assert np.all(np.isfinite(X))\n",
    "            assert np.all(np.isfinite(y))\n",
    "            \n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_denormalized_mse(std_y):\n",
    "    def denormalized_mse(y_true, y_pred):\n",
    "        # model is trained with normalized data, but we want\n",
    "        # mse on not normalized data to compare with MOST\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "        return mse * std_y**2\n",
    "    return denormalized_mse\n",
    "\n",
    "\n",
    "def orthonormal_regularizer(regu):\n",
    "    # eq. 3 in https://arxiv.org/pdf/1703.01827.pdf\n",
    "    def compute(weight_matrix):\n",
    "        rows, cols = weight_matrix.shape\n",
    "        wtw = K.dot(K.transpose(weight_matrix), weight_matrix)\n",
    "        return regu * K.sum((wtw - K.eye(cols.value))**2) / 2\n",
    "    return compute\n",
    "\n",
    "\n",
    "def build_model(sizes, std_y=1):\n",
    "    # every element in sizes specifies a layer\n",
    "    #   negative number: skip connection of -n layers\n",
    "    #                    successive skips are aggregated\n",
    "    #                    into a single layer\n",
    "    #   0<n<1: dropout with pkeep=n\n",
    "    #   >1 fully connected then prelu\n",
    "    layers = [Input(shape=(sizes[0],)),]\n",
    "    #layers.append(GaussianNoise(0.01)(layers[-1]))\n",
    "    i = 1\n",
    "    while i < len(sizes):\n",
    "        num = sizes[i]\n",
    "        if num < 0:\n",
    "            skip = [layers[-1]]\n",
    "            while i < len(sizes) and sizes[i] < 0:\n",
    "                skip.append(layers[sizes[i] - 1])\n",
    "                i += 1\n",
    "            layer = Concatenate()(skip)\n",
    "            i -= 1\n",
    "        elif num < 1:\n",
    "            layer = Dropout(num)(layers[-1])\n",
    "        else:\n",
    "            layer = PReLU()(\n",
    "                Dense(num, kernel_initializer=VarianceScaling(2, 'fan_in'))(\n",
    "                    layers[-1]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        layers.append(layer)\n",
    "        i += 1\n",
    "\n",
    "    layers.append(Dense(1)(layers[-1]))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model = Model(inputs=layers[0], outputs=layers[-1])\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=[compute_denormalized_mse(std_y)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(network, use_trend, feature_level, batch_size=1024, verbose=2, most_only=False):\n",
    "    ddf, features = get_features(df.dropna(), use_trend, feature_level)\n",
    "    if most_only:\n",
    "        ddf = ddf[(ddf.zL > -2) & (ddf.zL < 1)]\n",
    "    features, train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test_data_my_random_months(\n",
    "        ddf, features, 'phi_m'\n",
    "    )\n",
    "\n",
    "    K.clear_session()  # https://stackoverflow.com/q/35114376/521776\n",
    "    model = build_model([len(features)] + network, std_y=std_y)\n",
    "\n",
    "    dtime = datetime.datetime.utcnow().isoformat().replace('-', '').replace(':', '').replace('T', '-')[:-7]\n",
    "    logdir = 'dev/logs/%s-tren%s-features%s-batchsize%s-nparam%s/' % (\n",
    "        dtime, use_trend, feature_level, batch_size, model.count_params()\n",
    "    )\n",
    "\n",
    "    if verbose > 0:\n",
    "        print('Saving to', logdir)\n",
    "\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(factor=0.1, verbose=verbose, min_lr=1e-6, patience=10),\n",
    "        ModelCheckpoint(logdir + 'best.hdf5', verbose=verbose, save_best_only=True),\n",
    "        TensorBoard(logdir, write_graph=True, write_grads=True, histogram_freq=0),\n",
    "        EarlyStopping(min_delta=0.0001, patience=25),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_x, train_y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1000,\n",
    "        verbose=verbose,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(test_x, test_y)\n",
    "    )\n",
    "\n",
    "    return hist, logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data_by_index(df, features, target, train_idx, test_idx, normalize):\n",
    "    train_x, train_y = df.iloc[train_idx][features], df.iloc[train_idx][target]\n",
    "    test_x, test_y = df.iloc[test_idx][features], df.iloc[test_idx][target]\n",
    "\n",
    "    if normalize:\n",
    "        mean_x, std_x = train_x.mean(), train_x.std()\n",
    "        train_x = (train_x - mean_x) / std_x\n",
    "        test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "        mean_y, std_y = train_y.mean(), train_y.std()\n",
    "        train_y = (train_y - mean_y) / std_y\n",
    "        test_y = (test_y - mean_y) / std_y\n",
    "    else:\n",
    "        mean_y, std_y = 0, 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y\n",
    "\n",
    "\n",
    "def run_cv(network, use_trend, feature_level, most_only, batch_size=1024, cv_folds=5, verbose=0):\n",
    "    ddf, features = get_features(df.dropna(), use_trend, feature_level)\n",
    "    finite = np.isfinite(ddf[features]).all(axis=1)\n",
    "    ddf = ddf.loc[finite]\n",
    "    if most_only:\n",
    "        ddf = ddf[(ddf.zL > -2) & (ddf.zL < 1)]\n",
    "\n",
    "    cv = AttributeKFold(KFold(cv_folds, shuffle=True), ddf.ds)\n",
    "    results = []\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(cv.split(ddf.ds)):\n",
    "\n",
    "        # prepare data\n",
    "        train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test_data_by_index(\n",
    "            ddf, features, 'phi_m', train_idx, test_idx, normalize=True\n",
    "        )\n",
    "\n",
    "        K.clear_session()  # https://stackoverflow.com/q/35114376/521776\n",
    "        model = build_model([len(features)] + network, std_y=std_y)\n",
    "        dtime = datetime.datetime.utcnow().isoformat().replace('-', '').replace(':', '').replace('T', '-')[:-7]\n",
    "        logdir = 'dev/logs/%s-tren%s-features%s-batchsize%s-nparam%s-cv%d/' % (\n",
    "            dtime, use_trend, feature_level, batch_size, model.count_params(), cv_idx\n",
    "        )\n",
    "        save_to = logdir + 'best.hdf5'\n",
    "        if verbose > 0:\n",
    "            print('Saving to', logdir)\n",
    "\n",
    "        # fit to train data\n",
    "        hist = model.fit(\n",
    "            train_x, train_y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=500,\n",
    "            verbose=verbose,\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                ReduceLROnPlateau(factor=0.1, verbose=verbose, min_lr=1e-6, patience=10),\n",
    "                ModelCheckpoint(save_to, verbose=verbose, save_best_only=True),\n",
    "                TensorBoard(logdir, write_graph=True, write_grads=True, histogram_freq=0),\n",
    "                EarlyStopping(min_delta=0.0001, patience=25),\n",
    "            ],\n",
    "            validation_data=(test_x, test_y)\n",
    "        )\n",
    "        \n",
    "        # evaluate on test data\n",
    "        best = load_model(logdir + 'best.hdf5', custom_objects={\n",
    "            'denormalized_mse': compute_denormalized_mse(std_y)\n",
    "        })\n",
    "\n",
    "        y_pred = best.predict(test_x)\n",
    "        y_pred = y_pred * std_y + mean_y\n",
    "        test_y = test_y * std_y + mean_y\n",
    "        \n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        test_y = test_y.values.reshape(-1)\n",
    "\n",
    "        results.append((\n",
    "            metrics.explained_variance_score(test_y, y_pred),\n",
    "            metrics.mean_absolute_error(test_y, y_pred),\n",
    "            metrics.mean_squared_error(test_y, y_pred),\n",
    "            metrics.median_absolute_error(test_y, y_pred),\n",
    "            metrics.r2_score(test_y, y_pred),\n",
    "            np.mean(np.abs((test_y - y_pred) / test_y)) * 100,\n",
    "        ))\n",
    "    \n",
    "    return pd.DataFrame(results, columns=[\n",
    "        'explained_variance', 'mean_absolute_error', 'mean_squared_error',\n",
    "        'median_absolute_error', 'r2_score', 'mean_absolute_percent_error'\n",
    "    ])\n",
    "\n",
    "\n",
    "def test_setting(use_trend, feature_level, most_only, batch_size=1024, cv_folds=10, verbose=0):\n",
    "    # test all models on the given setting\n",
    "    models = [\n",
    "        [128, 64, 32, 16, 8, 4, 2, 1],\n",
    "        [256, 0.5, 128, 64, 32, 16, 8, 4, 2, 1],\n",
    "        [256, 0.5, 128, 64, 64, 32, 16, 8, 4, 2, 1], \n",
    "        [256, 0.5, 128, 64, 64, 32, 32, 16, 8, 4, 2, 1],\n",
    "        [512, 0.5, 256, 0.5, 128, 64, 32, 16, 8, 4, 2, 1],\n",
    "        [256, 0.5, 128, 64, 64, 32, 32, 16, 8, 4, 2, 1],\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for i, mod in enumerate(models):\n",
    "        res = run_cv(\n",
    "            mod, use_trend, feature_level, most_only, batch_size, cv_folds, verbose\n",
    "        )\n",
    "        print('----  model', i)\n",
    "        print(res.describe().T)\n",
    "        results.append(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----  model 0\n",
      "                             count       mean        std        min  \\\n",
      "explained_variance            10.0   0.845168   0.007878   0.836138   \n",
      "mean_absolute_error           10.0   0.223719   0.009633   0.209812   \n",
      "mean_squared_error            10.0   0.128021   0.010448   0.114250   \n",
      "median_absolute_error         10.0   0.139679   0.006043   0.131263   \n",
      "r2_score                      10.0   0.845037   0.007892   0.836013   \n",
      "mean_absolute_percent_error   10.0  66.382704  33.606492  43.173563   \n",
      "\n",
      "                                   25%        50%        75%         max  \n",
      "explained_variance            0.838149   0.843280   0.852672    0.855499  \n",
      "mean_absolute_error           0.216687   0.223827   0.230371    0.237424  \n",
      "mean_squared_error            0.119943   0.126748   0.133647    0.144310  \n",
      "median_absolute_error         0.134649   0.138898   0.145076    0.147642  \n",
      "r2_score                      0.837851   0.843267   0.852616    0.855380  \n",
      "mean_absolute_percent_error  46.180267  57.525448  65.353390  155.455487  \n",
      "----  model 1\n",
      "                             count       mean        std        min  \\\n",
      "explained_variance            10.0   0.849341   0.008675   0.837494   \n",
      "mean_absolute_error           10.0   0.223451   0.011967   0.202291   \n",
      "mean_squared_error            10.0   0.124951   0.013737   0.102776   \n",
      "median_absolute_error         10.0   0.142705   0.008627   0.129971   \n",
      "r2_score                      10.0   0.848895   0.008900   0.837316   \n",
      "mean_absolute_percent_error   10.0  74.169490  40.042720  39.615708   \n",
      "\n",
      "                                   25%        50%        75%         max  \n",
      "explained_variance            0.840806   0.851612   0.856238    0.860060  \n",
      "mean_absolute_error           0.214451   0.224468   0.232795    0.240164  \n",
      "mean_squared_error            0.114622   0.126659   0.133399    0.148540  \n",
      "median_absolute_error         0.137114   0.141694   0.147309    0.159905  \n",
      "r2_score                      0.839451   0.851342   0.856229    0.859164  \n",
      "mean_absolute_percent_error  48.647798  60.498757  83.026402  174.804220  \n",
      "----  model 2\n",
      "                             count       mean        std        min  \\\n",
      "explained_variance            10.0   0.847128   0.007022   0.835482   \n",
      "mean_absolute_error           10.0   0.225377   0.009479   0.212866   \n",
      "mean_squared_error            10.0   0.126653   0.009636   0.113132   \n",
      "median_absolute_error         10.0   0.145031   0.008707   0.135036   \n",
      "r2_score                      10.0   0.846787   0.007323   0.834582   \n",
      "mean_absolute_percent_error   10.0  70.316401  31.162344  41.907996   \n",
      "\n",
      "                                   25%        50%        75%         max  \n",
      "explained_variance            0.842521   0.848086   0.851120    0.857525  \n",
      "mean_absolute_error           0.218237   0.224545   0.229613    0.243249  \n",
      "mean_squared_error            0.120923   0.126739   0.130747    0.143580  \n",
      "median_absolute_error         0.138639   0.140918   0.152453    0.160479  \n",
      "r2_score                      0.842106   0.847788   0.850996    0.857523  \n",
      "mean_absolute_percent_error  56.546353  58.030542  68.631505  149.525413  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not operate array([1.21437722e+01, 2.68556354e+00, 6.13142094e+00, 5.47967716e+00,\n       2.34921918e+00, 2.54741347e+00, 2.75082854e+00, 6.16887242e+00,\n       6.12081704e+00, 6.07938917e+00, 1.27679213e+01, 1.60938388e+02,\n       1.30745856e-01, 5.60341478e+00, 4.70466667e+01, 1.10642087e+02,\n       1.33562232e+00, 7.89776570e-01, 2.82331789e-01, 1.24140715e+00,\n       1.33764925e+00, 1.43687907e+00, 8.07513164e-01, 7.85138730e-01,\n       7.63359860e-01, 4.75344300e+00, 8.41352168e+01, 2.21128149e-01,\n       9.35291275e-01, 2.83899059e+01, 6.27276580e+01]) with block values ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, errors, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(other)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-451a9f5d3760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0muse_trend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeature_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmost_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-22-e7334dd3fea9>\u001b[0m in \u001b[0;36mtest_setting\u001b[0;34m(use_trend, feature_level, most_only, batch_size, cv_folds, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         res = run_cv(\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_trend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----  model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e7334dd3fea9>\u001b[0m in \u001b[0;36mrun_cv\u001b[0;34m(network, use_trend, feature_level, most_only, batch_size, cv_folds, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test_data_by_index(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mddf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'phi_m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e7334dd3fea9>\u001b[0m in \u001b[0;36mget_train_test_data_by_index\u001b[0;34m(df, features, target, train_idx, test_idx, normalize)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level, try_cast)\u001b[0m\n\u001b[1;32m   3942\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[1;32m   3943\u001b[0m                                           \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3944\u001b[0;31m                                           try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m     def _combine_series_infer(self, other, func, level=None,\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series_infer\u001b[0;34m(self, other, func, level, fill_value, try_cast)\u001b[0m\n\u001b[1;32m   3956\u001b[0m         return self._combine_match_columns(other, func, level=level,\n\u001b[1;32m   3957\u001b[0m                                            \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3958\u001b[0;31m                                            try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m     def _combine_match_index(self, other, func, level=None,\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value, try_cast)\u001b[0m\n\u001b[1;32m   3979\u001b[0m         new_data = left._data.eval(func=func, other=right,\n\u001b[1;32m   3980\u001b[0m                                    \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3981\u001b[0;31m                                    try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3982\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3329\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3330\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, errors, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m         \u001b[0;31m# technically a broadcast error in numpy can 'work' by returning a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mhandle_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1365\u001b[0m                 \u001b[0;31m# The 'detail' variable is defined in outer scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 raise TypeError('Could not operate %s with block values %s' %\n\u001b[0;32m-> 1367\u001b[0;31m                                 (repr(other), str(detail)))  # noqa\n\u001b[0m\u001b[1;32m   1368\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0;31m# return the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not operate array([1.21437722e+01, 2.68556354e+00, 6.13142094e+00, 5.47967716e+00,\n       2.34921918e+00, 2.54741347e+00, 2.75082854e+00, 6.16887242e+00,\n       6.12081704e+00, 6.07938917e+00, 1.27679213e+01, 1.60938388e+02,\n       1.30745856e-01, 5.60341478e+00, 4.70466667e+01, 1.10642087e+02,\n       1.33562232e+00, 7.89776570e-01, 2.82331789e-01, 1.24140715e+00,\n       1.33764925e+00, 1.43687907e+00, 8.07513164e-01, 7.85138730e-01,\n       7.63359860e-01, 4.75344300e+00, 8.41352168e+01, 2.21128149e-01,\n       9.35291275e-01, 2.83899059e+01, 6.27276580e+01]) with block values "
     ]
    }
   ],
   "source": [
    "rt5m = test_setting(\n",
    "    use_trend=True,\n",
    "    feature_level=5,\n",
    "    most_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
