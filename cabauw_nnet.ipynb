{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "import pandas as pd\n",
    "from hkfold import HKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import PReLU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe_path = 'data/cabauw/processed.csv.gz'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(dframe_path, na_values='--')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(dframe_path, na_values='--', compression='gzip')\n",
    "\n",
    "\n",
    "df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "df = df[df.ds != 201603]\n",
    "#df = df.sort_values(['ds', 'tt'])\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1)  # aka shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1022889 (76.9%) samples, testing with 26602 (2.0%), 280601 (21.1%) samples lost\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'dewpoint', 'spec_hum', 'rel_hum', 'press', 'rain',\n",
    "    'air_dens', 'wind', 'temp', 'virtual_temp', 'soil_temp', 'z',\n",
    "    #'ustar', 'H', 'LE', 'zL_m', 'lval'\n",
    "]\n",
    "\n",
    "target = 'phi_m'\n",
    "\n",
    "train_idx, test_idx = next(HKFold(KFold(50, shuffle=True), h=int(1 * 60 / 10)).split(df))\n",
    "\n",
    "nr, ne, nn = len(train_idx), len(test_idx), len(df)\n",
    "print('training with %d (%.1f%%) samples, testing with %d (%.1f%%), %d (%.1f%%) samples lost' % (\n",
    "    nr, 100 * nr / nn, ne, 100 * ne / nn, nn - nr - ne, 100 * (nn - nr - ne) / nn\n",
    "))\n",
    "\n",
    "train_x, train_y = df[features].iloc[train_idx], df[target].iloc[train_idx]\n",
    "test_x, test_y = df[features].iloc[test_idx], df[target].iloc[test_idx]\n",
    "\n",
    "mean_x, mean_y = train_x.mean(), train_y.mean()\n",
    "std_x, std_y = train_x.std(), train_y.std()\n",
    "\n",
    "train_x = (train_x - mean_x) /  std_x\n",
    "test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "#train_y = (train_y - mean_y) / std_y\n",
    "#test_y = (test_y - mean_y) / std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1024)              12288     \n",
      "_________________________________________________________________\n",
      "p_re_lu_15 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "p_re_lu_16 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "p_re_lu_17 (PReLU)           (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "p_re_lu_18 (PReLU)           (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "p_re_lu_19 (PReLU)           (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "p_re_lu_20 (PReLU)           (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "p_re_lu_21 (PReLU)           (None, 32)                32        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,446,497\n",
      "Trainable params: 1,446,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(1024, input_shape=(len(features),)), PReLU(),\n",
    "    Dense(1024), PReLU(),\n",
    "    Dense(256), PReLU(),\n",
    "    Dense(256), PReLU(),\n",
    "    Dense(128), PReLU(),\n",
    "    Dense(128), PReLU(),\n",
    "    Dense(32), PReLU(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022889 samples, validate on 26602 samples\n",
      "Epoch 1/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 1.3702\n",
      "Epoch 00001: val_loss improved from inf to 0.73347, saving model to weights.01-0.73.hdf5\n",
      "1022889/1022889 [==============================] - 21s 21us/step - loss: 1.3681 - val_loss: 0.7335\n",
      "Epoch 2/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.6879\n",
      "Epoch 00002: val_loss improved from 0.73347 to 0.71025, saving model to weights.02-0.71.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.6873 - val_loss: 0.7103\n",
      "Epoch 3/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 00003: val_loss improved from 0.71025 to 0.45091, saving model to weights.03-0.45.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.5607 - val_loss: 0.4509\n",
      "Epoch 4/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.5043\n",
      "Epoch 00004: val_loss improved from 0.45091 to 0.38986, saving model to weights.04-0.39.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.5039 - val_loss: 0.3899\n",
      "Epoch 5/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.4627\n",
      "Epoch 00005: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.4628 - val_loss: 0.4099\n",
      "Epoch 6/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.4303\n",
      "Epoch 00006: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.4303 - val_loss: 0.5124\n",
      "Epoch 7/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.4039\n",
      "Epoch 00007: val_loss improved from 0.38986 to 0.36172, saving model to weights.07-0.36.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.4041 - val_loss: 0.3617\n",
      "Epoch 8/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.3795\n",
      "Epoch 00008: val_loss improved from 0.36172 to 0.31307, saving model to weights.08-0.31.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.3792 - val_loss: 0.3131\n",
      "Epoch 9/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.3569\n",
      "Epoch 00009: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.3568 - val_loss: 0.3274\n",
      "Epoch 10/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.3346\n",
      "Epoch 00010: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.3346 - val_loss: 0.3683\n",
      "Epoch 11/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.3154\n",
      "Epoch 00011: val_loss improved from 0.31307 to 0.27564, saving model to weights.11-0.28.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.3154 - val_loss: 0.2756\n",
      "Epoch 12/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2980\n",
      "Epoch 00012: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.2979 - val_loss: 0.3039\n",
      "Epoch 13/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2830\n",
      "Epoch 00013: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2829 - val_loss: 0.3288\n",
      "Epoch 14/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2695\n",
      "Epoch 00014: val_loss improved from 0.27564 to 0.23660, saving model to weights.14-0.24.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.2694 - val_loss: 0.2366\n",
      "Epoch 15/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2530\n",
      "Epoch 00015: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2528 - val_loss: 0.2425\n",
      "Epoch 16/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2431\n",
      "Epoch 00016: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2432 - val_loss: 0.2856\n",
      "Epoch 17/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2306\n",
      "Epoch 00017: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2306 - val_loss: 0.3098\n",
      "Epoch 18/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2205\n",
      "Epoch 00018: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2207 - val_loss: 0.2514\n",
      "Epoch 19/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2105\n",
      "Epoch 00019: val_loss improved from 0.23660 to 0.19570, saving model to weights.19-0.20.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2105 - val_loss: 0.1957\n",
      "Epoch 20/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.2029\n",
      "Epoch 00020: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.2032 - val_loss: 0.2198\n",
      "Epoch 21/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1941\n",
      "Epoch 00021: val_loss improved from 0.19570 to 0.15979, saving model to weights.21-0.16.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1940 - val_loss: 0.1598\n",
      "Epoch 22/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1883\n",
      "Epoch 00022: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1883 - val_loss: 0.1987\n",
      "Epoch 23/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1802\n",
      "Epoch 00023: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1805 - val_loss: 0.2310\n",
      "Epoch 24/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1750\n",
      "Epoch 00024: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1749 - val_loss: 0.1624\n",
      "Epoch 25/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1700\n",
      "Epoch 00025: val_loss improved from 0.15979 to 0.15796, saving model to weights.25-0.16.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1700 - val_loss: 0.1580\n",
      "Epoch 26/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1643\n",
      "Epoch 00026: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1643 - val_loss: 0.1769\n",
      "Epoch 27/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1599\n",
      "Epoch 00027: val_loss improved from 0.15796 to 0.13815, saving model to weights.27-0.14.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1597 - val_loss: 0.1381\n",
      "Epoch 28/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1547\n",
      "Epoch 00028: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 29/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1510\n",
      "Epoch 00029: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1510 - val_loss: 0.1566\n",
      "Epoch 30/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1463\n",
      "Epoch 00030: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1464 - val_loss: 0.1932\n",
      "Epoch 31/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1429\n",
      "Epoch 00031: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.1430 - val_loss: 0.1599\n",
      "Epoch 32/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1396\n",
      "Epoch 00032: val_loss improved from 0.13815 to 0.13492, saving model to weights.32-0.13.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1396 - val_loss: 0.1349\n",
      "Epoch 33/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1373\n",
      "Epoch 00033: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1373 - val_loss: 0.1373\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1326\n",
      "Epoch 00034: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1328 - val_loss: 0.2172\n",
      "Epoch 35/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1308\n",
      "Epoch 00035: val_loss improved from 0.13492 to 0.12200, saving model to weights.35-0.12.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1307 - val_loss: 0.1220\n",
      "Epoch 36/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1279\n",
      "Epoch 00036: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1279 - val_loss: 0.1376\n",
      "Epoch 37/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1248\n",
      "Epoch 00037: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1248 - val_loss: 0.1356\n",
      "Epoch 38/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1230\n",
      "Epoch 00038: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1230 - val_loss: 0.1731\n",
      "Epoch 39/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1198\n",
      "Epoch 00039: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1198 - val_loss: 0.1317\n",
      "Epoch 40/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1181\n",
      "Epoch 00040: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1183 - val_loss: 0.2131\n",
      "Epoch 41/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1159\n",
      "Epoch 00041: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1159 - val_loss: 0.1226\n",
      "Epoch 42/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1134\n",
      "Epoch 00042: val_loss improved from 0.12200 to 0.11690, saving model to weights.42-0.12.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.1134 - val_loss: 0.1169\n",
      "Epoch 43/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1114\n",
      "Epoch 00043: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.1115 - val_loss: 0.1666\n",
      "Epoch 44/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1090\n",
      "Epoch 00044: val_loss improved from 0.11690 to 0.10768, saving model to weights.44-0.11.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.1089 - val_loss: 0.1077\n",
      "Epoch 45/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1076\n",
      "Epoch 00045: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1076 - val_loss: 0.1336\n",
      "Epoch 46/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1061\n",
      "Epoch 00046: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1060 - val_loss: 0.1114\n",
      "Epoch 47/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1042\n",
      "Epoch 00047: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1041 - val_loss: 0.1331\n",
      "Epoch 48/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1029\n",
      "Epoch 00048: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.1029 - val_loss: 0.1089\n",
      "Epoch 49/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.1007\n",
      "Epoch 00049: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.1007 - val_loss: 0.1133\n",
      "Epoch 50/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0998\n",
      "Epoch 00050: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0999 - val_loss: 0.1181\n",
      "Epoch 51/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0984\n",
      "Epoch 00051: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0985 - val_loss: 0.1403\n",
      "Epoch 52/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0967\n",
      "Epoch 00052: val_loss improved from 0.10768 to 0.09659, saving model to weights.52-0.10.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0967 - val_loss: 0.0966\n",
      "Epoch 53/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0952\n",
      "Epoch 00053: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0952 - val_loss: 0.0994\n",
      "Epoch 54/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0943\n",
      "Epoch 00054: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0945 - val_loss: 0.1226\n",
      "Epoch 55/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0930\n",
      "Epoch 00055: val_loss improved from 0.09659 to 0.09222, saving model to weights.55-0.09.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0930 - val_loss: 0.0922\n",
      "Epoch 56/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0917\n",
      "Epoch 00056: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0918 - val_loss: 0.1057\n",
      "Epoch 57/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0905\n",
      "Epoch 00057: val_loss improved from 0.09222 to 0.08634, saving model to weights.57-0.09.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0905 - val_loss: 0.0863\n",
      "Epoch 58/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0886\n",
      "Epoch 00058: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0885 - val_loss: 0.0918\n",
      "Epoch 59/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0876\n",
      "Epoch 00059: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0876 - val_loss: 0.0964\n",
      "Epoch 60/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0871\n",
      "Epoch 00060: val_loss improved from 0.08634 to 0.08325, saving model to weights.60-0.08.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0870 - val_loss: 0.0833\n",
      "Epoch 61/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0850\n",
      "Epoch 00061: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0850 - val_loss: 0.1162\n",
      "Epoch 62/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0848\n",
      "Epoch 00062: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0848 - val_loss: 0.1047\n",
      "Epoch 63/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0839\n",
      "Epoch 00063: val_loss improved from 0.08325 to 0.07906, saving model to weights.63-0.08.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0838 - val_loss: 0.0791\n",
      "Epoch 64/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0833\n",
      "Epoch 00064: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0833 - val_loss: 0.0933\n",
      "Epoch 65/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0821\n",
      "Epoch 00065: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0821 - val_loss: 0.0934\n",
      "Epoch 66/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0809\n",
      "Epoch 00066: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0810 - val_loss: 0.0975\n",
      "Epoch 67/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0798\n",
      "Epoch 00067: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0798 - val_loss: 0.0915\n",
      "Epoch 68/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0794\n",
      "Epoch 00068: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0794 - val_loss: 0.0952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0787\n",
      "Epoch 00069: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0787 - val_loss: 0.0875\n",
      "Epoch 70/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0777\n",
      "Epoch 00070: val_loss improved from 0.07906 to 0.07045, saving model to weights.70-0.07.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0776 - val_loss: 0.0704\n",
      "Epoch 71/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0764\n",
      "Epoch 00071: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0764 - val_loss: 0.0873\n",
      "Epoch 72/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0764\n",
      "Epoch 00072: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0764 - val_loss: 0.0874\n",
      "Epoch 73/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0749\n",
      "Epoch 00073: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0749 - val_loss: 0.0880\n",
      "Epoch 74/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0741\n",
      "Epoch 00074: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0741 - val_loss: 0.0773\n",
      "Epoch 75/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0738\n",
      "Epoch 00075: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0737 - val_loss: 0.0785\n",
      "Epoch 76/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0729\n",
      "Epoch 00076: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0728 - val_loss: 0.0705\n",
      "Epoch 77/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0721\n",
      "Epoch 00077: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0721 - val_loss: 0.0865\n",
      "Epoch 78/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0715\n",
      "Epoch 00078: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0716 - val_loss: 0.0962\n",
      "Epoch 79/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0707\n",
      "Epoch 00079: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0707 - val_loss: 0.0880\n",
      "Epoch 80/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0701\n",
      "Epoch 00080: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0701 - val_loss: 0.0742\n",
      "Epoch 81/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0697\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0697 - val_loss: 0.0865\n",
      "Epoch 82/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0377\n",
      "Epoch 00082: val_loss improved from 0.07045 to 0.04134, saving model to weights.82-0.04.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0377 - val_loss: 0.0413\n",
      "Epoch 83/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0327\n",
      "Epoch 00083: val_loss improved from 0.04134 to 0.03978, saving model to weights.83-0.04.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0328 - val_loss: 0.0398\n",
      "Epoch 84/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0308\n",
      "Epoch 00084: val_loss improved from 0.03978 to 0.03671, saving model to weights.84-0.04.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0308 - val_loss: 0.0367\n",
      "Epoch 85/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0293\n",
      "Epoch 00085: val_loss improved from 0.03671 to 0.03545, saving model to weights.85-0.04.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0293 - val_loss: 0.0354\n",
      "Epoch 86/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0281\n",
      "Epoch 00086: val_loss improved from 0.03545 to 0.03377, saving model to weights.86-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0281 - val_loss: 0.0338\n",
      "Epoch 87/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0270\n",
      "Epoch 00087: val_loss improved from 0.03377 to 0.03309, saving model to weights.87-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0270 - val_loss: 0.0331\n",
      "Epoch 88/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0261\n",
      "Epoch 00088: val_loss improved from 0.03309 to 0.03161, saving model to weights.88-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0261 - val_loss: 0.0316\n",
      "Epoch 89/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00089: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0253 - val_loss: 0.0317\n",
      "Epoch 90/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0245\n",
      "Epoch 00090: val_loss improved from 0.03161 to 0.03046, saving model to weights.90-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0245 - val_loss: 0.0305\n",
      "Epoch 91/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0239\n",
      "Epoch 00091: val_loss improved from 0.03046 to 0.02886, saving model to weights.91-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0239 - val_loss: 0.0289\n",
      "Epoch 92/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0233\n",
      "Epoch 00092: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0233 - val_loss: 0.0293\n",
      "Epoch 93/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0227\n",
      "Epoch 00093: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0227 - val_loss: 0.0289\n",
      "Epoch 94/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0221\n",
      "Epoch 00094: val_loss improved from 0.02886 to 0.02719, saving model to weights.94-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 95/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00095: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0216 - val_loss: 0.0274\n",
      "Epoch 96/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0212\n",
      "Epoch 00096: val_loss improved from 0.02719 to 0.02714, saving model to weights.96-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0212 - val_loss: 0.0271\n",
      "Epoch 97/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0207\n",
      "Epoch 00097: val_loss improved from 0.02714 to 0.02533, saving model to weights.97-0.03.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0207 - val_loss: 0.0253\n",
      "Epoch 98/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0203\n",
      "Epoch 00098: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0203 - val_loss: 0.0258\n",
      "Epoch 99/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00099: val_loss improved from 0.02533 to 0.02497, saving model to weights.99-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 100/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00100: val_loss improved from 0.02497 to 0.02406, saving model to weights.100-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 101/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00101: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0192 - val_loss: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0189\n",
      "Epoch 00102: val_loss improved from 0.02406 to 0.02374, saving model to weights.102-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0189 - val_loss: 0.0237\n",
      "Epoch 103/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0185\n",
      "Epoch 00103: val_loss improved from 0.02374 to 0.02325, saving model to weights.103-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0185 - val_loss: 0.0232\n",
      "Epoch 104/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00104: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0183 - val_loss: 0.0241\n",
      "Epoch 105/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00105: val_loss improved from 0.02325 to 0.02289, saving model to weights.105-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0180 - val_loss: 0.0229\n",
      "Epoch 106/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00106: val_loss improved from 0.02289 to 0.02227, saving model to weights.106-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0177 - val_loss: 0.0223\n",
      "Epoch 107/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0175\n",
      "Epoch 00107: val_loss improved from 0.02227 to 0.02182, saving model to weights.107-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 108/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0172\n",
      "Epoch 00108: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0172 - val_loss: 0.0224\n",
      "Epoch 109/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0169\n",
      "Epoch 00109: val_loss improved from 0.02182 to 0.02143, saving model to weights.109-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0169 - val_loss: 0.0214\n",
      "Epoch 110/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00110: val_loss improved from 0.02143 to 0.02081, saving model to weights.110-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0167 - val_loss: 0.0208\n",
      "Epoch 111/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00111: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0165 - val_loss: 0.0216\n",
      "Epoch 112/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00112: val_loss improved from 0.02081 to 0.02023, saving model to weights.112-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0163 - val_loss: 0.0202\n",
      "Epoch 113/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00113: val_loss improved from 0.02023 to 0.02013, saving model to weights.113-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 18s 17us/step - loss: 0.0161 - val_loss: 0.0201\n",
      "Epoch 114/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00114: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0160 - val_loss: 0.0204\n",
      "Epoch 115/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00115: val_loss improved from 0.02013 to 0.01907, saving model to weights.115-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0158 - val_loss: 0.0191\n",
      "Epoch 116/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00116: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 117/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00117: val_loss improved from 0.01907 to 0.01900, saving model to weights.117-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0154 - val_loss: 0.0190\n",
      "Epoch 118/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0152\n",
      "Epoch 00118: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0152 - val_loss: 0.0192\n",
      "Epoch 119/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00119: val_loss improved from 0.01900 to 0.01884, saving model to weights.119-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0151 - val_loss: 0.0188\n",
      "Epoch 120/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00120: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0148 - val_loss: 0.0193\n",
      "Epoch 121/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00121: val_loss improved from 0.01884 to 0.01838, saving model to weights.121-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0147 - val_loss: 0.0184\n",
      "Epoch 122/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00122: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0145 - val_loss: 0.0185\n",
      "Epoch 123/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00123: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 124/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00124: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0143 - val_loss: 0.0186\n",
      "Epoch 125/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00125: val_loss improved from 0.01838 to 0.01719, saving model to weights.125-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 126/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00126: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 127/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00127: val_loss improved from 0.01719 to 0.01715, saving model to weights.127-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 128/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00128: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0138 - val_loss: 0.0173\n",
      "Epoch 129/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00129: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 130/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00130: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0136 - val_loss: 0.0172\n",
      "Epoch 131/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0134\n",
      "Epoch 00131: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0134 - val_loss: 0.0182\n",
      "Epoch 132/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0133\n",
      "Epoch 00132: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 133/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0132\n",
      "Epoch 00133: val_loss improved from 0.01715 to 0.01702, saving model to weights.133-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 134/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00134: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0131 - val_loss: 0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0130\n",
      "Epoch 00135: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0130 - val_loss: 0.0174\n",
      "Epoch 136/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00136: val_loss improved from 0.01702 to 0.01657, saving model to weights.136-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 137/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00137: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0129 - val_loss: 0.0176\n",
      "Epoch 138/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00138: val_loss improved from 0.01657 to 0.01533, saving model to weights.138-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 139/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0126\n",
      "Epoch 00139: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 140/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0126\n",
      "Epoch 00140: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0126 - val_loss: 0.0170\n",
      "Epoch 141/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00141: val_loss improved from 0.01533 to 0.01508, saving model to weights.141-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 142/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00142: val_loss improved from 0.01508 to 0.01502, saving model to weights.142-0.02.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 143/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00143: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 144/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00144: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 145/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00145: val_loss improved from 0.01502 to 0.01436, saving model to weights.145-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 146/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00146: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 147/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00147: val_loss improved from 0.01436 to 0.01414, saving model to weights.147-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 148/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0118\n",
      "Epoch 00148: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 149/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0119\n",
      "Epoch 00149: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 150/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0118\n",
      "Epoch 00150: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0118 - val_loss: 0.0162\n",
      "Epoch 151/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00151: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 152/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00152: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 153/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00153: val_loss improved from 0.01414 to 0.01386, saving model to weights.153-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 154/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00154: val_loss improved from 0.01386 to 0.01384, saving model to weights.154-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 155/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00155: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0114 - val_loss: 0.0157\n",
      "Epoch 156/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0113\n",
      "Epoch 00156: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0114 - val_loss: 0.0152\n",
      "Epoch 157/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0113\n",
      "Epoch 00157: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 158/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00158: val_loss improved from 0.01384 to 0.01379, saving model to weights.158-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 159/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00159: val_loss improved from 0.01379 to 0.01368, saving model to weights.159-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 160/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00160: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 161/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00161: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 162/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00162: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0110 - val_loss: 0.0144\n",
      "Epoch 163/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00163: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 164/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00164: val_loss improved from 0.01368 to 0.01356, saving model to weights.164-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 165/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0108\n",
      "Epoch 00165: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 166/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0108\n",
      "Epoch 00166: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0108 - val_loss: 0.0137\n",
      "Epoch 167/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00167: val_loss improved from 0.01356 to 0.01282, saving model to weights.167-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 168/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00168: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0106 - val_loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00169: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 170/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00170: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 171/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00171: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 172/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00172: val_loss improved from 0.01282 to 0.01274, saving model to weights.172-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 173/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00173: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 174/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00174: val_loss improved from 0.01274 to 0.01214, saving model to weights.174-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 175/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00175: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 176/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00176: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 177/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 00177: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 178/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 00178: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 179/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 00179: val_loss improved from 0.01214 to 0.01194, saving model to weights.179-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 180/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0101\n",
      "Epoch 00180: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 181/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00181: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0100 - val_loss: 0.0125\n",
      "Epoch 182/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00182: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0100 - val_loss: 0.0152\n",
      "Epoch 183/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00183: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 184/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00184: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 185/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00185: val_loss improved from 0.01194 to 0.01190, saving model to weights.185-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 186/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00186: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 187/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00187: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 188/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00188: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 189/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00189: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 190/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00190: val_loss improved from 0.01190 to 0.01165, saving model to weights.190-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 191/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00191: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 192/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00192: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 193/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00193: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 194/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00194: val_loss improved from 0.01165 to 0.01152, saving model to weights.194-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 195/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00195: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 196/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00196: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 197/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00197: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0094 - val_loss: 0.0128\n",
      "Epoch 198/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00198: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 199/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00199: val_loss improved from 0.01152 to 0.01125, saving model to weights.199-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 200/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00200: val_loss improved from 0.01125 to 0.01048, saving model to weights.200-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 201/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00201: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 202/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00202: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 203/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00203: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0092 - val_loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00204: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 205/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00205: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0092 - val_loss: 0.0113\n",
      "Epoch 206/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00206: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 207/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0091\n",
      "Epoch 00207: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0091 - val_loss: 0.0118\n",
      "Epoch 208/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0091- ETA: 0s - loss: 0.00\n",
      "Epoch 00208: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 209/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0091\n",
      "Epoch 00209: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0091 - val_loss: 0.0124\n",
      "Epoch 210/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0090\n",
      "Epoch 00210: val_loss improved from 0.01048 to 0.01046, saving model to weights.210-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 211/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0090\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00211: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 212/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0056\n",
      "Epoch 00212: val_loss improved from 0.01046 to 0.00730, saving model to weights.212-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 213/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00213: val_loss improved from 0.00730 to 0.00720, saving model to weights.213-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 214/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00214: val_loss improved from 0.00720 to 0.00699, saving model to weights.214-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 18s 18us/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 215/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00215: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 216/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00216: val_loss improved from 0.00699 to 0.00694, saving model to weights.216-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 217/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00217: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 29s 28us/step - loss: 0.0049 - val_loss: 0.0069\n",
      "Epoch 218/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00218: val_loss improved from 0.00694 to 0.00683, saving model to weights.218-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 219/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00219: val_loss improved from 0.00683 to 0.00676, saving model to weights.219-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 220/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00220: val_loss improved from 0.00676 to 0.00672, saving model to weights.220-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 50s 49us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 221/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00221: val_loss improved from 0.00672 to 0.00671, saving model to weights.221-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 222/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00222: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 223/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00223: val_loss improved from 0.00671 to 0.00664, saving model to weights.223-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 51s 50us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 224/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00224: val_loss improved from 0.00664 to 0.00659, saving model to weights.224-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 50s 49us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 225/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00225: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 226/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00226: val_loss improved from 0.00659 to 0.00652, saving model to weights.226-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 227/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00227: val_loss improved from 0.00652 to 0.00643, saving model to weights.227-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 48s 47us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 228/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00228: val_loss improved from 0.00643 to 0.00642, saving model to weights.228-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 48s 47us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 229/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00229: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 48s 47us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 230/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00230: val_loss improved from 0.00642 to 0.00631, saving model to weights.230-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 49s 48us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 231/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00231: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 48s 47us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 232/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00232: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 24s 23us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 233/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00233: val_loss improved from 0.00631 to 0.00631, saving model to weights.233-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 234/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00234: val_loss improved from 0.00631 to 0.00620, saving model to weights.234-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 235/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00235: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0044 - val_loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00236: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 237/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00237: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 238/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00238: val_loss improved from 0.00620 to 0.00613, saving model to weights.238-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 239/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00239: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 240/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00240: val_loss improved from 0.00613 to 0.00610, saving model to weights.240-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 241/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00241: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 242/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00242: val_loss improved from 0.00610 to 0.00599, saving model to weights.242-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 243/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00243: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 244/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00244: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 245/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00245: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 246/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00246: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 17us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 247/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00247: val_loss improved from 0.00599 to 0.00593, saving model to weights.247-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 248/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00248: val_loss improved from 0.00593 to 0.00591, saving model to weights.248-0.01.hdf5\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 249/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00249: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 250/250\n",
      "1019904/1022889 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00250: val_loss did not improve\n",
      "1022889/1022889 [==============================] - 17s 16us/step - loss: 0.0042 - val_loss: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe628f330b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=4096, epochs=250,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(factor=0.2, verbose=1, min_lr=1e-6),\n",
    "        ModelCheckpoint('dev/models/weights.{epoch:04d}-{val_loss:.4f}.hdf5',\n",
    "                        verbose=1, save_best_only=True),\n",
    "        TensorBoard('dev/logs/', write_graph=False, write_grads=True),\n",
    "    ],\n",
    "    validation_data=(test_x, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
