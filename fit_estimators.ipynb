{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we run some baselines to understand the level of performance to beat\n",
    "we use nested CV and grid search to get realistic performance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from collections import defaultdict, namedtuple\n",
    "import datetime\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import base64\n",
    "import pickle\n",
    "import hashlib\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import fmin_cg, fmin_ncg\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df():\n",
    "    dframe_path = 'hdfs:///Projects/more_stuff/cabauw/processed-full-log.csv.gz'\n",
    "\n",
    "    from hops import hdfs\n",
    "    fs = hdfs.get_fs()\n",
    "\n",
    "    with fs.open_file(dframe_path) as f:\n",
    "        df = pd.read_csv(f, na_values='--', compression='gzip')\n",
    "\n",
    "    df = df[(df.ustar > 0.1) & (abs(df.H) > 10) & (df.wind > 1)]\n",
    "    df = df[df.ds != 201603]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(dtimes, interval):\n",
    "    # returns a tuple index_above, index_below\n",
    "    # index_above[i] is the largest i\n",
    "    # such that dtimes[index_above[i]] - dtimes[i] < interval\n",
    "    # index_below[i] is the smallest i\n",
    "    # such that dtimes[i] - dtimes[index_below[i]] < interval\n",
    "    # dtimes must be already sorted!\n",
    "    index_below, index_above = np.zeros(\n",
    "        (2, len(dtimes)), dtype=np.int\n",
    "    ) - 1\n",
    "\n",
    "    for i, x in enumerate(dtimes):\n",
    "        j = index_below[i - 1] if i > 0 else 0\n",
    "        while x - dtimes[j] > interval:\n",
    "            j += 1\n",
    "\n",
    "        index_below[i] = j\n",
    "        index_above[j] = i\n",
    "\n",
    "    last_above = index_above[0]\n",
    "    for i in range(len(dtimes)):\n",
    "        if index_above[i] < 0:\n",
    "            index_above[i] = last_above\n",
    "        else:\n",
    "            last_above = index_above[i]\n",
    "    \n",
    "    return index_above, index_below\n",
    "\n",
    "\n",
    "def compute_trend(df, columns, interval=3600):\n",
    "    df = df.sort_values('datetime')\n",
    "    for z in df.z.unique():  \n",
    "        this_level = df[df.z == z]\n",
    "        index_above, index_below = make_index(this_level.datetime.values, interval)\n",
    "\n",
    "        for col in columns:\n",
    "            val_above = this_level[col].values\n",
    "            val_below = this_level.iloc[index_below][col].values\n",
    "\n",
    "            time_above = this_level.datetime.values\n",
    "            time_below = this_level.iloc[index_below].datetime.values\n",
    "\n",
    "            trend = 3600 * (val_above - val_below) / (time_above - time_below)\n",
    "\n",
    "            df.loc[df.z == z, col + '_trend'] = trend\n",
    "\n",
    "    return df, [col + '_trend' for col in columns]\n",
    "\n",
    "\n",
    "def get_features(df, use_trend, feature_level):\n",
    "    # get feature names of the corresponding level\n",
    "    # adding them to df if not already there\n",
    "\n",
    "    feature_sets = [\n",
    "        [\n",
    "            'z', 'wind', 'temp', 'soil_temp',\n",
    "            'wind_10', 'wind_20', 'wind_40',\n",
    "            'temp_10', 'temp_20', 'temp_40',\n",
    "        ],\n",
    "        ['soilheat'],\n",
    "        ['netrad'],\n",
    "        ['rain', 'dewpoint'],\n",
    "        ['H', 'LE'],\n",
    "    ]\n",
    "\n",
    "    if isinstance(feature_level, int):\n",
    "        if feature_level < len(feature_sets):\n",
    "            features = [\n",
    "                f for fset in feature_sets[:feature_level]\n",
    "                for f in fset\n",
    "            ]\n",
    "        else:\n",
    "            features = [\n",
    "                'air_dens', 'wind', 'temp', 'virtual_temp', 'soil_temp', 'z',\n",
    "                'dewpoint', 'spec_hum', 'rel_hum', 'press', 'rain', 'co2flux',\n",
    "                'soilheat', 'netrad', 'temp_10', 'temp_20', 'temp_40', 'wind_10',\n",
    "                'wind_20', 'wind_40'\n",
    "            ]\n",
    "    elif isinstance(feature_level, (list, tuple)):\n",
    "        features = feature_level\n",
    "    else:\n",
    "        raise ValueError('pass list or int')\n",
    "\n",
    "    \n",
    "    if ('wind_40' not in df.columns or\n",
    "            'wind_20' not in df.columns or\n",
    "            'wind_10' not in df.columns):\n",
    "\n",
    "        wind_temp_levels = df.pivot_table(\n",
    "            values=['wind', 'temp'], columns='z', index=['ds', 'tt']\n",
    "        ).reset_index()\n",
    "        wind_temp_levels.columns = [\n",
    "            '%s_%d' % (a, b) if b else a\n",
    "            for a, b in wind_temp_levels.columns.values\n",
    "        ]\n",
    "        df = df.merge(wind_temp_levels, on=['ds', 'tt'])\n",
    "\n",
    "    if use_trend:\n",
    "        missing_trend = [\n",
    "            f for f in features\n",
    "            if f != 'z' and f + '_trend' not in df.columns\n",
    "        ]\n",
    "\n",
    "        if missing_trend:\n",
    "            df, added_cols = compute_trend(df, missing_trend)\n",
    "            features.extend(added_cols)\n",
    "\n",
    "    # remove feature columns with only nulls and rows with any null\n",
    "    empty_columns = df.isnull().all(axis=0)\n",
    "    keep_columns = df.columns.isin(features) & ~empty_columns\n",
    "    missing = df.loc[:, keep_columns].isnull().any(axis=1)\n",
    "    df = df[~missing]\n",
    "    features = keep_columns.index.values[keep_columns.values]\n",
    "\n",
    "    return df, features\n",
    "\n",
    "\n",
    "def get_train_test(df, features, target, train_idx, test_idx, normalize):\n",
    "    train_x, train_y = df.iloc[train_idx][features], df.iloc[train_idx][target]\n",
    "    test_x, test_y = df.iloc[test_idx][features], df.iloc[test_idx][target]\n",
    "\n",
    "    if normalize:\n",
    "        mean_x, std_x = train_x.mean(), train_x.std()\n",
    "        train_x = (train_x - mean_x) / std_x\n",
    "        test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "        mean_y, std_y = train_y.mean(), train_y.std()\n",
    "        train_y = (train_y - mean_y) / std_y\n",
    "        test_y = (test_y - mean_y) / std_y\n",
    "    else:\n",
    "        mean_y, std_y = 0, 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MOSTEstimator:\n",
    "    ''' estimator for the universal functions in the monin-obukhov similarity theory\n",
    "        implementing scikit's interface\n",
    "        \n",
    "        fitting is done by minimizing the L2 regularized squared error\n",
    "        via conjugate gradient\n",
    "    '''\n",
    "    def __init__(self, regu=0.1, use_hessian=True):\n",
    "        self.regu = regu\n",
    "        self.a, self.b, self.c, self.d = (1, 4.8, np.sqrt(19.3), -0.25)\n",
    "        self.use_hessian = use_hessian\n",
    "        self.symbols = None\n",
    "\n",
    "    def _lazy_init_hessian(self):\n",
    "        # we initialize these functions lazily so that we can pickle\n",
    "        # this object and send it around before fitting\n",
    "        if self.use_hessian and self.symbols is None:\n",
    "            a, b, c, d, x = sp.symbols('a b c d x')\n",
    "            self.symbols = a, b, c, d\n",
    "\n",
    "            self._neg_H_fn = self._get_hessian_functions(\n",
    "                a * sp.Pow(1 - x * c**2, d), x, a, b, c, d\n",
    "            )\n",
    "            self._pos_H_fn = self._get_hessian_functions(\n",
    "                a + b * x, x, a, b, c, d\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_hessian_functions(expr, x, *symbols):\n",
    "        # returns functions computing second-order partial derivatives\n",
    "        # of expr. keyed by differentiation variables\n",
    "        return {\n",
    "            (s1, s2): sp.lambdify(\n",
    "                [x] + list(symbols),\n",
    "                sp.simplify(sp.diff(sp.diff(expr, s1), s2)),\n",
    "                'numpy'\n",
    "            ) for s1 in symbols for s2 in symbols\n",
    "        }\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'regu': self.regu}\n",
    "\n",
    "    def set_params(self, regu):\n",
    "        self.regu = regu\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def _compute_phi(cls, zL, a, b, c, d):\n",
    "        zL = cls._to_vec(zL)\n",
    "        mask = zL >= 0\n",
    "        yy = np.zeros(zL.shape)\n",
    "        yy[mask] = a + b * zL[mask]\n",
    "        yy[~mask] = a * np.power(1 - c**2 * zL[~mask], d)\n",
    "        assert all(np.isfinite(zL))\n",
    "        assert all(np.isfinite(yy)), (a, b, c, d)\n",
    "        return yy\n",
    "\n",
    "    @classmethod\n",
    "    def _compute_phi_prime(cls, zL, a, b, c, d):\n",
    "        zL = cls._to_vec(zL)\n",
    "        dpda, dpdb, dpdc, dpdd = np.zeros((4, len(zL)))\n",
    "\n",
    "        pos, neg = zL >= 0, zL < 0\n",
    "\n",
    "        dpda[pos] = 1\n",
    "        dpdb[pos] = zL[pos]\n",
    "\n",
    "        inner = 1 - c**2 * zL[neg]\n",
    "        dpda[neg] = np.power(inner, d)\n",
    "        dpdc[neg] = -2 * zL[neg] * a * c * d * np.power(inner, d - 1)\n",
    "        dpdd[neg] = a * np.log(inner) * np.power(inner, d)\n",
    "\n",
    "        return dpda, dpdb, dpdc, dpdd\n",
    "\n",
    "    def _fmin_hess(self, params, xx, yy, regu):\n",
    "        self._lazy_init_hessian()\n",
    "\n",
    "        preds = self._compute_phi(xx, *params)\n",
    "        xpos_mask = xx >= 0\n",
    "        hh1 = np.zeros((4, 4))\n",
    "\n",
    "        for i, s1 in enumerate(self.symbols):\n",
    "            for j, s2 in enumerate(self.symbols):\n",
    "                # when xx >= 0 the function is linear\n",
    "                # its hessian is always 0\n",
    "\n",
    "                neg = self._neg_H_fn[s1, s2](xx[~xpos_mask], *params)\n",
    "                hh1[i, j] = np.sum((preds[~xpos_mask] - yy[~xpos_mask]) * neg)\n",
    "\n",
    "        hh2 = np.zeros((4, len(xx)))\n",
    "        hh2[:, :] = self._compute_phi_prime(xx, *params)\n",
    "        \n",
    "        hess = 2 * ((hh2.dot(hh2.T) + hh1) / len(xx) + regu * np.eye(4))\n",
    "        return hess\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmin_target(params, xx, yy, regu):\n",
    "        preds = MOSTEstimator._compute_phi(xx, *params)\n",
    "        err = np.mean((yy - preds)**2) + regu * sum(p**2 for p in params)\n",
    "        return err\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmin_grad(params, xx, yy, regu):\n",
    "        preds = MOSTEstimator._compute_phi(xx, *params)\n",
    "        der = MOSTEstimator._compute_phi_prime(xx, *params)\n",
    "\n",
    "        grads = [\n",
    "            2 * np.mean((preds - yy) * parpr) + 2 * regu * par\n",
    "            for par, parpr in zip(params, der)\n",
    "        ]\n",
    "\n",
    "        return np.array(grads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_vec(mat):\n",
    "        mat = np.array(mat)\n",
    "        \n",
    "        # check that multi-dimensional arrays have only one\n",
    "        # dimension with more than one sample\n",
    "        # e.g. 1x1x99x1 is fine, 1x2x99x is not\n",
    "        assert sum(1 for n in mat.shape if n > 1) == 1\n",
    "        return mat.reshape(-1)\n",
    "    \n",
    "    def fit(self, X, y, disp=False):\n",
    "        X = self._to_vec(X)\n",
    "        y = self._to_vec(y)\n",
    "\n",
    "        if self.use_hessian:\n",
    "            self.a, self.b, self.c, self.d = fmin_ncg(\n",
    "                self._fmin_target,\n",
    "                (self.a, self.b, self.c, self.d),\n",
    "                self._fmin_grad,\n",
    "                fhess=self._fmin_hess,\n",
    "                args=(X, y, self.regu),\n",
    "                disp=disp,\n",
    "            )\n",
    "        else:\n",
    "            self.a, self.b, self.c, self.d = fmin_cg(\n",
    "                self._fmin_target,\n",
    "                (self.a, self.b, self.c, self.d),\n",
    "                self._fmin_grad,\n",
    "                args=(X, y, self.regu),\n",
    "                disp=disp,\n",
    "            )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._compute_phi(X, self.a, self.b, self.c, self.d)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return metrics.mean_squared_error(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeKFold:\n",
    "    ''' k-fold cross validator splitting on a particular attribute\n",
    "        so that all samples with a given value are either in the train or test set\n",
    "\n",
    "        attribute value for each sample is given in the constructor, so that\n",
    "        the attribute itself need not be in the features for the model\n",
    "    '''\n",
    "    def __init__(self, cv, attr):\n",
    "        self.cv, self.attr = cv, attr\n",
    "\n",
    "    def get_n_splits(self, *args, **kwargs):\n",
    "        return self.cv.get_n_splits(*args, **kwargs)\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        vals = self.attr.unique()\n",
    "        for train_idx, test_idx in self.cv.split(vals):\n",
    "            train_mask = self.attr.isin(vals[train_idx])\n",
    "            test_mask = self.attr.isin(vals[test_idx])\n",
    "\n",
    "            yield (\n",
    "                np.argwhere(train_mask).reshape(-1),\n",
    "                np.argwhere(test_mask).reshape(-1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attributekfold():\n",
    "    outer_cv = AttributeKFold(KFold(10, shuffle=True), df.ds)\n",
    "    outer_train, outer_test = np.zeros((2, len(df)))\n",
    "    for outer_train_idx, outer_test_idx in outer_cv.split(df):\n",
    "\n",
    "        outer_train[outer_train_idx] += 1\n",
    "        outer_test[outer_test_idx] += 1\n",
    "\n",
    "        inner_train, inner_test = np.zeros((2, len(outer_train_idx)))\n",
    "        inner_cv = AttributeKFold(KFold(5, shuffle=True), df.iloc[outer_train_idx].ds)\n",
    "        for inner_train_idx, inner_test_idx in inner_cv.split(df.iloc[outer_train_idx]):\n",
    "            inner_train[inner_train_idx] += 1\n",
    "            inner_test[inner_test_idx] += 1\n",
    "\n",
    "        assert all(inner_train == 4)\n",
    "        assert all(inner_test == 1)\n",
    "\n",
    "    assert all(outer_train == 9)\n",
    "    assert all(outer_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(ypred, ytrue):\n",
    "    minn = max(min(ypred), min(ytrue))\n",
    "    maxx = min(max(ypred), max(ytrue))\n",
    "    \n",
    "    plt.scatter(ytrue, ypred, s=2)\n",
    "    plt.plot([minn, maxx], [minn, maxx], 'r--')\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogUniform:\n",
    "    ''' random variable X such that log(x) is distributed uniformly\n",
    "    '''\n",
    "    def __init__(self, base, expmin, expmax):\n",
    "        self.base, self.expmin, self.expmax = base, expmin, expmax\n",
    "\n",
    "    def rvs(self, size=None, random_state=None):\n",
    "        random_state = random_state or np.random.RandomState()\n",
    "        exp = random_state.uniform(self.expmin, self.expmax, size=size)\n",
    "        return np.power(self.base, exp)\n",
    "\n",
    "\n",
    "class IntDistribution:\n",
    "    ''' random variable taking only integer values\n",
    "    '''\n",
    "    def __init__(self, rv):\n",
    "        self.rv = rv\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        sample = self.rv.rvs(*args, **kwargs)\n",
    "        return int(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVSpec = namedtuple('CVSpec', [\n",
    "    'model', 'param_distribution', 'features',\n",
    "    'target', 'inner_cv', 'outer_cv', 'n_iter', 'normalize',\n",
    "    'inner_seed', 'outer_seed', 'param_seed', 'meta',\n",
    "    'save_to',\n",
    "])\n",
    "\n",
    "CVResult = namedtuple('CVResult', [\n",
    "    'meta', 'scores', 'test_x', 'test_y', 'y_pred', 'imps'\n",
    "])\n",
    "\n",
    "\n",
    "# set default value to None, https://stackoverflow.com/a/18348004/521776\n",
    "CVSpec.__new__.__defaults__ = (None,) * len(CVSpec._fields)\n",
    "CVResult.__new__.__defaults__ = (None,) * len(CVResult._fields)\n",
    "\n",
    "Scores = namedtuple('Scores', [\n",
    "    'train_mse',\n",
    "    'explained_variance_score',\n",
    "    'mean_absolute_error',\n",
    "    'mean_squared_error',\n",
    "    'median_absolute_error',\n",
    "    'r2_score',\n",
    "    'mean_abs_percent_error',\n",
    "    'median_abs_percent_error',\n",
    "])\n",
    "\n",
    "OuterCVResult = namedtuple('OuterCVResult', [\n",
    "    'scores',\n",
    "    'param_keys',\n",
    "    'param_values',\n",
    "    'test_x',\n",
    "    'test_y',\n",
    "    'y_pred',\n",
    "])\n",
    "\n",
    "InnerCVResult = namedtuple('InnerCVResult', [\n",
    "    'inner_mse', 'final_results'\n",
    "])\n",
    "\n",
    "\n",
    "def get_cv_fold(fold, cv_k, seed, attr):\n",
    "    assert fold < cv_k\n",
    "    \n",
    "    cv = AttributeKFold(\n",
    "        KFold(cv_k, shuffle=True, random_state=seed),\n",
    "        attr\n",
    "    ).split(attr)\n",
    "    \n",
    "    for _ in range(fold):\n",
    "        _ = next(cv)\n",
    "    return next(cv)\n",
    "\n",
    "\n",
    "def get_train_test(df, features, target, train_idx, test_idx, normalize):\n",
    "    train_x, train_y = df.iloc[train_idx][features], df.iloc[train_idx][target]\n",
    "    test_x, test_y = df.iloc[test_idx][features], df.iloc[test_idx][target]\n",
    "\n",
    "    if normalize:\n",
    "        mean_x, std_x = train_x.mean(), train_x.std()\n",
    "        train_x = (train_x - mean_x) / std_x\n",
    "        test_x = (test_x - mean_x) / std_x\n",
    "\n",
    "        mean_y, std_y = train_y.mean(), train_y.std()\n",
    "        train_y = (train_y - mean_y) / std_y\n",
    "        test_y = (test_y - mean_y) / std_y\n",
    "    else:\n",
    "        mean_y, std_y = 0, 1\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, mean_y, std_y\n",
    "\n",
    "\n",
    "class EncodeMoreStuff(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "class CachedResults:\n",
    "    def __init__(self, **kwargs):\n",
    "        try:\n",
    "            from hops import hdfs\n",
    "        except ImportError:\n",
    "            self.open_ = lambda f, m: open(f, m + 'b')\n",
    "            self.cache_dir = './dev/checkpoints/'\n",
    "        else:\n",
    "            fs = hdfs.get_fs()\n",
    "            self.open_ = lambda f, m: fs.open_file(f, m)\n",
    "            \n",
    "            # using HDFS as a filesystem cache\n",
    "            # is a *terrible* idea in so many ways\n",
    "            # but we have no alternative.\n",
    "            self.cache_dir = 'hdfs:///Projects/more_stuff/cabauw/checkpoints/'\n",
    "\n",
    "        self.fname = hashlib.sha256(\n",
    "            json.dumps(kwargs, cls=EncodeMoreStuff).encode('utf8')\n",
    "        ).hexdigest()\n",
    "    \n",
    "    def get_value(self):\n",
    "        try:\n",
    "            with self.open_(self.cache_dir + self.fname, 'r') as f:\n",
    "                return pickle.loads(f.read())\n",
    "        except:  # want to invalidate cache regardless of what went wrong\n",
    "            return None\n",
    "\n",
    "    def set_value(self, val):\n",
    "        with self.open_(self.cache_dir + self.fname, 'w') as f:\n",
    "            f.write(pickle.dumps(val))\n",
    "\n",
    "\n",
    "class CachedResults:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def get_value(self):\n",
    "        return None\n",
    "    \n",
    "    def set_value(self, val):\n",
    "        return None\n",
    "            \n",
    "            \n",
    "def compute_metrics(train_y, y_pred_train, test_y, y_pred, mean_y, std_y):\n",
    "    y_pred = y_pred * std_y + mean_y\n",
    "    y_pred_train = y_pred_train * std_y + mean_y\n",
    "\n",
    "    test_y = test_y * std_y + mean_y\n",
    "    train_y = train_y * std_y + mean_y\n",
    "\n",
    "    perc_errors = 100 * np.abs((test_y - y_pred) / test_y)\n",
    "\n",
    "    return Scores(\n",
    "        train_mse=metrics.mean_squared_error(train_y, y_pred_train),\n",
    "        explained_variance_score=metrics.explained_variance_score(test_y, y_pred),\n",
    "        mean_absolute_error=metrics.mean_absolute_error(test_y, y_pred),\n",
    "        mean_squared_error=metrics.mean_squared_error(test_y, y_pred),\n",
    "        median_absolute_error=metrics.median_absolute_error(test_y, y_pred),\n",
    "        r2_score=metrics.r2_score(test_y, y_pred),\n",
    "        mean_abs_percent_error=np.mean(perc_errors),\n",
    "        median_abs_percent_error=np.median(perc_errors),\n",
    "    )\n",
    "\n",
    "\n",
    "def inner_train(df_bcast, model, features, target, params, outer_cv,\n",
    "                outer_fold, inner_cv, inner_fold, keys, outer_seed,\n",
    "                inner_seed, normalize):\n",
    "    # pass outer_cv <= 0 to have plain CV instead of nested CV\n",
    "\n",
    "    cache = CachedResults(\n",
    "        model=model.__class__.__name__, features=features, target=target,\n",
    "        params=params, outer_fold=outer_fold, inner_fold=inner_fold, keys=keys,\n",
    "        outer_seed=outer_seed, inner_seed=inner_seed, normalize=normalize\n",
    "    )\n",
    "    saved = cache.get_value()\n",
    "    if saved is not None:\n",
    "        return saved\n",
    "\n",
    "    df = df_bcast.value\n",
    "    if any(f not in df.columns for f in features):\n",
    "        print('some features are missing, reloading...')\n",
    "        df, _ = get_features(read_df(), use_trend=True, feature_level=5)\n",
    "    assert all(f in df.columns for f in features), (df.columns, features)\n",
    "\n",
    "    if outer_cv > 0:\n",
    "        outer_train_idx, outer_test_idx = get_cv_fold(\n",
    "            outer_fold, outer_cv, outer_seed, df.ds\n",
    "        )\n",
    "\n",
    "        inner_train_idx, inner_test_idx = get_cv_fold(\n",
    "            inner_fold, inner_cv, inner_seed, df.iloc[outer_train_idx].ds\n",
    "        )\n",
    "\n",
    "        train_idx = outer_train_idx[inner_train_idx]\n",
    "        test_idx = outer_train_idx[inner_test_idx]\n",
    "    else:\n",
    "        train_idx, test_idx = get_cv_fold(\n",
    "            inner_fold, inner_cv, inner_seed, df.ds\n",
    "        )\n",
    "\n",
    "    train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test(\n",
    "        df, features, target, train_idx, test_idx, normalize\n",
    "    )\n",
    "\n",
    "    model = model.set_params(**dict(zip(keys, params)))\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred_train = model.predict(train_x)\n",
    "    y_pred = model.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, y_pred)\n",
    "    \n",
    "    if outer_cv > 0:\n",
    "        final_results = None\n",
    "    else:\n",
    "        final_results = OuterCVResult(\n",
    "            scores=compute_metrics(\n",
    "                train_y, y_pred_train, test_y, y_pred, mean_y, std_y\n",
    "            ),\n",
    "            param_keys=keys,\n",
    "            param_values=params,\n",
    "            test_x=test_x if inner_fold == 0 else None,\n",
    "            test_y=test_x if inner_fold == 0 else None,\n",
    "            y_pred=test_x if inner_fold == 0 else None,\n",
    "        )\n",
    "\n",
    "    result = InnerCVResult(\n",
    "        inner_mse=test_mse,\n",
    "        final_results=final_results,\n",
    "    )\n",
    "\n",
    "    cache.set_value(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def outer_train(df_bcast, model, features, target, outer_cv, outer_fold,\n",
    "                params, keys, outer_seed, normalize):\n",
    "    cache = CachedResults(\n",
    "        model=model.__class__.__name__, features=features,\n",
    "        target=target, params=params, outer_fold=outer_fold,\n",
    "        keys=keys, outer_seed=outer_seed, normalize=normalize\n",
    "    )\n",
    "    saved = cache.get_value()\n",
    "    if saved is not None:\n",
    "        return saved\n",
    "\n",
    "    df = df_bcast.value\n",
    "    if any(f not in df.columns for f in features):\n",
    "        print('some features are missing, reloading...')\n",
    "        df, _ = get_features(read_df(), use_trend=True, feature_level=5)\n",
    "    assert all(f in df.columns for f in features), (df.columns, features)\n",
    "    \n",
    "    assert outer_cv > 0\n",
    "    train_idx, test_idx = get_cv_fold(\n",
    "        outer_fold, outer_cv, outer_seed, df.ds\n",
    "    )\n",
    "\n",
    "    train_x, train_y, test_x, test_y, mean_y, std_y = get_train_test(\n",
    "        df, features, target, train_idx, test_idx, normalize\n",
    "    )\n",
    "\n",
    "    model = model.set_params(**dict(zip(keys, params)))\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    y_pred_train = model.predict(train_x)\n",
    "    y_pred = model.predict(test_x)\n",
    "\n",
    "    result = OuterCVResult(\n",
    "        scores=compute_metrics(\n",
    "            train_y, y_pred_train, test_y, y_pred, mean_y, std_y\n",
    "        ),\n",
    "        param_keys=keys,\n",
    "        param_values=params,\n",
    "        test_x=test_x if outer_fold == 0 else None,\n",
    "        test_y=test_y if outer_fold == 0 else None,\n",
    "        y_pred=y_pred if outer_fold == 0 else None,\n",
    "    )\n",
    "\n",
    "    cache.set_value(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def finalize_result(meta, results, save_to=None):\n",
    "    scores, params = [], []\n",
    "    test_x = test_y = y_pred = None\n",
    "    for res in list(results):\n",
    "        scores.append(res.scores)\n",
    "        params.append(dict(zip(res.param_keys, res.param_values)))\n",
    "      \n",
    "        #if res.test_x is not None:\n",
    "        #    test_x = res.test_x\n",
    "        #    \n",
    "        #if res.test_y is not None:\n",
    "        #    test_y = res.test_y\n",
    "        #    \n",
    "        #if res.y_pred is not None:\n",
    "        #    y_pred = res.y_pred\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    params_df = pd.DataFrame(params)\n",
    "\n",
    "    cvres = CVResult(\n",
    "        meta=meta, scores=scores,\n",
    "        test_x=test_x, test_y=test_y, y_pred=y_pred, imps=params_df\n",
    "    )\n",
    "\n",
    "    if save_to:\n",
    "        try:\n",
    "            from hops import hdfs\n",
    "            fs = hdfs.get_fs()\n",
    "            open_ = fs.open_file\n",
    "            base_dir = 'hdfs:///Projects/more_stuff/cabauw/results/'\n",
    "        except ImportError:\n",
    "            open_ = open\n",
    "            base_dir = './data/'\n",
    "\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "        fname = '%s/results_%s.txt' % (base_dir, save_to)\n",
    "        with open_(fname, 'w') as f:\n",
    "            f.write(scores_df.describe().T.to_string())\n",
    "            f.write('\\n\\n**raw scores\\n\\n')\n",
    "            f.write(scores_df.to_string())\n",
    "            f.write('\\n\\n**parameters\\n\\n')\n",
    "            f.write(params_df.describe().T.to_string())\n",
    "            f.write('\\n\\n**raw parameters\\n\\n')\n",
    "            f.write(params_df.to_string())\n",
    "            f.write('\\n\\n**raw json results\\n\\n')\n",
    "\n",
    "            data = base64.b64encode(pickle.dumps(cvres)).decode('utf8')\n",
    "            bufsize = 2**16\n",
    "            for buf in range(0, len(data), bufsize):\n",
    "                f.write(data[buf:buf+bufsize])\n",
    "\n",
    "    return cvres\n",
    "\n",
    "\n",
    "def make_nested_cv_tasks(df_bcast, spec, cv_vals):\n",
    "    return (sc.parallelize(cv_vals, len(cv_vals))\n",
    "\n",
    "         # train and evaluate on inner fold for each outer fold\n",
    "         # x is (outer, inner, param values)\n",
    "         # key by (outer fold, param values)\n",
    "         .map(lambda x: ((x[0], x[2]), inner_train(\n",
    "             df_bcast=df_bcast,\n",
    "             model=spec.model,\n",
    "             features=spec.features,\n",
    "             target=spec.target,\n",
    "             outer_cv=spec.outer_cv,\n",
    "             outer_fold=x[0],\n",
    "             inner_cv=spec.inner_cv,\n",
    "             inner_fold=x[1],\n",
    "             params=x[2],\n",
    "             keys=tuple(sorted(spec.param_distribution.keys())),\n",
    "             outer_seed=spec.outer_seed,\n",
    "             inner_seed=spec.inner_seed,\n",
    "             normalize=spec.normalize\n",
    "         )))\n",
    "\n",
    "         # for each outer fold/parameters, compute sum of mse\n",
    "         .reduceByKey(lambda res1, res2: InnerCVResult(\n",
    "                 inner_mse=res1.inner_mse + res2.inner_mse,\n",
    "                 final_results=None,\n",
    "             ), numPartitions=spec.outer_cv)\n",
    "\n",
    "        # for each outer fold, find parameters with best mse\n",
    "        .map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "        .reduceByKey(lambda x, y: x if x[1].inner_mse < y[1].inner_mse else y)\n",
    "\n",
    "        # for each outer fold, validate using best parameters\n",
    "        # x is (outer fold, (parameters, mse))\n",
    "        .map(lambda x: outer_train(\n",
    "            df_bcast=df_bcast,\n",
    "            model=spec.model,\n",
    "            features=spec.features,\n",
    "            target=spec.target,\n",
    "            outer_cv=spec.outer_cv,\n",
    "            outer_fold=x[0],\n",
    "            params=x[1][0],\n",
    "            keys=tuple(sorted(spec.param_distribution.keys())),\n",
    "            outer_seed=spec.outer_seed,\n",
    "            normalize=spec.normalize\n",
    "         ))\n",
    "\n",
    "         # finalize results, optionally saving\n",
    "         #\n",
    "         # we could use a coalesce(1) -> mapPartitions, but this would\n",
    "         # compute all the outer folds of all specs in the last stage\n",
    "         # (the one that contains collect), which means that it will only\n",
    "         # use len(cv_specs) executors to run sum(s.outer_cv for s in cv_specs)\n",
    "         # tasks. needlessly to say, that sucks\n",
    "         #\n",
    "         # by adding a keyBy/groupByKey/map, we force the previos outer cv\n",
    "         # to be in its own stage, thus there will be one partition for each\n",
    "         # outer fold of each spec, and we can fully utilize the executors\n",
    "         .keyBy(lambda x: 1)\n",
    "\n",
    "         # create one partition for each CV result\n",
    "         .groupByKey(spec.outer_cv)\n",
    "         .map(lambda x: finalize_result(spec.meta, x[1], spec.save_to))\n",
    "\n",
    "         # with this, we force finalize_result to be in its own stage\n",
    "         # \n",
    "         # since the default scheduler is FIFO, this means we will finalize\n",
    "         # the results as soon as the outer cv finishes\n",
    "         # without this, we would need to wait for all the outer cvs to finish\n",
    "         # and the results will all be finalized together at the end\n",
    "         # that would also suck\n",
    "         .coalesce(1)\n",
    "         .repartition(2))\n",
    "\n",
    "\n",
    "def make_cv_tasks(df_bcast, spec, cv_vals):\n",
    "\n",
    "    def merge_cv_results(res1, res2):\n",
    "        fin1, fin2 = res1.final_results, res2.final_results\n",
    "        \n",
    "        # make a list containing all the final results\n",
    "        #\n",
    "        # we cannot compare types directly because pyspark serialization\n",
    "        # will use a different type (that has the same name and attributes)\n",
    "        #\n",
    "        # moreover, lists are serialized as tuples, thus we need to\n",
    "        # convertthem  back to lists before joining\n",
    "        list_fin_1 = [fin1] if hasattr(fin1, 'scores') else list(fin1)\n",
    "        list_fin_2 = [fin2] if hasattr(fin2, 'scores') else list(fin2)\n",
    "        all_fin = list_fin_1 + list_fin_2\n",
    "\n",
    "        return InnerCVResult(\n",
    "            inner_mse=res1.inner_mse + res2.inner_mse,\n",
    "            final_results=all_fin,\n",
    "        )\n",
    "\n",
    "    return (sc.parallelize(cv_vals, len(cv_vals))\n",
    "        # train and evaluate on each fold\n",
    "        # x is (outer, inner, param values)\n",
    "        # key by param values\n",
    "        .map(lambda x: (x[2], inner_train(\n",
    "            df_bcast=df_bcast,\n",
    "            model=spec.model,\n",
    "            features=spec.features,\n",
    "            target=spec.target,\n",
    "            outer_cv=spec.outer_cv,\n",
    "            outer_fold=x[0],\n",
    "            inner_cv=spec.inner_cv,\n",
    "            inner_fold=x[1],\n",
    "            params=x[2],\n",
    "            keys=tuple(sorted(spec.param_distribution.keys())),\n",
    "            outer_seed=spec.outer_seed,\n",
    "            inner_seed=spec.inner_seed,\n",
    "            normalize=spec.normalize\n",
    "        )))\n",
    "\n",
    "        # for each parameters, compute sum of scores\n",
    "        # and preserve results of each fold\n",
    "        .reduceByKey(lambda res1, res2: merge_cv_results(res1, res2))\n",
    "\n",
    "        # find parameters with best mse\n",
    "        .map(lambda x: (1, x[1]))\n",
    "        .reduceByKey(lambda x, y: x if x.inner_mse < y.inner_mse else y)\n",
    "\n",
    "        # at this point we only have the InnerCVResult of the best parameters\n",
    "        # which contains the scores on each fold\n",
    "        .flatMap(lambda x: x[1].final_results)\n",
    "\n",
    "        # finalize results, optionally saving\n",
    "        .keyBy(lambda x: 1)\n",
    "        .groupByKey(spec.inner_cv)\n",
    "        .map(lambda x: finalize_result(spec.meta, x[1], spec.save_to))\n",
    "        .coalesce(1)\n",
    "        .repartition(2))\n",
    "\n",
    "\n",
    "def spark_cv(df, *cv_specs):\n",
    "    ''' cross-validation performing random search\n",
    "\n",
    "        optimized for running several nested cv in parallel, each with\n",
    "        different models and/or grids\n",
    "        \n",
    "        use outer_cv > 0 for nested cross validation\n",
    "    '''\n",
    "\n",
    "    df_bcast = sc.broadcast(df)\n",
    "    result_rdd = None\n",
    "    for spec in cv_specs:\n",
    "        # default values\n",
    "        spec = spec._replace(\n",
    "            inner_cv = spec.inner_cv or 10,\n",
    "            outer_cv = 10 if spec.outer_cv is None else spec.outer_cv,\n",
    "            n_iter = spec.n_iter or 10,\n",
    "            normalize = spec.normalize or True,\n",
    "            inner_seed = spec.inner_seed or np.random.randint(2**32, dtype=np.uint),\n",
    "            outer_seed = spec.outer_seed or np.random.randint(2**32, dtype=np.uint),   \n",
    "        )\n",
    "        \n",
    "        # build list of all grids to try and inner/outer combinations\n",
    "        rnd = np.random.RandomState(spec.param_seed)\n",
    "        cv_vals = []\n",
    "        for outer_fold in range(max(spec.outer_cv, 1)):\n",
    "            for rand in range(spec.n_iter):\n",
    "                distrs = spec.param_distribution\n",
    "                params = [(\n",
    "                    distrs[param].rvs(random_state=rnd)\n",
    "                    if hasattr(distrs[param], 'rvs')\n",
    "                    else np.random.choice(distrs[param])\n",
    "                ) for param in sorted(distrs.keys())]\n",
    "\n",
    "                for inner_fold in range(spec.inner_cv):\n",
    "                    cv_vals.append((\n",
    "                        outer_fold,\n",
    "                        inner_fold,\n",
    "                        tuple(params),\n",
    "                    ))\n",
    "\n",
    "        if spec.outer_cv > 0:\n",
    "            results = make_nested_cv_tasks(df_bcast, spec, cv_vals)\n",
    "        else:\n",
    "            results = make_cv_tasks(df_bcast, spec, cv_vals)\n",
    "\n",
    "        # we build the result rdd gradually with unions so that we can proceed\n",
    "        # to the outer cvs as soon as the spec's inner cv has finished\n",
    "        # if we built the whole result rdd in one go we would need to wait on\n",
    "        # all inner cvs from all specs to finish, before being able to start\n",
    "        # the outer cvs\n",
    "        if result_rdd is None:\n",
    "            result_rdd = results\n",
    "        else:\n",
    "            result_rdd = result_rdd.union(results)\n",
    "\n",
    "    cv_results = result_rdd.collect()\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def fit_most_estimator(df, most_only):\n",
    "    if most_only:\n",
    "        df = df[(df.zL > -2) & (df.zL < 1)]\n",
    "\n",
    "    dtime = datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "    fname = '%s_%smost-%s' % (\n",
    "        'MOSTEstimator', '' if most_only else 'no', dtime\n",
    "    )\n",
    "\n",
    "    meta = {\n",
    "        'model': 'MOSTEstimator',\n",
    "        'most': most_only\n",
    "    }\n",
    "\n",
    "    spec = CVSpec(\n",
    "        model=MOSTEstimator(),\n",
    "        param_distribution={'regu': LogUniform(10, -6, 1)},\n",
    "        features=['zL'],\n",
    "        target='phi_m',\n",
    "        inner_cv=10,\n",
    "        outer_cv=10,\n",
    "        n_iter=10,\n",
    "        normalize=False,\n",
    "        meta=meta,\n",
    "        save_to=fname,\n",
    "    )\n",
    "\n",
    "    return spark_cv(df, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(df, most_only, outer_cv, feature_sets, trends):\n",
    "    if most_only:\n",
    "        df = df[(df.zL > -2) & (df.zL < 1)]\n",
    "        \n",
    "    ridge_spec = Ridge, {\n",
    "        'alpha': LogUniform(10, -6, 1)\n",
    "    }\n",
    "    \n",
    "    knn_spec = KNeighborsRegressor, {\n",
    "        'n_neighbors': IntDistribution(LogUniform(10, 0, 1.7)),  # 10**1.7 ~= 50\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2],\n",
    "    }\n",
    "    \n",
    "    gbr_spec = GradientBoostingRegressor, {\n",
    "        'max_depth': IntDistribution(stats.uniform(loc=1, scale=9)),\n",
    "        'subsample': stats.uniform(loc=0.25, scale=0.75),\n",
    "        'max_features': stats.uniform(0.1, 0.9),\n",
    "        'loss': ['lad', 'ls', 'huber'],\n",
    "        'n_estimators': IntDistribution(LogUniform(10, 2, 3)),\n",
    "        'learning_rate': LogUniform(10, -5, -1),\n",
    "        'alpha': stats.uniform(0.01, 0.98),\n",
    "    }\n",
    "\n",
    "    all_specs = []\n",
    "    for fset in feature_sets:\n",
    "        for trend in trends:\n",
    "            _, features = get_features(df, trend, fset)\n",
    "            for model_cls, grid in [ridge_spec, knn_spec, gbr_spec]:\n",
    "                dtime = datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "                fname = '%s_f%d_%strend_%smost_%doutercv-%s' % (\n",
    "                    model_cls.__name__, fset,\n",
    "                    '' if trend else 'no',\n",
    "                    '' if most_only else 'no',\n",
    "                    outer_cv, dtime\n",
    "                )\n",
    "\n",
    "                all_specs.append(CVSpec(\n",
    "                    model=model_cls(),\n",
    "                    param_distribution=grid,\n",
    "                    features=features,\n",
    "                    target='phi_m',\n",
    "                    inner_cv=10,\n",
    "                    outer_cv=outer_cv,\n",
    "                    n_iter=25,\n",
    "                    normalize=True,\n",
    "                    meta={\n",
    "                        'trend': trend,\n",
    "                        'fset': fset,\n",
    "                        'model': model_cls,\n",
    "                        'most': most_only\n",
    "                    },\n",
    "                    save_to=fname,\n",
    "                ))\n",
    "\n",
    "    import random\n",
    "    random.shuffle(all_specs)\n",
    "\n",
    "    return spark_cv(df, *all_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = read_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf, _ = get_features(df, use_trend=True, feature_level=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_most_estimator(ddf, most_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_most_estimator(ddf, most_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = do_test(ddf, most_only=True, outer_cv=10, feature_sets=[9], trends=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf, _ = get_features(df, use_trend=True, feature_level=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = do_test(ddf, most_only=False, outer_cv=10, feature_sets=[9], trends=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = do_test(ddf, most_only=True, outer_cv=0, fset=[1,2,3,4,5], trend=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatTruncatedSVD(TruncatedSVD):\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(self.n_components, float):\n",
    "            self.n_components = max(1, int(X.shape[1] * self.n_components))\n",
    "        return super(FloatTruncatedSVD, self).fit(X, y)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if isinstance(self.n_components, float):\n",
    "            self.n_components = max(1, int(X.shape[1] * self.n_components))\n",
    "        return super(FloatTruncatedSVD, self).fit_transform(X, y)\n",
    "\n",
    "\n",
    "def ensemble_of_linear_models(df, most_only, outer_cv, trend):\n",
    "    if most_only:\n",
    "        df = df[(df.zL > -2) & (df.zL < 1)]\n",
    "\n",
    "    model = BaggingRegressor(Pipeline([\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('scal', StandardScaler()),\n",
    "        ('redu', FloatTruncatedSVD()),\n",
    "        ('reg', Ridge()),\n",
    "    ]))\n",
    "\n",
    "    params = {\n",
    "        'base_estimator__poly__degree': [1, 2],\n",
    "        'base_estimator__poly__interaction_only': [True, False],\n",
    "        'base_estimator__redu__n_components': stats.uniform(0.1, 0.89),\n",
    "        'base_estimator__reg__alpha': LogUniform(10, -7, 1),\n",
    "        'n_estimators': IntDistribution(stats.uniform(5, 95)),\n",
    "        'max_samples': stats.uniform(0.05, 0.45),\n",
    "        'max_features': stats.uniform(0.25, 0.75),\n",
    "    }\n",
    "\n",
    "    features = [\n",
    "        'air_dens', 'wind', 'temp', 'virtual_temp', 'soil_temp', 'z',\n",
    "        'dewpoint', 'spec_hum', 'rel_hum', 'press', 'rain', 'co2flux',\n",
    "        'soilheat', 'netrad', 'temp_10', 'temp_20', 'temp_40', 'wind_10',\n",
    "        'wind_20', 'wind_40'\n",
    "    ]\n",
    "    \n",
    "    dtime = datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "    fname = 'LinearEnsemble_f9_%strend_%smost_%doutercv-%s' % (\n",
    "        '' if trend else 'no',\n",
    "        '' if most_only else 'no',\n",
    "        outer_cv, dtime\n",
    "    )\n",
    "    \n",
    "    spec = CVSpec(\n",
    "        model=model,\n",
    "        param_distribution=params,\n",
    "        features=features,\n",
    "        target='phi_m',\n",
    "        inner_cv=10,\n",
    "        outer_cv=0,\n",
    "        n_iter=250,\n",
    "        normalize=True,\n",
    "        meta={\n",
    "            'trend': trend,\n",
    "            'fset': 'full',\n",
    "            'model': 'LinearEnsemble',\n",
    "            'most': most_only\n",
    "        },\n",
    "        save_to=fname,\n",
    "    )\n",
    "\n",
    "    return spark_cv(df, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ensemble_of_linear_models(ddf, most_only=True, outer_cv=0, trend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
